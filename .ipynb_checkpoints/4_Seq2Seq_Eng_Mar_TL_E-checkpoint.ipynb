{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 76055,
     "status": "ok",
     "timestamp": 1554793094988,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "gwTL36ttLedG",
    "outputId": "3c6783be-6108-4e7e-af9e-4dd2b8409210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# To mount Google drive on Google Colab environment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "root = '/content/drive/My Drive/English Dataset'\n",
    "# root = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb0tHTz1LedM"
   },
   "source": [
    "### 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2604,
     "status": "ok",
     "timestamp": 1554793104453,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "92RA6N5fLedO",
    "outputId": "db838591-c04a-49ed-c09b-57ca9dec199b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5-UJzoBLedS"
   },
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEj_b0VSLedT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5429f17fcad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mar-eng_cleaned.parallel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "# Read dataset\n",
    "lines = pd.read_pickle(os.path.join(root, 'mar-eng_cleaned.parallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1228,
     "status": "ok",
     "timestamp": 1554793108285,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "D787xMeLLedV",
    "outputId": "38ca493e-3cb8-4be6-970e-9c926f394902"
   },
   "outputs": [],
   "source": [
    "# View the shape of dataset\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsqG7aFTLedd"
   },
   "outputs": [],
   "source": [
    "# Add 'start' and 'end' tokens to target sentences\n",
    "lines.Mar = lines.Mar.apply(lambda x: '<START> ' + x + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1554793192576,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "GbGtP_6VLedh",
    "outputId": "d535e68c-6722-4e18-ec43-9ee48044b9c8"
   },
   "outputs": [],
   "source": [
    "# View a few samples of the dataset\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCXugjOO_-v_"
   },
   "outputs": [],
   "source": [
    "# Get vocabulary and embeddings\n",
    "with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n",
    "    english_summary = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(root, 'embeddings.ma'), 'rb') as f:\n",
    "    marathi_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W9WhAqyB_ZC"
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to dictionary\n",
    "for word in ['<START>', '<END>']:\n",
    "    l = len(marathi_summary['dictionary'].keys())\n",
    "    marathi_summary['dictionary'][word] = l\n",
    "    marathi_summary['reverse_dictionary'][l] = word\n",
    "    marathi_summary['embeddings'] = np.vstack((marathi_summary['embeddings'], np.zeros((1, marathi_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_i-8ssyLedl"
   },
   "outputs": [],
   "source": [
    "# English vocabulary\n",
    "all_eng_words = set(list(english_summary['dictionary'].keys()))\n",
    "        \n",
    "# Marathi vocabulary\n",
    "all_mar_words = set(list(marathi_summary['dictionary'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1554793205159,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "7QZaq1bQLedo",
    "outputId": "25372e5a-8bb3-445f-b1da-9a72a33e21e3"
   },
   "outputs": [],
   "source": [
    "# Max length of source sequence\n",
    "max_length_src = 0\n",
    "\n",
    "for line in lines.Eng:\n",
    "    if len(line.split(' ')) > max_length_src:\n",
    "        max_length_src = len(line.split(' '))\n",
    "        \n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1068,
     "status": "ok",
     "timestamp": 1554793207319,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SHtikVcQLedu",
    "outputId": "f48d9db5-9d3a-4909-843e-69bb876fddc8"
   },
   "outputs": [],
   "source": [
    "# Max length of target sequence\n",
    "max_length_tar = 0\n",
    "\n",
    "for line in lines.Mar:\n",
    "    if len(line.split(' ')) > max_length_tar:\n",
    "        max_length_tar = len(line.split(' '))\n",
    "        \n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1554793211837,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "Eaj5LOJgLedz",
    "outputId": "745ec89a-5806-48b0-991d-d3a379e18b13"
   },
   "outputs": [],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_mar_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNryqdRvLed3"
   },
   "outputs": [],
   "source": [
    "source_dictionary = english_summary['dictionary']\n",
    "target_dictionary = marathi_summary['dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0bt1VxLLed5"
   },
   "outputs": [],
   "source": [
    "source_reverse_dictionary = english_summary['reverse_dictionary']\n",
    "target_reverse_dictionary = marathi_summary['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1004,
     "status": "ok",
     "timestamp": 1554793218589,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "v9Z2BiygLed9",
    "outputId": "2dcec176-4eb0-4714-f08a-f8956b4ecac7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpwDCXjSLeeC"
   },
   "source": [
    "### 3. Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bUerHhNLeeD"
   },
   "outputs": [],
   "source": [
    "def encode_input(X):\n",
    "    \"\"\"\n",
    "        X = batch of inputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(X)\n",
    "    \n",
    "    # Create a numpy array of zeros to hold input\n",
    "    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(X):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            if word not in source_dictionary.keys():\n",
    "                word = 'UNK'\n",
    "            encoder_input_data[i, t] = source_dictionary[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "        y = batch of outputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(y)\n",
    "    \n",
    "    # Create numpy arrays of zeros to hold encoded targets\n",
    "    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(y):\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if t < len(target_text.split()) - 1:\n",
    "                decoder_input_data[i, t] = target_dictionary[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiOFeb9vLeeH"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size=128):\n",
    "    \"\"\"\n",
    "        X = Source dataset\n",
    "        y = Target dataset\n",
    "        batch_size = Size of each batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_input(X[j:j+batch_size])\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-x4hM2sLeeL"
   },
   "source": [
    "### 4. Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203,
     "status": "ok",
     "timestamp": 1554793226710,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "1UtH1Hp3LeeN",
    "outputId": "a7a88e4a-362e-48dc-9fa7-6381e1121204"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X, y = lines.Eng, lines.Mar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CUiDGfCLeeS"
   },
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6hMfdyQLeeW"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxWNZCbELeeZ"
   },
   "source": [
    "#### 4.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3399,
     "status": "ok",
     "timestamp": 1554793231752,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "aGdBX4MhLeeZ",
    "outputId": "9b49d050-e7ac-4260-ebdf-3c14c4dffebf"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
    "\n",
    "# Embedding Lookup\n",
    "encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[english_summary['embeddings']], \n",
    "                                    name='English_Embedding_Layer')\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "# Keeping only the states and discarding encoder outputs\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqcAW1TRLeed"
   },
   "source": [
    "#### 4.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT4GcwdKLeee"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
    "\n",
    "# Embedding\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[marathi_summary['embeddings']], \n",
    "                                    name='Marathi_Embedding_Layer')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "# Dense output layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zUNups0Leei"
   },
   "outputs": [],
   "source": [
    "# Define a model with these layers\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1772,
     "status": "ok",
     "timestamp": 1554793246122,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "EmPdHO_sLeel",
    "outputId": "045451eb-c79b-40a1-df0d-9fefae62b82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "English_Embedding_Layer (Embedd (None, None, 128)    1117568     Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[0][0]    \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,644,122\n",
      "Trainable params: 4,644,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-Upu1etLeep"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFHzeRT25jMR"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJGZXMmsLeev"
   },
   "outputs": [],
   "source": [
    "# Create checkpoints to save model from time to time\n",
    "filepath = os.path.join(root, 'best_model_en_ma_tl_e.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5360822,
     "status": "ok",
     "timestamp": 1554700772656,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "z-FyOS1lLeey",
    "outputId": "0545c2d6-4e5c-4b31-d63e-933e2639aee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "237/237 [==============================] - 110s 466ms/step - loss: 6.0075 - acc: 0.1985 - val_loss: 5.5365 - val_acc: 0.2245\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.22455, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 5.2119 - acc: 0.2564 - val_loss: 5.0641 - val_acc: 0.2839\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.22455 to 0.28387, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 3/50\n",
      "237/237 [==============================] - 109s 460ms/step - loss: 4.7623 - acc: 0.2995 - val_loss: 4.7215 - val_acc: 0.3208\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.28387 to 0.32084, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 4/50\n",
      "237/237 [==============================] - 111s 467ms/step - loss: 4.3951 - acc: 0.3381 - val_loss: 4.4286 - val_acc: 0.3559\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.32084 to 0.35588, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 5/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 4.0806 - acc: 0.3732 - val_loss: 4.1953 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.35588 to 0.38164, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 6/50\n",
      "237/237 [==============================] - 109s 460ms/step - loss: 3.8081 - acc: 0.4054 - val_loss: 4.0190 - val_acc: 0.4095\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.38164 to 0.40951, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 7/50\n",
      "237/237 [==============================] - 109s 459ms/step - loss: 3.5689 - acc: 0.4333 - val_loss: 3.8496 - val_acc: 0.4329\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.40951 to 0.43289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 8/50\n",
      "237/237 [==============================] - 107s 454ms/step - loss: 3.3554 - acc: 0.4602 - val_loss: 3.6989 - val_acc: 0.4513\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.43289 to 0.45126, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 9/50\n",
      "237/237 [==============================] - 108s 454ms/step - loss: 3.1666 - acc: 0.4855 - val_loss: 3.5884 - val_acc: 0.4642\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.45126 to 0.46421, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 10/50\n",
      "237/237 [==============================] - 109s 458ms/step - loss: 2.9972 - acc: 0.5093 - val_loss: 3.4774 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.46421 to 0.48245, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 11/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 2.8495 - acc: 0.5299 - val_loss: 3.3880 - val_acc: 0.4945\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.48245 to 0.49451, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 12/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 2.7132 - acc: 0.5495 - val_loss: 3.2880 - val_acc: 0.5051\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.49451 to 0.50513, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 13/50\n",
      "237/237 [==============================] - 109s 460ms/step - loss: 2.5881 - acc: 0.5687 - val_loss: 3.2099 - val_acc: 0.5174\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.50513 to 0.51743, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 14/50\n",
      "237/237 [==============================] - 109s 458ms/step - loss: 2.4721 - acc: 0.5864 - val_loss: 3.1375 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.51743 to 0.52760, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 15/50\n",
      "237/237 [==============================] - 106s 449ms/step - loss: 2.3676 - acc: 0.6027 - val_loss: 3.0835 - val_acc: 0.5340\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.52760 to 0.53404, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 16/50\n",
      "237/237 [==============================] - 104s 441ms/step - loss: 2.2744 - acc: 0.6176 - val_loss: 3.0389 - val_acc: 0.5395\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.53404 to 0.53947, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 17/50\n",
      "237/237 [==============================] - 104s 441ms/step - loss: 2.1931 - acc: 0.6310 - val_loss: 3.0162 - val_acc: 0.5447\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.53947 to 0.54472, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 18/50\n",
      "237/237 [==============================] - 105s 442ms/step - loss: 2.1179 - acc: 0.6439 - val_loss: 2.9590 - val_acc: 0.5513\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.54472 to 0.55128, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 19/50\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 2.0515 - acc: 0.6560 - val_loss: 2.9572 - val_acc: 0.5522\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.55128 to 0.55220, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 20/50\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 1.9898 - acc: 0.6670 - val_loss: 2.9443 - val_acc: 0.5557\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.55220 to 0.55575, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 21/50\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 1.9321 - acc: 0.6776 - val_loss: 2.9216 - val_acc: 0.5608\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.55575 to 0.56077, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 22/50\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 1.8804 - acc: 0.6868 - val_loss: 2.8985 - val_acc: 0.5629\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.56077 to 0.56289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 23/50\n",
      "237/237 [==============================] - 106s 447ms/step - loss: 1.8305 - acc: 0.6959 - val_loss: 2.8746 - val_acc: 0.5672\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.56289 to 0.56716, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 24/50\n",
      "237/237 [==============================] - 105s 442ms/step - loss: 1.7846 - acc: 0.7043 - val_loss: 2.8592 - val_acc: 0.5698\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.56716 to 0.56976, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 25/50\n",
      "237/237 [==============================] - 104s 440ms/step - loss: 1.7418 - acc: 0.7131 - val_loss: 2.8493 - val_acc: 0.5735\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.56976 to 0.57354, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 26/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.7013 - acc: 0.7202 - val_loss: 2.8222 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.57354 to 0.58003, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 27/50\n",
      "237/237 [==============================] - 105s 442ms/step - loss: 1.6596 - acc: 0.7274 - val_loss: 2.8289 - val_acc: 0.5771\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.58003\n",
      "Epoch 28/50\n",
      "237/237 [==============================] - 107s 453ms/step - loss: 1.6190 - acc: 0.7339 - val_loss: 2.8040 - val_acc: 0.5811\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.58003 to 0.58106, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 29/50\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 1.5805 - acc: 0.7411 - val_loss: 2.8083 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.58106\n",
      "Epoch 30/50\n",
      "237/237 [==============================] - 108s 456ms/step - loss: 1.5510 - acc: 0.7467 - val_loss: 2.8003 - val_acc: 0.5805\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.58106\n",
      "Epoch 31/50\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 1.5218 - acc: 0.7520 - val_loss: 2.7819 - val_acc: 0.5829\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.58106 to 0.58289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 32/50\n",
      "237/237 [==============================] - 108s 455ms/step - loss: 1.4958 - acc: 0.7572 - val_loss: 2.7751 - val_acc: 0.5859\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.58289 to 0.58590, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 33/50\n",
      "237/237 [==============================] - 108s 454ms/step - loss: 1.4704 - acc: 0.7617 - val_loss: 2.7827 - val_acc: 0.5834\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.58590\n",
      "Epoch 34/50\n",
      "237/237 [==============================] - 108s 456ms/step - loss: 1.4466 - acc: 0.7658 - val_loss: 2.7774 - val_acc: 0.5844\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.58590\n",
      "Epoch 35/50\n",
      "237/237 [==============================] - 108s 456ms/step - loss: 1.4254 - acc: 0.7698 - val_loss: 2.7663 - val_acc: 0.5864\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.58590 to 0.58643, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 36/50\n",
      "237/237 [==============================] - 107s 451ms/step - loss: 1.4056 - acc: 0.7744 - val_loss: 2.7760 - val_acc: 0.5839\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.58643\n",
      "Epoch 37/50\n",
      "237/237 [==============================] - 107s 450ms/step - loss: 1.3855 - acc: 0.7786 - val_loss: 2.7740 - val_acc: 0.5820\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.58643\n",
      "Epoch 38/50\n",
      "237/237 [==============================] - 107s 451ms/step - loss: 1.3681 - acc: 0.7818 - val_loss: 2.7559 - val_acc: 0.5852\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.58643\n",
      "Epoch 39/50\n",
      "237/237 [==============================] - 106s 449ms/step - loss: 1.3497 - acc: 0.7852 - val_loss: 2.7559 - val_acc: 0.5869\n",
      "\n",
      "Epoch 00039: val_acc improved from 0.58643 to 0.58686, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 40/50\n",
      "237/237 [==============================] - 106s 448ms/step - loss: 1.3347 - acc: 0.7884 - val_loss: 2.7522 - val_acc: 0.5845\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.58686\n",
      "Epoch 41/50\n",
      "237/237 [==============================] - 105s 444ms/step - loss: 1.3191 - acc: 0.7913 - val_loss: 2.7400 - val_acc: 0.5892\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.58686 to 0.58920, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 42/50\n",
      "237/237 [==============================] - 105s 441ms/step - loss: 1.3045 - acc: 0.7941 - val_loss: 2.7462 - val_acc: 0.5902\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.58920 to 0.59023, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n",
      "Epoch 43/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.2898 - acc: 0.7968 - val_loss: 2.7496 - val_acc: 0.5877\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.59023\n",
      "Epoch 44/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.2757 - acc: 0.7996 - val_loss: 2.7711 - val_acc: 0.5873\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.59023\n",
      "Epoch 45/50\n",
      "237/237 [==============================] - 103s 437ms/step - loss: 1.2644 - acc: 0.8016 - val_loss: 2.7469 - val_acc: 0.5869\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.59023\n",
      "Epoch 46/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 1.2521 - acc: 0.8038 - val_loss: 2.7739 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.59023\n",
      "Epoch 47/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 1.2379 - acc: 0.8063 - val_loss: 2.7858 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.59023\n",
      "Epoch 48/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.2271 - acc: 0.8085 - val_loss: 2.7709 - val_acc: 0.5867\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.59023\n",
      "Epoch 49/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.2167 - acc: 0.8095 - val_loss: 2.7664 - val_acc: 0.5868\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.59023\n",
      "Epoch 50/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 1.2048 - acc: 0.8117 - val_loss: 2.7639 - val_acc: 0.5861\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.59023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe011426b70>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n",
    "                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRdA-3G8Lee1"
   },
   "source": [
    "#### 4.3 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B6oDJqsLee2"
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(root, 'nmt_weights_en_ma_tl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFYkdLTcLee5"
   },
   "source": [
    "#### 4.4 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvWzXHqHMEe-"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'nmt_weights_en_ma_tl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3s531y3Lee_"
   },
   "source": [
    "### 5. Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZapXObgLefC"
   },
   "outputs": [],
   "source": [
    "# Encoder-decoder model that uses trained weights from the original model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kA9ZktGiLefH"
   },
   "source": [
    "#### 5.1 Inference Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLp33CktLefJ"
   },
   "outputs": [],
   "source": [
    "# Encoder model to create a thought vector from the input\n",
    "inference_encoder = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51w8NazaLefM"
   },
   "source": [
    "#### 5.2 Inference Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQjvRgCPLefN"
   },
   "outputs": [],
   "source": [
    "# For each time step, the decoder states from previous timestep would act as inputs\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Embedding\n",
    "decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n",
    "                                                                               initial_state=decoder_states_inputs)\n",
    "decoder_states_inference = [state_h_inference, state_c_inference]\n",
    "\n",
    "# Dense\n",
    "decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL7B1qchLefP"
   },
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "inference_decoder = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inference] + decoder_states_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1495,
     "status": "ok",
     "timestamp": 1554793294310,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SvR0urBBLefR",
    "outputId": "87e9e85d-48e7-402b-e4b8-93373a8c4127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_Inputs (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "English_Embedding_Layer (Emb (None, None, 128)         1117568   \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 1,249,152\n",
      "Trainable params: 1,249,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1077,
     "status": "ok",
     "timestamp": 1554793296809,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "PH3DCqVjLefV",
    "outputId": "23ccd248-deb9-4e94-ea6b-16df9bfbc936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Output (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Memory (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[1][0]    \n",
      "                                                                 Inference_Decoder_Output[0][0]   \n",
      "                                                                 Inference_Decoder_Memory[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,394,970\n",
      "Trainable params: 3,394,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlo9Ng46LefY"
   },
   "source": [
    "#### 5.3 Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NUGmwBtLefZ"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    # Get thought vector by encoding the input sequence\n",
    "    states_value = inference_encoder.predict(input_sequence)\n",
    "    \n",
    "    # Generate target sequence initialized with <START> character\n",
    "    target_sequence = np.zeros((1, 1))\n",
    "    target_sequence[0, 0] = target_dictionary['<START>']\n",
    "    \n",
    "    # To stop the recurrent loop\n",
    "    stop_condition = False\n",
    "    \n",
    "    # Final sentence\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # Get next prediction\n",
    "        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n",
    "        \n",
    "        # Get the token with max probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_reverse_dictionary[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        # Test for exit condition\n",
    "        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update the target sequence with current prediction\n",
    "        target_sequence = np.zeros((1, 1))\n",
    "        target_sequence[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eehBSrbvLefc"
   },
   "source": [
    "### 6. Evaluation on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1345,
     "status": "ok",
     "timestamp": 1554793582924,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "s2D1wd2NLefl",
    "outputId": "77554d99-9f3c-45a7-b19d-bb7f6f5980be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'माझं नाव आहे'"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = encode_input([''])\n",
    "decoded_sentence = decode_sequence(input_sequence)\n",
    "' '.join(decoded_sentence.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yM-WPO4E6P5H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Eng_Mar_NTL_E.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
