{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27067,
     "status": "ok",
     "timestamp": 1554647017331,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "gwTL36ttLedG",
    "outputId": "524a74cb-b89f-4b2f-d3e7-9efb444b7878"
   },
   "outputs": [],
   "source": [
    "# # To mount Google drive on Google Colab environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root = '/content/drive/My Drive/English Dataset'\n",
    "root = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb0tHTz1LedM"
   },
   "source": [
    "### 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2457,
     "status": "ok",
     "timestamp": 1554647020992,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "92RA6N5fLedO",
    "outputId": "4846f9ac-5957-4d73-ada2-d20e4a7ca872"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5-UJzoBLedS"
   },
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEj_b0VSLedT"
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "lines = pd.read_pickle(os.path.join(root, 'mar-eng_cleaned.parallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1227,
     "status": "ok",
     "timestamp": 1554647030105,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "D787xMeLLedV",
    "outputId": "39f0a78d-49d6-4734-c581-9fda8fd90dcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33725, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of dataset\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsqG7aFTLedd"
   },
   "outputs": [],
   "source": [
    "# Add 'start' and 'end' tokens to target sentences\n",
    "lines.Mar = lines.Mar.apply(lambda x: '<START> ' + x + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1452,
     "status": "ok",
     "timestamp": 1554647034726,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "GbGtP_6VLedh",
    "outputId": "ddd76360-2e94-4837-ce8d-a0319c1c43e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28040</th>\n",
       "      <td>they teach chinese at that school</td>\n",
       "      <td>&lt;START&gt; त्या शाळेत चिनी शिकवतात &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>give me your phone number</td>\n",
       "      <td>&lt;START&gt; मला तुमचा फोन नंबर द्या &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20727</th>\n",
       "      <td>french is my mother tongue</td>\n",
       "      <td>&lt;START&gt; फ्रेंच माझी मातृभाषा आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16168</th>\n",
       "      <td>why is your cat so big</td>\n",
       "      <td>&lt;START&gt; तुझी मांजर इतकी मोठा का आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14358</th>\n",
       "      <td>we havent even tried</td>\n",
       "      <td>&lt;START&gt; आपण तर प्रयत्नही करून बघितला नाहीये &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Eng  \\\n",
       "28040  they teach chinese at that school   \n",
       "19331          give me your phone number   \n",
       "20727         french is my mother tongue   \n",
       "16168             why is your cat so big   \n",
       "14358               we havent even tried   \n",
       "\n",
       "                                                     Mar  \n",
       "28040              <START> त्या शाळेत चिनी शिकवतात <END>  \n",
       "19331              <START> मला तुमचा फोन नंबर द्या <END>  \n",
       "20727             <START> फ्रेंच माझी मातृभाषा आहे <END>  \n",
       "16168          <START> तुझी मांजर इतकी मोठा का आहे <END>  \n",
       "14358  <START> आपण तर प्रयत्नही करून बघितला नाहीये <END>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a few samples of the dataset\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_i-8ssyLedl"
   },
   "outputs": [],
   "source": [
    "# English vocabulary\n",
    "all_eng_words = set()\n",
    "for line in lines.Eng:\n",
    "    for word in line.split():\n",
    "        all_eng_words.add(word)\n",
    "        \n",
    "# Marathi vocabulary\n",
    "all_mar_words = set()\n",
    "for line in lines.Mar:\n",
    "    for word in line.split():\n",
    "        all_mar_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1554647040458,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "7QZaq1bQLedo",
    "outputId": "0b7c956a-c161-471a-e834-e3a17b213e9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of source sequence\n",
    "max_length_src = 0\n",
    "\n",
    "for line in lines.Eng:\n",
    "    if len(line.split(' ')) > max_length_src:\n",
    "        max_length_src = len(line.split(' '))\n",
    "        \n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1554647042449,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SHtikVcQLedu",
    "outputId": "ca0e3cd0-6933-42e2-d638-eef34906ee73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of target sequence\n",
    "max_length_tar = 0\n",
    "\n",
    "for line in lines.Mar:\n",
    "    if len(line.split(' ')) > max_length_tar:\n",
    "        max_length_tar = len(line.split(' '))\n",
    "        \n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1554647045266,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "Eaj5LOJgLedz",
    "outputId": "cc6c7f65-2689-4364-9447-00206f4fac3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5388, 12698)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_mar_words) + 1\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNryqdRvLed3"
   },
   "outputs": [],
   "source": [
    "source_dictionary = dict([(word, i+1) for i, word in enumerate(sorted(all_eng_words))])\n",
    "target_dictionary = dict([(word, i+1) for i, word in enumerate(sorted(all_mar_words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0bt1VxLLed5"
   },
   "outputs": [],
   "source": [
    "source_reverse_dictionary = dict([(i, word) for word, i in source_dictionary.items()])\n",
    "target_reverse_dictionary = dict([(i, word) for word, i in target_dictionary.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 724,
     "status": "ok",
     "timestamp": 1554647050189,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "v9Z2BiygLed9",
    "outputId": "a6f3b8fb-030d-4ab3-9683-bd7873a396cd",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9556</th>\n",
       "      <td>he can play a flute</td>\n",
       "      <td>&lt;START&gt; त्याला बासरी वाजवता येते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20825</th>\n",
       "      <td>how many bags did you have</td>\n",
       "      <td>&lt;START&gt; तुझ्याकडे किती बॅगा होत्या &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25570</th>\n",
       "      <td>i dont want to drink cold tea</td>\n",
       "      <td>&lt;START&gt; मला थंड चहा प्यायचा नाहीये &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12073</th>\n",
       "      <td>nobody will help you</td>\n",
       "      <td>&lt;START&gt; कोणीच तुमची मदत करणार नाही &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>tom had never driven a truck</td>\n",
       "      <td>&lt;START&gt; टॉमने कधीही ट्रक चालवला नव्हता &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32523</th>\n",
       "      <td>historically the persian gulf belongs to iran</td>\n",
       "      <td>&lt;START&gt; ऐतिहासिकदृष्ट्या इराणी आखात हा इराणचा ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13613</th>\n",
       "      <td>i was happy yesterday</td>\n",
       "      <td>&lt;START&gt; मी काल खूष होते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13011</th>\n",
       "      <td>did you like the book</td>\n",
       "      <td>&lt;START&gt; पुस्तक आवडलं का &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31875</th>\n",
       "      <td>tom chased mary all the way to the station</td>\n",
       "      <td>&lt;START&gt; टॉमने मेरीचा स्थानकापर्यंत पाठलाग केला...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5074</th>\n",
       "      <td>i refuse to help</td>\n",
       "      <td>&lt;START&gt; मी मदत करण्यास नकार देतो &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Eng  \\\n",
       "9556                             he can play a flute   \n",
       "20825                     how many bags did you have   \n",
       "25570                  i dont want to drink cold tea   \n",
       "12073                           nobody will help you   \n",
       "23998                   tom had never driven a truck   \n",
       "32523  historically the persian gulf belongs to iran   \n",
       "13613                          i was happy yesterday   \n",
       "13011                          did you like the book   \n",
       "31875     tom chased mary all the way to the station   \n",
       "5074                                i refuse to help   \n",
       "\n",
       "                                                     Mar  \n",
       "9556              <START> त्याला बासरी वाजवता येते <END>  \n",
       "20825           <START> तुझ्याकडे किती बॅगा होत्या <END>  \n",
       "25570           <START> मला थंड चहा प्यायचा नाहीये <END>  \n",
       "12073           <START> कोणीच तुमची मदत करणार नाही <END>  \n",
       "23998       <START> टॉमने कधीही ट्रक चालवला नव्हता <END>  \n",
       "32523  <START> ऐतिहासिकदृष्ट्या इराणी आखात हा इराणचा ...  \n",
       "13613                      <START> मी काल खूष होते <END>  \n",
       "13011                      <START> पुस्तक आवडलं का <END>  \n",
       "31875  <START> टॉमने मेरीचा स्थानकापर्यंत पाठलाग केला...  \n",
       "5074              <START> मी मदत करण्यास नकार देतो <END>  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpwDCXjSLeeC"
   },
   "source": [
    "### 3. Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bUerHhNLeeD"
   },
   "outputs": [],
   "source": [
    "def encode_input(X):\n",
    "    \"\"\"\n",
    "        X = batch of inputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(X)\n",
    "    \n",
    "    # Create a numpy array of zeros to hold input\n",
    "    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(X):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            encoder_input_data[i, t] = source_dictionary[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "        y = batch of outputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(y)\n",
    "    \n",
    "    # Create numpy arrays of zeros to hold encoded targets\n",
    "    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(y):\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if t < len(target_text.split()) - 1:\n",
    "                decoder_input_data[i, t] = target_dictionary[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiOFeb9vLeeH"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size=128):\n",
    "    \"\"\"\n",
    "        X = Source dataset\n",
    "        y = Target dataset\n",
    "        batch_size = Size of each batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_input(X[j:j+batch_size])\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-x4hM2sLeeL"
   },
   "source": [
    "### 4. Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1554647056691,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "1UtH1Hp3LeeN",
    "outputId": "121a81d5-90b8-4370-82be-382ef99891af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30352,), (3373,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "X, y = lines.Eng, lines.Mar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CUiDGfCLeeS"
   },
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6hMfdyQLeeW"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxWNZCbELeeZ"
   },
   "source": [
    "#### 4.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1262,
     "status": "ok",
     "timestamp": 1554647063252,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "aGdBX4MhLeeZ",
    "outputId": "d65a0535-7b7e-4a06-f99c-13e599670e3f"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
    "\n",
    "# Embedding Lookup\n",
    "encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, name='English_Embedding_Layer')\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "# Keeping only the states and discarding encoder outputs\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqcAW1TRLeed"
   },
   "source": [
    "#### 4.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT4GcwdKLeee"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
    "\n",
    "# Embedding\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, name='Marathi_Embedding_Layer')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "# Dense output layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zUNups0Leei"
   },
   "outputs": [],
   "source": [
    "# Define a model with these layers\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('nmt_weights_mar_en_NTL_NE.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1554647070780,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "EmPdHO_sLeel",
    "outputId": "45188734-773f-4f40-a0b7-545b6d3d703f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "English_Embedding_Layer (Embedd (None, None, 128)    689664      Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[0][0]    \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,216,218\n",
      "Trainable params: 4,216,218\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-Upu1etLeep"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJGZXMmsLeev"
   },
   "outputs": [],
   "source": [
    "# Create checkpoints to save model from time to time\n",
    "filepath = os.path.join(root, 'best_model_en_ma.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3725559,
     "status": "ok",
     "timestamp": 1554652290308,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "z-FyOS1lLeey",
    "outputId": "ba55301a-8dca-43c2-b2a2-eedb123dab9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "237/237 [==============================] - 107s 454ms/step - loss: 6.0456 - acc: 0.1947 - val_loss: 5.5243 - val_acc: 0.2194\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.21940, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 5.2911 - acc: 0.2394 - val_loss: 5.1407 - val_acc: 0.2616\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.21940 to 0.26159, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 3/50\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 4.9254 - acc: 0.2734 - val_loss: 4.8531 - val_acc: 0.2914\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.26159 to 0.29135, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 4/50\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 4.6141 - acc: 0.3037 - val_loss: 4.6092 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.29135 to 0.32243, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 5/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 4.3319 - acc: 0.3381 - val_loss: 4.4380 - val_acc: 0.3465\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.32243 to 0.34649, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 6/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 4.0803 - acc: 0.3674 - val_loss: 4.2341 - val_acc: 0.3736\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.34649 to 0.37357, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 7/50\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 3.8561 - acc: 0.3937 - val_loss: 4.0624 - val_acc: 0.3945\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.37357 to 0.39446, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 8/50\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 3.6492 - acc: 0.4184 - val_loss: 3.9050 - val_acc: 0.4192\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.39446 to 0.41920, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 9/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 3.4563 - acc: 0.4419 - val_loss: 3.7722 - val_acc: 0.4355\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.41920 to 0.43550, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 10/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 3.2802 - acc: 0.4640 - val_loss: 3.6361 - val_acc: 0.4532\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.43550 to 0.45319, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 11/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 3.1195 - acc: 0.4850 - val_loss: 3.5410 - val_acc: 0.4676\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.45319 to 0.46758, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 12/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 2.9742 - acc: 0.5058 - val_loss: 3.4520 - val_acc: 0.4760\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.46758 to 0.47597, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 13/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 2.8460 - acc: 0.5250 - val_loss: 3.3833 - val_acc: 0.4905\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.47597 to 0.49054, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 14/50\n",
      "237/237 [==============================] - 103s 434ms/step - loss: 2.7289 - acc: 0.5424 - val_loss: 3.3035 - val_acc: 0.4980\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.49054 to 0.49801, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 15/50\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 2.6218 - acc: 0.5593 - val_loss: 3.2245 - val_acc: 0.5112\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.49801 to 0.51119, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 16/50\n",
      "237/237 [==============================] - 103s 437ms/step - loss: 2.5196 - acc: 0.5747 - val_loss: 3.1717 - val_acc: 0.5192\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.51119 to 0.51917, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 17/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 2.4259 - acc: 0.5899 - val_loss: 3.1154 - val_acc: 0.5283\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.51917 to 0.52831, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 18/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 2.3421 - acc: 0.6039 - val_loss: 3.0873 - val_acc: 0.5326\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.52831 to 0.53257, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 19/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 2.2692 - acc: 0.6173 - val_loss: 3.0502 - val_acc: 0.5395\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.53257 to 0.53952, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 20/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 2.2000 - acc: 0.6296 - val_loss: 3.0080 - val_acc: 0.5449\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.53952 to 0.54492, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 21/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 2.1356 - acc: 0.6414 - val_loss: 2.9727 - val_acc: 0.5501\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.54492 to 0.55015, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 22/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 2.0752 - acc: 0.6521 - val_loss: 2.9401 - val_acc: 0.5545\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.55015 to 0.55449, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 23/50\n",
      "237/237 [==============================] - 104s 441ms/step - loss: 2.0188 - acc: 0.6625 - val_loss: 2.9219 - val_acc: 0.5573\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.55449 to 0.55731, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 24/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.9663 - acc: 0.6718 - val_loss: 2.9078 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.55731 to 0.56087, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 25/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.9174 - acc: 0.6806 - val_loss: 2.8868 - val_acc: 0.5634\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.56087 to 0.56343, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 26/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.8711 - acc: 0.6888 - val_loss: 2.8719 - val_acc: 0.5665\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.56343 to 0.56654, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 27/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 1.8265 - acc: 0.6974 - val_loss: 2.8605 - val_acc: 0.5680\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.56654 to 0.56801, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 28/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 1.7850 - acc: 0.7048 - val_loss: 2.8446 - val_acc: 0.5705\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.56801 to 0.57050, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 29/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.7460 - acc: 0.7115 - val_loss: 2.8293 - val_acc: 0.5734\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.57050 to 0.57335, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 30/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.7103 - acc: 0.7183 - val_loss: 2.8285 - val_acc: 0.5730\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.57335\n",
      "Epoch 31/50\n",
      "237/237 [==============================] - 103s 435ms/step - loss: 1.6755 - acc: 0.7253 - val_loss: 2.8124 - val_acc: 0.5741\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.57335 to 0.57410, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 32/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.6429 - acc: 0.7310 - val_loss: 2.8167 - val_acc: 0.5746\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.57410 to 0.57465, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 33/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.6140 - acc: 0.7366 - val_loss: 2.8061 - val_acc: 0.5774\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.57465 to 0.57736, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 34/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.5864 - acc: 0.7417 - val_loss: 2.7937 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.57736 to 0.57992, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 35/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 1.5578 - acc: 0.7468 - val_loss: 2.7949 - val_acc: 0.5783\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.57992\n",
      "Epoch 36/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.5312 - acc: 0.7508 - val_loss: 2.7887 - val_acc: 0.5784\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.57992\n",
      "Epoch 37/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.5082 - acc: 0.7550 - val_loss: 2.7719 - val_acc: 0.5793\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.57992\n",
      "Epoch 38/50\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 1.4847 - acc: 0.7598 - val_loss: 2.7905 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.57992\n",
      "Epoch 39/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.4625 - acc: 0.7640 - val_loss: 2.7866 - val_acc: 0.5789\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.57992\n",
      "Epoch 40/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 1.4408 - acc: 0.7678 - val_loss: 2.7813 - val_acc: 0.5786\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.57992\n",
      "Epoch 41/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.4198 - acc: 0.7717 - val_loss: 2.7715 - val_acc: 0.5822\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.57992 to 0.58224, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 42/50\n",
      "237/237 [==============================] - 104s 437ms/step - loss: 1.4012 - acc: 0.7746 - val_loss: 2.7492 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.58224 to 0.58600, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 43/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.3833 - acc: 0.7789 - val_loss: 2.7531 - val_acc: 0.5854\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.58600\n",
      "Epoch 44/50\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 1.3679 - acc: 0.7812 - val_loss: 2.7485 - val_acc: 0.5859\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.58600\n",
      "Epoch 45/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.3540 - acc: 0.7838 - val_loss: 2.7604 - val_acc: 0.5836\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.58600\n",
      "Epoch 46/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.3390 - acc: 0.7864 - val_loss: 2.7697 - val_acc: 0.5837\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.58600\n",
      "Epoch 47/50\n",
      "237/237 [==============================] - 104s 439ms/step - loss: 1.3245 - acc: 0.7888 - val_loss: 2.7528 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.58600\n",
      "Epoch 48/50\n",
      "237/237 [==============================] - 103s 436ms/step - loss: 1.3091 - acc: 0.7910 - val_loss: 2.7543 - val_acc: 0.5863\n",
      "\n",
      "Epoch 00048: val_acc improved from 0.58600 to 0.58628, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n",
      "Epoch 49/50\n",
      "237/237 [==============================] - 104s 438ms/step - loss: 1.2953 - acc: 0.7947 - val_loss: 2.7581 - val_acc: 0.5843\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.58628\n",
      "Epoch 50/50\n",
      "237/237 [==============================] - 104s 440ms/step - loss: 1.2805 - acc: 0.7972 - val_loss: 2.7667 - val_acc: 0.5843\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.58628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f85ab064be0>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n",
    "                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRdA-3G8Lee1"
   },
   "source": [
    "#### 4.3 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B6oDJqsLee2"
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(root, 'nmt_weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFYkdLTcLee5"
   },
   "source": [
    "#### 4.4 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvWzXHqHMEe-"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'nmt_weights.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3s531y3Lee_"
   },
   "source": [
    "### 5. Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZapXObgLefC"
   },
   "outputs": [],
   "source": [
    "# Encoder-decoder model that uses trained weights from the original model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kA9ZktGiLefH"
   },
   "source": [
    "#### 5.1 Inference Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLp33CktLefJ"
   },
   "outputs": [],
   "source": [
    "# Encoder model to create a thought vector from the input\n",
    "inference_encoder = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51w8NazaLefM"
   },
   "source": [
    "#### 5.2 Inference Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQjvRgCPLefN"
   },
   "outputs": [],
   "source": [
    "# For each time step, the decoder states from previous timestep would act as inputs\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Embedding\n",
    "decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n",
    "                                                                               initial_state=decoder_states_inputs)\n",
    "decoder_states_inference = [state_h_inference, state_c_inference]\n",
    "\n",
    "# Dense\n",
    "decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL7B1qchLefP"
   },
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "inference_decoder = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inference] + decoder_states_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1206,
     "status": "ok",
     "timestamp": 1554652319063,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SvR0urBBLefR",
    "outputId": "30f6e780-dbd7-4331-fdf3-46fb54438193"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_Inputs (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "English_Embedding_Layer (Emb (None, None, 128)         689664    \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 821,248\n",
      "Trainable params: 821,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1358,
     "status": "ok",
     "timestamp": 1554652322955,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "PH3DCqVjLefV",
    "outputId": "d30f547b-f9a6-46e1-8e75-a3832fe65167"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Output (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Memory (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[1][0]    \n",
      "                                                                 Inference_Decoder_Output[0][0]   \n",
      "                                                                 Inference_Decoder_Memory[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,394,970\n",
      "Trainable params: 3,394,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlo9Ng46LefY"
   },
   "source": [
    "#### 5.3 Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NUGmwBtLefZ"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    # Get thought vector by encoding the input sequence\n",
    "    states_value = inference_encoder.predict(input_sequence)\n",
    "    \n",
    "    # Generate target sequence initialized with <START> character\n",
    "    target_sequence = np.zeros((1, 1))\n",
    "    target_sequence[0, 0] = target_dictionary['<START>']\n",
    "    \n",
    "    # To stop the recurrent loop\n",
    "    stop_condition = False\n",
    "    \n",
    "    # Final sentence\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # Get next prediction\n",
    "        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n",
    "        \n",
    "        # Get the token with max probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_reverse_dictionary[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        # Test for exit condition\n",
    "        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update the target sequence with current prediction\n",
    "        target_sequence = np.zeros((1, 1))\n",
    "        target_sequence[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eehBSrbvLefc"
   },
   "source": [
    "### 6. Evaluation on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1582,
     "status": "ok",
     "timestamp": 1554652407029,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "s2D1wd2NLefl",
    "outputId": "93119a2c-7b4c-46ee-ebd4-dde6114250bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'मी परदेशात गेले'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = encode_input(['i went abroad'])\n",
    "decoded_sentence = decode_sequence(input_sequence)\n",
    "' '.join(decoded_sentence.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Eng_Mar_NTL_NE.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
