{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2158,
     "status": "ok",
     "timestamp": 1554652971324,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "gwTL36ttLedG",
    "outputId": "a6351883-bc95-422c-a497-7594c2df07f7"
   },
   "outputs": [],
   "source": [
    "# To mount Google drive on Google Colab environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root = '/content/drive/My Drive/English Dataset'\n",
    "root = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb0tHTz1LedM"
   },
   "source": [
    "### 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2475,
     "status": "ok",
     "timestamp": 1554652977193,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "92RA6N5fLedO",
    "outputId": "8fd27a36-0b47-4c21-acce-4d4add299b85"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5-UJzoBLedS"
   },
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEj_b0VSLedT"
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "lines = pd.read_pickle(os.path.join(root, 'hin-eng_cleaned.parallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 919,
     "status": "ok",
     "timestamp": 1554652981442,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "D787xMeLLedV",
    "outputId": "725ab20b-63da-4049-a1fa-d232f4b7a44a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67700, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of dataset\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsqG7aFTLedd"
   },
   "outputs": [],
   "source": [
    "# Add 'start' and 'end' tokens to target sentences\n",
    "lines.Hin = lines.Hin.apply(lambda x: '<START> ' + x + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1554652985113,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "GbGtP_6VLedh",
    "outputId": "78ccbf60-1aad-43b1-aab4-8baef87b5147"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Hin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31734</th>\n",
       "      <td>composer</td>\n",
       "      <td>&lt;START&gt; लेखकः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54662</th>\n",
       "      <td>close</td>\n",
       "      <td>&lt;START&gt; बंद करें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42118</th>\n",
       "      <td>the object controlling the layout of an actor ...</td>\n",
       "      <td>&lt;START&gt; कर्ता के बच्चों के खाका को नियंत्रित क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66632</th>\n",
       "      <td>images</td>\n",
       "      <td>&lt;START&gt; छवियाँ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29481</th>\n",
       "      <td>you do not have the required permission to wri...</td>\n",
       "      <td>&lt;START&gt; आप को इस स्थान पर लिखने के लिए जरूरी अ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Eng  \\\n",
       "31734                                           composer   \n",
       "54662                                              close   \n",
       "42118  the object controlling the layout of an actor ...   \n",
       "66632                                             images   \n",
       "29481  you do not have the required permission to wri...   \n",
       "\n",
       "                                                     Hin  \n",
       "31734                                <START> लेखकः <END>  \n",
       "54662                             <START> बंद करें <END>  \n",
       "42118  <START> कर्ता के बच्चों के खाका को नियंत्रित क...  \n",
       "66632                               <START> छवियाँ <END>  \n",
       "29481  <START> आप को इस स्थान पर लिखने के लिए जरूरी अ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a few samples of the dataset\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './embeddings.en'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b6a79d5b4699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get vocabulary and embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embeddings.en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0menglish_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embeddings.hi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './embeddings.en'"
     ]
    }
   ],
   "source": [
    "# Get vocabulary and embeddings\n",
    "with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n",
    "    english_summary = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(root, 'embeddings.hi'), 'rb') as f:\n",
    "    hindi_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to dictionary\n",
    "for word in ['<START>', '<END>']:\n",
    "    l = len(hindi_summary['dictionary'].keys())\n",
    "    hindi_summary['dictionary'][word] = l\n",
    "    hindi_summary['reverse_dictionary'][l] = word\n",
    "    hindi_summary['embeddings'] = np.vstack((hindi_summary['embeddings'], np.zeros((1, hindi_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_i-8ssyLedl"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'english_summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a422e2819151>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# English vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_eng_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menglish_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dictionary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Hin vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_hin_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhindi_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dictionary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'english_summary' is not defined"
     ]
    }
   ],
   "source": [
    "# English vocabulary\n",
    "all_eng_words = set(list(english_summary['dictionary'].keys()))\n",
    "        \n",
    "# Hin vocabulary\n",
    "all_hin_words = set(list(hindi_summary['dictionary'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1554652999101,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "7QZaq1bQLedo",
    "outputId": "ed4d12d1-0f0e-4c91-8a78-fd9694bae16b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of source sequence\n",
    "max_length_src = 0\n",
    "\n",
    "for line in lines.Eng:\n",
    "    if len(line.split(' ')) > max_length_src:\n",
    "        max_length_src = len(line.split(' '))\n",
    "        \n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104,
     "status": "ok",
     "timestamp": 1554653000822,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SHtikVcQLedu",
    "outputId": "81f7a228-5dba-4173-c6b2-8e0de653d5df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of target sequence\n",
    "max_length_tar = 0\n",
    "\n",
    "for line in lines.Hin:\n",
    "    if len(line.split(' ')) > max_length_tar:\n",
    "        max_length_tar = len(line.split(' '))\n",
    "        \n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1554653011329,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "Eaj5LOJgLedz",
    "outputId": "cb154221-4a06-4a6f-adb1-f4f47f897f34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5770, 6566)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hin_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNryqdRvLed3"
   },
   "outputs": [],
   "source": [
    "source_dictionary = english_summary['dictionary']\n",
    "target_dictionary = marathi_summary['dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0bt1VxLLed5"
   },
   "outputs": [],
   "source": [
    "source_reverse_dictionary = english_summary['reverse_dictionary']\n",
    "target_reverse_dictionary = marathi_summary['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1469,
     "status": "ok",
     "timestamp": 1554653032760,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "v9Z2BiygLed9",
    "outputId": "682317b5-fc7a-491c-c2e8-85b2aff3e4fb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Hin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>class name</td>\n",
       "      <td>&lt;START&gt; वर्ग नामः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48007</th>\n",
       "      <td>consult the balance history</td>\n",
       "      <td>&lt;START&gt; शेष इतिहास से सलाह लें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52049</th>\n",
       "      <td>preview</td>\n",
       "      <td>&lt;START&gt; पूर्वावलोकन &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41521</th>\n",
       "      <td>vertical fill</td>\n",
       "      <td>&lt;START&gt; लंबवत भरण &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47931</th>\n",
       "      <td>the default video view</td>\n",
       "      <td>&lt;START&gt; मूलभूत वीडियो दृश्य &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>clear</td>\n",
       "      <td>&lt;START&gt; साफ़ करें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49202</th>\n",
       "      <td>looking for work</td>\n",
       "      <td>&lt;START&gt; काम की तलाश &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19410</th>\n",
       "      <td>reset</td>\n",
       "      <td>&lt;START&gt; रीसेट &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48831</th>\n",
       "      <td>place windows displaying video above other win...</td>\n",
       "      <td>&lt;START&gt; कॉल के दौरान अन्य विंडो के ऊपर वीडियो ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62076</th>\n",
       "      <td>chinese simplified hz</td>\n",
       "      <td>&lt;START&gt; चीनी सरल &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Eng  \\\n",
       "22572                                         class name   \n",
       "48007                        consult the balance history   \n",
       "52049                                            preview   \n",
       "41521                                      vertical fill   \n",
       "47931                             the default video view   \n",
       "24992                                              clear   \n",
       "49202                                   looking for work   \n",
       "19410                                              reset   \n",
       "48831  place windows displaying video above other win...   \n",
       "62076                              chinese simplified hz   \n",
       "\n",
       "                                                     Hin  \n",
       "22572                            <START> वर्ग नामः <END>  \n",
       "48007               <START> शेष इतिहास से सलाह लें <END>  \n",
       "52049                          <START> पूर्वावलोकन <END>  \n",
       "41521                            <START> लंबवत भरण <END>  \n",
       "47931                  <START> मूलभूत वीडियो दृश्य <END>  \n",
       "24992                            <START> साफ़ करें <END>  \n",
       "49202                          <START> काम की तलाश <END>  \n",
       "19410                                <START> रीसेट <END>  \n",
       "48831  <START> कॉल के दौरान अन्य विंडो के ऊपर वीडियो ...  \n",
       "62076                             <START> चीनी सरल <END>  "
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpwDCXjSLeeC"
   },
   "source": [
    "### 3. Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bUerHhNLeeD"
   },
   "outputs": [],
   "source": [
    "def encode_input(X):\n",
    "    \"\"\"\n",
    "        X = batch of inputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(X)\n",
    "    \n",
    "    # Create a numpy array of zeros to hold input\n",
    "    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(X):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            if word not in source_dictionary.keys():\n",
    "                word = 'UNK'\n",
    "            encoder_input_data[i, t] = source_dictionary[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "        y = batch of outputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(y)\n",
    "    \n",
    "    # Create numpy arrays of zeros to hold encoded targets\n",
    "    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(y):\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if t < len(target_text.split()) - 1:\n",
    "                decoder_input_data[i, t] = target_dictionary[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiOFeb9vLeeH"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size=128):\n",
    "    \"\"\"\n",
    "        X = Source dataset\n",
    "        y = Target dataset\n",
    "        batch_size = Size of each batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_input(X[j:j+batch_size])\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-x4hM2sLeeL"
   },
   "source": [
    "### 4. Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 879,
     "status": "ok",
     "timestamp": 1554653038014,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "1UtH1Hp3LeeN",
    "outputId": "5f191013-4d92-4fe8-da92-db2df760e7e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60930,), (6770,))"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "X, y = lines.Eng, lines.Hin\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CUiDGfCLeeS"
   },
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6hMfdyQLeeW"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxWNZCbELeeZ"
   },
   "source": [
    "#### 4.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1554653044520,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "aGdBX4MhLeeZ",
    "outputId": "01fbd4a3-8d23-4092-95fd-c455dba37e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
    "\n",
    "# Embedding Lookup\n",
    "encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[english_summary['embeddings']], \n",
    "                                    name='English_Embedding_Layer_NT')\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "# Keeping only the states and discarding encoder outputs\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqcAW1TRLeed"
   },
   "source": [
    "#### 4.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT4GcwdKLeee"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
    "\n",
    "# Embedding\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[hindi_summary['embeddings']], \n",
    "                                    name='Hindi_Embedding_Layer_NT')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "# Dense output layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense_NT')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zUNups0Leei"
   },
   "outputs": [],
   "source": [
    "# Define a model with these layers\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1082,
     "status": "ok",
     "timestamp": 1554653051305,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "EmPdHO_sLeel",
    "outputId": "50b80a86-b401-40d5-ee75-5e1a6f44a170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "English_Embedding_Layer_2 (Embe (None, None, 128)    738560      Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Hindi_Embedding_Layer (Embeddin (None, None, 128)    840448      Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Hindi_Embedding_Layer[0][0]      \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense_2 (Dense)         (None, None, 6566)   847014      Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 2,689,190\n",
      "Trainable params: 2,689,190\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-Upu1etLeep"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJGZXMmsLeev"
   },
   "outputs": [],
   "source": [
    "# Create checkpoints to save model from time to time\n",
    "filepath = os.path.join(root, 'best_model_en_hi_ntl_e.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11284745,
     "status": "ok",
     "timestamp": 1554664348667,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "z-FyOS1lLeey",
    "outputId": "9b783f76-2db1-445d-e563-39095843e113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "476/476 [==============================] - 229s 481ms/step - loss: 5.4710 - acc: 0.2109 - val_loss: 4.9447 - val_acc: 0.2355\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.23552, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 4.6158 - acc: 0.2681 - val_loss: 4.2928 - val_acc: 0.3046\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.23552 to 0.30464, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 3/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 3.9866 - acc: 0.3415 - val_loss: 3.7368 - val_acc: 0.3748\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.30464 to 0.37480, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 4/50\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 3.4493 - acc: 0.4165 - val_loss: 3.2682 - val_acc: 0.4552\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.37480 to 0.45520, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 5/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 2.9941 - acc: 0.4891 - val_loss: 2.8882 - val_acc: 0.5146\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.45520 to 0.51465, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 6/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 2.6086 - acc: 0.5533 - val_loss: 2.5562 - val_acc: 0.5739\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.51465 to 0.57388, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 7/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 2.2849 - acc: 0.6104 - val_loss: 2.2944 - val_acc: 0.6241\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.57388 to 0.62406, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 8/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 2.0118 - acc: 0.6600 - val_loss: 2.0507 - val_acc: 0.6670\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.62406 to 0.66696, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 9/50\n",
      "476/476 [==============================] - 228s 478ms/step - loss: 1.7821 - acc: 0.7041 - val_loss: 1.8640 - val_acc: 0.7026\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.66696 to 0.70259, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 10/50\n",
      "476/476 [==============================] - 227s 477ms/step - loss: 1.6001 - acc: 0.7400 - val_loss: 1.7165 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.70259 to 0.73266, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 11/50\n",
      "476/476 [==============================] - 225s 474ms/step - loss: 1.4490 - acc: 0.7690 - val_loss: 1.5982 - val_acc: 0.7546\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.73266 to 0.75458, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 12/50\n",
      "476/476 [==============================] - 225s 474ms/step - loss: 1.3247 - acc: 0.7935 - val_loss: 1.5042 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.75458 to 0.77397, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 13/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 1.2204 - acc: 0.8125 - val_loss: 1.4181 - val_acc: 0.7921\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.77397 to 0.79207, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 14/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 1.1338 - acc: 0.8293 - val_loss: 1.3466 - val_acc: 0.8051\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.79207 to 0.80513, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 15/50\n",
      "476/476 [==============================] - 225s 474ms/step - loss: 1.0620 - acc: 0.8421 - val_loss: 1.2835 - val_acc: 0.8170\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.80513 to 0.81704, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 16/50\n",
      "476/476 [==============================] - 227s 477ms/step - loss: 1.0003 - acc: 0.8531 - val_loss: 1.2342 - val_acc: 0.8266\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.81704 to 0.82658, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 17/50\n",
      "476/476 [==============================] - 227s 478ms/step - loss: 0.9488 - acc: 0.8621 - val_loss: 1.1974 - val_acc: 0.8341\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.82658 to 0.83413, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 18/50\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 0.9037 - acc: 0.8696 - val_loss: 1.1739 - val_acc: 0.8387\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.83413 to 0.83867, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 19/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.8646 - acc: 0.8767 - val_loss: 1.1318 - val_acc: 0.8434\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.83867 to 0.84341, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 20/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 0.8301 - acc: 0.8821 - val_loss: 1.1025 - val_acc: 0.8493\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.84341 to 0.84927, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 21/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.8002 - acc: 0.8869 - val_loss: 1.0802 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.84927 to 0.85287, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 22/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.7729 - acc: 0.8916 - val_loss: 1.0665 - val_acc: 0.8572\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.85287 to 0.85720, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 23/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.7483 - acc: 0.8957 - val_loss: 1.0527 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.85720 to 0.85850, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 24/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.7258 - acc: 0.8992 - val_loss: 1.0375 - val_acc: 0.8618\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.85850 to 0.86184, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 25/50\n",
      "476/476 [==============================] - 225s 474ms/step - loss: 0.7052 - acc: 0.9027 - val_loss: 1.0203 - val_acc: 0.8647\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.86184 to 0.86467, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 26/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.6854 - acc: 0.9057 - val_loss: 0.9987 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.86467 to 0.86695, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 27/50\n",
      "476/476 [==============================] - 224s 472ms/step - loss: 0.6696 - acc: 0.9084 - val_loss: 1.0025 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00027: val_acc improved from 0.86695 to 0.86770, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 28/50\n",
      "476/476 [==============================] - 223s 468ms/step - loss: 0.6540 - acc: 0.9110 - val_loss: 0.9827 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.86770 to 0.87017, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 29/50\n",
      "476/476 [==============================] - 222s 466ms/step - loss: 0.6387 - acc: 0.9130 - val_loss: 0.9783 - val_acc: 0.8715\n",
      "\n",
      "Epoch 00029: val_acc improved from 0.87017 to 0.87148, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 30/50\n",
      "476/476 [==============================] - 222s 467ms/step - loss: 0.6251 - acc: 0.9150 - val_loss: 0.9654 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.87148 to 0.87237, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 31/50\n",
      "476/476 [==============================] - 220s 463ms/step - loss: 0.6125 - acc: 0.9169 - val_loss: 0.9509 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.87237 to 0.87484, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 32/50\n",
      "476/476 [==============================] - 221s 465ms/step - loss: 0.5987 - acc: 0.9190 - val_loss: 0.9453 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.87484 to 0.87546, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 33/50\n",
      "476/476 [==============================] - 224s 471ms/step - loss: 0.5862 - acc: 0.9207 - val_loss: 0.9441 - val_acc: 0.8768\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.87546 to 0.87679, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 34/50\n",
      "476/476 [==============================] - 224s 471ms/step - loss: 0.5785 - acc: 0.9217 - val_loss: 0.9367 - val_acc: 0.8780\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.87679 to 0.87797, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 35/50\n",
      "476/476 [==============================] - 224s 471ms/step - loss: 0.5700 - acc: 0.9232 - val_loss: 0.9284 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.87797 to 0.87813, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 36/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.5613 - acc: 0.9244 - val_loss: 0.9163 - val_acc: 0.8802\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.87813 to 0.88021, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 37/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 0.5522 - acc: 0.9258 - val_loss: 0.9167 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.88021 to 0.88046, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 38/50\n",
      "476/476 [==============================] - 224s 471ms/step - loss: 0.5442 - acc: 0.9269 - val_loss: 0.9127 - val_acc: 0.8814\n",
      "\n",
      "Epoch 00038: val_acc improved from 0.88046 to 0.88141, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 39/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 0.5357 - acc: 0.9284 - val_loss: 0.9122 - val_acc: 0.8811\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.88141\n",
      "Epoch 40/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.5288 - acc: 0.9293 - val_loss: 0.9087 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.88141\n",
      "Epoch 41/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.5210 - acc: 0.9307 - val_loss: 0.9021 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.88141 to 0.88274, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 42/50\n",
      "476/476 [==============================] - 225s 472ms/step - loss: 0.5141 - acc: 0.9313 - val_loss: 0.8975 - val_acc: 0.8827\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.88274\n",
      "Epoch 43/50\n",
      "476/476 [==============================] - 224s 471ms/step - loss: 0.5075 - acc: 0.9322 - val_loss: 0.8910 - val_acc: 0.8832\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.88274 to 0.88325, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 44/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.5004 - acc: 0.9333 - val_loss: 0.8737 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.88325 to 0.88695, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 45/50\n",
      "476/476 [==============================] - 226s 474ms/step - loss: 0.4952 - acc: 0.9338 - val_loss: 0.8741 - val_acc: 0.8872\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.88695 to 0.88724, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi.hdf5\n",
      "Epoch 46/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.4891 - acc: 0.9345 - val_loss: 0.8738 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.88724\n",
      "Epoch 47/50\n",
      "476/476 [==============================] - 226s 475ms/step - loss: 0.4832 - acc: 0.9356 - val_loss: 0.8702 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.88724\n",
      "Epoch 48/50\n",
      "476/476 [==============================] - 227s 477ms/step - loss: 0.4784 - acc: 0.9361 - val_loss: 0.8809 - val_acc: 0.8860\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.88724\n",
      "Epoch 49/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.4733 - acc: 0.9369 - val_loss: 0.8738 - val_acc: 0.8863\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.88724\n",
      "Epoch 50/50\n",
      "476/476 [==============================] - 225s 473ms/step - loss: 0.4680 - acc: 0.9380 - val_loss: 0.8732 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.88724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb03105ecf8>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n",
    "                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRdA-3G8Lee1"
   },
   "source": [
    "#### 4.3 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B6oDJqsLee2"
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFYkdLTcLee5"
   },
   "source": [
    "#### 4.4 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvWzXHqHMEe-"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3s531y3Lee_"
   },
   "source": [
    "### 5. Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZapXObgLefC"
   },
   "outputs": [],
   "source": [
    "# Encoder-decoder model that uses trained weights from the original model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kA9ZktGiLefH"
   },
   "source": [
    "#### 5.1 Inference Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLp33CktLefJ"
   },
   "outputs": [],
   "source": [
    "# Encoder model to create a thought vector from the input\n",
    "inference_encoder = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51w8NazaLefM"
   },
   "source": [
    "#### 5.2 Inference Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQjvRgCPLefN"
   },
   "outputs": [],
   "source": [
    "# For each time step, the decoder states from previous timestep would act as inputs\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Embedding\n",
    "decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n",
    "                                                                               initial_state=decoder_states_inputs)\n",
    "decoder_states_inference = [state_h_inference, state_c_inference]\n",
    "\n",
    "# Dense\n",
    "decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL7B1qchLefP"
   },
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "inference_decoder = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inference] + decoder_states_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1554689261447,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SvR0urBBLefR",
    "outputId": "b8eb7bfb-a3e1-4270-8ebc-20950994142c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_Inputs (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "English_Embedding_Layer_2 (E (None, None, 128)         738560    \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 870,144\n",
      "Trainable params: 870,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1554689263138,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "PH3DCqVjLefV",
    "outputId": "a8b4afdd-7a42-46e8-ab7a-8e2a9320f37c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Hindi_Embedding_Layer (Embeddin (None, None, 128)    840448      Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Output (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Memory (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Hindi_Embedding_Layer[2][0]      \n",
      "                                                                 Inference_Decoder_Output[0][0]   \n",
      "                                                                 Inference_Decoder_Memory[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense_2 (Dense)         (None, None, 6566)   847014      Decoder_LSTM[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,819,046\n",
      "Trainable params: 1,819,046\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlo9Ng46LefY"
   },
   "source": [
    "#### 5.3 Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NUGmwBtLefZ"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    # Get thought vector by encoding the input sequence\n",
    "    states_value = inference_encoder.predict(input_sequence)\n",
    "    \n",
    "    # Generate target sequence initialized with <START> character\n",
    "    target_sequence = np.zeros((1, 1))\n",
    "    target_sequence[0, 0] = target_dictionary['<START>']\n",
    "    \n",
    "    # To stop the recurrent loop\n",
    "    stop_condition = False\n",
    "    \n",
    "    # Final sentence\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # Get next prediction\n",
    "        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n",
    "        \n",
    "        # Get the token with max probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_reverse_dictionary[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        # Test for exit condition\n",
    "        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update the target sequence with current prediction\n",
    "        target_sequence = np.zeros((1, 1))\n",
    "        target_sequence[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eehBSrbvLefc"
   },
   "source": [
    "### 6. Evaluation on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1402,
     "status": "ok",
     "timestamp": 1554689397333,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "s2D1wd2NLefl",
    "outputId": "e20823d9-46d7-4784-efcf-a2eb21d1157e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'काम की जवाब'"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = encode_input(['looking for work'])\n",
    "decoded_sentence = decode_sequence(input_sequence)\n",
    "' '.join(decoded_sentence.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApsARXqWtUcj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Eng_Hin_NTL_NE.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
