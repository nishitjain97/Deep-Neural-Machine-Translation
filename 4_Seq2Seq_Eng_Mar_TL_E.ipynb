{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1073,
     "status": "ok",
     "timestamp": 1554820002362,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "gwTL36ttLedG",
    "outputId": "2f084d19-58f1-401f-c7bb-0972662a09b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# To mount Google drive on Google Colab environment\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "root = '/content/drive/My Drive/English Dataset'\n",
    "# root = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eb0tHTz1LedM"
   },
   "source": [
    "### 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1813,
     "status": "ok",
     "timestamp": 1554820008530,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "92RA6N5fLedO",
    "outputId": "898f9564-9241-4467-e19c-5eedfddcc9fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from string import digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5-UJzoBLedS"
   },
   "source": [
    "### 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEj_b0VSLedT"
   },
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "lines = pd.read_pickle(os.path.join(root, 'mar-eng_cleaned.parallel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 866,
     "status": "ok",
     "timestamp": 1554820013477,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "D787xMeLLedV",
    "outputId": "5e35f87c-be4f-46e2-89ad-be8303a788e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33725, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the shape of dataset\n",
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsqG7aFTLedd"
   },
   "outputs": [],
   "source": [
    "# Add 'start' and 'end' tokens to target sentences\n",
    "lines.Mar = lines.Mar.apply(lambda x: '<START> ' + x + ' <END>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1554820017264,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "GbGtP_6VLedh",
    "outputId": "bb09549b-81c3-4791-b5da-7282fde10d32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15958</th>\n",
       "      <td>we cant both be right</td>\n",
       "      <td>&lt;START&gt; आपण दोघेही बरोबर असू शकत नाही &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>nobody likes my country</td>\n",
       "      <td>&lt;START&gt; माझा देश कोणालाही आवडत नाही &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13407</th>\n",
       "      <td>i cant open the door</td>\n",
       "      <td>&lt;START&gt; मला दार उघडता येत नाहीये &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>this isnt new</td>\n",
       "      <td>&lt;START&gt; हे काय नवीन नाहीये &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32484</th>\n",
       "      <td>without a good education how can you succeed</td>\n",
       "      <td>&lt;START&gt; चांगल्या शिक्षणाशिवाय तू यशस्वी कसा हो...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Eng  \\\n",
       "15958                         we cant both be right   \n",
       "16986                       nobody likes my country   \n",
       "13407                          i cant open the door   \n",
       "3006                                  this isnt new   \n",
       "32484  without a good education how can you succeed   \n",
       "\n",
       "                                                     Mar  \n",
       "15958        <START> आपण दोघेही बरोबर असू शकत नाही <END>  \n",
       "16986          <START> माझा देश कोणालाही आवडत नाही <END>  \n",
       "13407             <START> मला दार उघडता येत नाहीये <END>  \n",
       "3006                    <START> हे काय नवीन नाहीये <END>  \n",
       "32484  <START> चांगल्या शिक्षणाशिवाय तू यशस्वी कसा हो...  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a few samples of the dataset\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCXugjOO_-v_"
   },
   "outputs": [],
   "source": [
    "# Get vocabulary and embeddings\n",
    "with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n",
    "    english_summary = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(root, 'embeddings.ma'), 'rb') as f:\n",
    "    marathi_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_W9WhAqyB_ZC"
   },
   "outputs": [],
   "source": [
    "# Add start and end tokens to dictionary\n",
    "for word in ['<START>', '<END>']:\n",
    "    l = len(marathi_summary['dictionary'].keys())\n",
    "    marathi_summary['dictionary'][word] = l\n",
    "    marathi_summary['reverse_dictionary'][l] = word\n",
    "    marathi_summary['embeddings'] = np.vstack((marathi_summary['embeddings'], np.zeros((1, marathi_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_i-8ssyLedl"
   },
   "outputs": [],
   "source": [
    "# English vocabulary\n",
    "all_eng_words = set(list(english_summary['dictionary'].keys()))\n",
    "        \n",
    "# Marathi vocabulary\n",
    "all_mar_words = set(list(marathi_summary['dictionary'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1554820036776,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "7QZaq1bQLedo",
    "outputId": "74f7b56f-3f5b-47a5-f59b-6d7e0b0a7fd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of source sequence\n",
    "max_length_src = 0\n",
    "\n",
    "for line in lines.Eng:\n",
    "    if len(line.split(' ')) > max_length_src:\n",
    "        max_length_src = len(line.split(' '))\n",
    "        \n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1148,
     "status": "ok",
     "timestamp": 1554820038470,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SHtikVcQLedu",
    "outputId": "27cb0b1b-6352-466b-be4d-576e41401fb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max length of target sequence\n",
    "max_length_tar = 0\n",
    "\n",
    "for line in lines.Mar:\n",
    "    if len(line.split(' ')) > max_length_tar:\n",
    "        max_length_tar = len(line.split(' '))\n",
    "        \n",
    "max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1554820039950,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "Eaj5LOJgLedz",
    "outputId": "abe2194a-5fa8-4e8d-fb24-6a1e4e6a92d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8731, 12698)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_mar_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FNryqdRvLed3"
   },
   "outputs": [],
   "source": [
    "source_dictionary = english_summary['dictionary']\n",
    "target_dictionary = marathi_summary['dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W0bt1VxLLed5"
   },
   "outputs": [],
   "source": [
    "source_reverse_dictionary = english_summary['reverse_dictionary']\n",
    "target_reverse_dictionary = marathi_summary['reverse_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1292,
     "status": "ok",
     "timestamp": 1554820044925,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "v9Z2BiygLed9",
    "outputId": "521e5109-40ca-4fea-cf0c-7c6eb6775c57",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng</th>\n",
       "      <th>Mar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>whats a porcupine</td>\n",
       "      <td>&lt;START&gt; साळिंदर काय असतो &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12705</th>\n",
       "      <td>what is your address</td>\n",
       "      <td>&lt;START&gt; तुझा पत्ता काय आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12892</th>\n",
       "      <td>you two come with me</td>\n",
       "      <td>&lt;START&gt; तुम्ही दोघी माझ्याबरोबर या &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8186</th>\n",
       "      <td>i watch television</td>\n",
       "      <td>&lt;START&gt; मी टीव्ही बघते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>tom needs a towel</td>\n",
       "      <td>&lt;START&gt; टॉमला एका टॉवेलची गरज आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31153</th>\n",
       "      <td>how many hours a day do you study french</td>\n",
       "      <td>&lt;START&gt; तू दिवसातून किती तास फ्रेंचचा अभ्यास क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7304</th>\n",
       "      <td>well do the rest</td>\n",
       "      <td>&lt;START&gt; बाकीचं आपण करू &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>i bought a new car</td>\n",
       "      <td>&lt;START&gt; मी एक नवीन गाडी विकत घेतली &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>i was sleeping</td>\n",
       "      <td>&lt;START&gt; मी झोपत होते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26462</th>\n",
       "      <td>i still have friends in the cia</td>\n",
       "      <td>&lt;START&gt; माझ्याकडे अजूनही सीआयएमध्ये मित्र आहेत...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Eng  \\\n",
       "9101                          whats a porcupine   \n",
       "12705                      what is your address   \n",
       "12892                      you two come with me   \n",
       "8186                         i watch television   \n",
       "7138                          tom needs a towel   \n",
       "31153  how many hours a day do you study french   \n",
       "7304                           well do the rest   \n",
       "7996                         i bought a new car   \n",
       "2690                             i was sleeping   \n",
       "26462           i still have friends in the cia   \n",
       "\n",
       "                                                     Mar  \n",
       "9101                      <START> साळिंदर काय असतो <END>  \n",
       "12705                   <START> तुझा पत्ता काय आहे <END>  \n",
       "12892           <START> तुम्ही दोघी माझ्याबरोबर या <END>  \n",
       "8186                        <START> मी टीव्ही बघते <END>  \n",
       "7138             <START> टॉमला एका टॉवेलची गरज आहे <END>  \n",
       "31153  <START> तू दिवसातून किती तास फ्रेंचचा अभ्यास क...  \n",
       "7304                        <START> बाकीचं आपण करू <END>  \n",
       "7996            <START> मी एक नवीन गाडी विकत घेतली <END>  \n",
       "2690                          <START> मी झोपत होते <END>  \n",
       "26462  <START> माझ्याकडे अजूनही सीआयएमध्ये मित्र आहेत...  "
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OpwDCXjSLeeC"
   },
   "source": [
    "### 3. Batch Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bUerHhNLeeD"
   },
   "outputs": [],
   "source": [
    "def encode_input(X):\n",
    "    \"\"\"\n",
    "        X = batch of inputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(X)\n",
    "    \n",
    "    # Create a numpy array of zeros to hold input\n",
    "    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(X):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            if word not in source_dictionary.keys():\n",
    "                word = 'UNK'\n",
    "            encoder_input_data[i, t] = source_dictionary[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(y):\n",
    "    \"\"\"\n",
    "        y = batch of outputs\n",
    "    \"\"\"\n",
    "    # Get the batch_size\n",
    "    batch_size = len(y)\n",
    "    \n",
    "    # Create numpy arrays of zeros to hold encoded targets\n",
    "    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(y):\n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if t < len(target_text.split()) - 1:\n",
    "                decoder_input_data[i, t] = target_dictionary[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GiOFeb9vLeeH"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size=128):\n",
    "    \"\"\"\n",
    "        X = Source dataset\n",
    "        y = Target dataset\n",
    "        batch_size = Size of each batch\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_input(X[j:j+batch_size])\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-x4hM2sLeeL"
   },
   "source": [
    "### 4. Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1953,
     "status": "ok",
     "timestamp": 1554820050025,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "1UtH1Hp3LeeN",
    "outputId": "cb14ff52-dc24-4654-b92e-1c425e3aea9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30352,), (3373,))"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train-test split\n",
    "X, y = lines.Eng, lines.Mar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CUiDGfCLeeS"
   },
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6hMfdyQLeeW"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxWNZCbELeeZ"
   },
   "source": [
    "#### 4.1 Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1667,
     "status": "ok",
     "timestamp": 1554820058475,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "aGdBX4MhLeeZ",
    "outputId": "bd6f03d2-ea3d-4aff-b2fb-1283b2b74bcf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
    "\n",
    "# Embedding Lookup\n",
    "encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[english_summary['embeddings']], \n",
    "                                    name='English_Embedding_Layer')\n",
    "encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "# Keeping only the states and discarding encoder outputs\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqcAW1TRLeed"
   },
   "source": [
    "#### 4.2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT4GcwdKLeee"
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
    "\n",
    "# Embedding\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n",
    "                                    weights=[marathi_summary['embeddings']], \n",
    "                                    name='Marathi_Embedding_Layer')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "# Dense output layer\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zUNups0Leei"
   },
   "outputs": [],
   "source": [
    "# Define a model with these layers\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1554820063817,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "EmPdHO_sLeel",
    "outputId": "2fc45cda-b7fb-4f9e-c4a3-e5fe20f3a4cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Encoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "English_Embedding_Layer (Embedd (None, None, 128)    1117568     Encoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[0][0]    \n",
      "                                                                 Encoder_LSTM[0][1]               \n",
      "                                                                 Encoder_LSTM[0][2]               \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,644,122\n",
      "Trainable params: 4,644,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-Upu1etLeep"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFHzeRT25jMR"
   },
   "outputs": [],
   "source": [
    "# Load pre-trained weights from Eng-Hin model\n",
    "model.load_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJGZXMmsLeev"
   },
   "outputs": [],
   "source": [
    "# Create checkpoints to save model from time to time\n",
    "filepath = os.path.join(root, 'best_model_en_ma_tl_e.hdf5')\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3590
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5592798,
     "status": "ok",
     "timestamp": 1554825733403,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "z-FyOS1lLeey",
    "outputId": "5a9ecc77-353b-4676-e9f4-c1bd8c623823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "237/237 [==============================] - 117s 492ms/step - loss: 5.7952 - acc: 0.2223 - val_loss: 5.1438 - val_acc: 0.2731\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.27308, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "237/237 [==============================] - 112s 474ms/step - loss: 4.7749 - acc: 0.3087 - val_loss: 4.6222 - val_acc: 0.3343\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.27308 to 0.33432, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 3/50\n",
      "237/237 [==============================] - 113s 476ms/step - loss: 4.2433 - acc: 0.3701 - val_loss: 4.2414 - val_acc: 0.3841\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.33432 to 0.38406, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 4/50\n",
      "237/237 [==============================] - 112s 474ms/step - loss: 3.8409 - acc: 0.4162 - val_loss: 3.9572 - val_acc: 0.4193\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.38406 to 0.41927, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 5/50\n",
      "237/237 [==============================] - 112s 474ms/step - loss: 3.5150 - acc: 0.4527 - val_loss: 3.7606 - val_acc: 0.4429\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.41927 to 0.44294, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 6/50\n",
      "237/237 [==============================] - 112s 473ms/step - loss: 3.2444 - acc: 0.4849 - val_loss: 3.5829 - val_acc: 0.4666\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.44294 to 0.46659, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 7/50\n",
      "237/237 [==============================] - 112s 474ms/step - loss: 3.0179 - acc: 0.5145 - val_loss: 3.4705 - val_acc: 0.4804\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.46659 to 0.48039, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 8/50\n",
      "237/237 [==============================] - 111s 470ms/step - loss: 2.8272 - acc: 0.5407 - val_loss: 3.3467 - val_acc: 0.4965\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.48039 to 0.49654, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 9/50\n",
      "237/237 [==============================] - 111s 469ms/step - loss: 2.6628 - acc: 0.5637 - val_loss: 3.2754 - val_acc: 0.5089\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.49654 to 0.50889, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 10/50\n",
      "237/237 [==============================] - 111s 469ms/step - loss: 2.5147 - acc: 0.5854 - val_loss: 3.1952 - val_acc: 0.5204\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.50889 to 0.52043, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 11/50\n",
      "237/237 [==============================] - 111s 469ms/step - loss: 2.3869 - acc: 0.6042 - val_loss: 3.1460 - val_acc: 0.5300\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.52043 to 0.53002, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 12/50\n",
      "237/237 [==============================] - 112s 472ms/step - loss: 2.2756 - acc: 0.6219 - val_loss: 3.0697 - val_acc: 0.5367\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.53002 to 0.53666, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 13/50\n",
      "237/237 [==============================] - 110s 465ms/step - loss: 2.1747 - acc: 0.6376 - val_loss: 3.0564 - val_acc: 0.5430\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.53666 to 0.54305, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 14/50\n",
      "237/237 [==============================] - 110s 464ms/step - loss: 2.0828 - acc: 0.6522 - val_loss: 3.0061 - val_acc: 0.5491\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.54305 to 0.54910, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 15/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.9960 - acc: 0.6658 - val_loss: 2.9702 - val_acc: 0.5517\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.54910 to 0.55165, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 16/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.9200 - acc: 0.6776 - val_loss: 2.9283 - val_acc: 0.5582\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.55165 to 0.55816, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 17/50\n",
      "237/237 [==============================] - 110s 465ms/step - loss: 1.8474 - acc: 0.6897 - val_loss: 2.9063 - val_acc: 0.5586\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.55816 to 0.55863, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 18/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.7813 - acc: 0.7004 - val_loss: 2.9035 - val_acc: 0.5616\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.55863 to 0.56164, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 19/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.7255 - acc: 0.7105 - val_loss: 2.8735 - val_acc: 0.5665\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.56164 to 0.56645, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 20/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.6764 - acc: 0.7187 - val_loss: 2.8548 - val_acc: 0.5719\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.56645 to 0.57187, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 21/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 1.6305 - acc: 0.7277 - val_loss: 2.8501 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.57187 to 0.57401, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 22/50\n",
      "237/237 [==============================] - 109s 462ms/step - loss: 1.5898 - acc: 0.7349 - val_loss: 2.8360 - val_acc: 0.5765\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.57401 to 0.57654, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 23/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.5539 - acc: 0.7425 - val_loss: 2.8619 - val_acc: 0.5722\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.57654\n",
      "Epoch 24/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 1.5196 - acc: 0.7487 - val_loss: 2.8617 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.57654\n",
      "Epoch 25/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.4880 - acc: 0.7547 - val_loss: 2.8517 - val_acc: 0.5725\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.57654\n",
      "Epoch 26/50\n",
      "237/237 [==============================] - 110s 464ms/step - loss: 1.4571 - acc: 0.7607 - val_loss: 2.8747 - val_acc: 0.5726\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.57654\n",
      "Epoch 27/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.4271 - acc: 0.7664 - val_loss: 2.8763 - val_acc: 0.5736\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.57654\n",
      "Epoch 28/50\n",
      "237/237 [==============================] - 109s 462ms/step - loss: 1.3994 - acc: 0.7718 - val_loss: 2.8490 - val_acc: 0.5769\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.57654 to 0.57691, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 29/50\n",
      "237/237 [==============================] - 110s 465ms/step - loss: 1.3725 - acc: 0.7759 - val_loss: 2.8560 - val_acc: 0.5741\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.57691\n",
      "Epoch 30/50\n",
      "237/237 [==============================] - 110s 463ms/step - loss: 1.3472 - acc: 0.7801 - val_loss: 2.8462 - val_acc: 0.5756\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.57691\n",
      "Epoch 31/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 1.3206 - acc: 0.7849 - val_loss: 2.8286 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.57691\n",
      "Epoch 32/50\n",
      "237/237 [==============================] - 110s 465ms/step - loss: 1.2981 - acc: 0.7883 - val_loss: 2.8401 - val_acc: 0.5770\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.57691 to 0.57698, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 33/50\n",
      "237/237 [==============================] - 111s 468ms/step - loss: 1.2765 - acc: 0.7918 - val_loss: 2.8339 - val_acc: 0.5797\n",
      "\n",
      "Epoch 00033: val_acc improved from 0.57698 to 0.57966, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 34/50\n",
      "237/237 [==============================] - 111s 468ms/step - loss: 1.2560 - acc: 0.7947 - val_loss: 2.8426 - val_acc: 0.5770\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.57966\n",
      "Epoch 35/50\n",
      "237/237 [==============================] - 111s 468ms/step - loss: 1.2350 - acc: 0.7987 - val_loss: 2.8261 - val_acc: 0.5798\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.57966 to 0.57985, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 36/50\n",
      "237/237 [==============================] - 111s 467ms/step - loss: 1.2169 - acc: 0.8016 - val_loss: 2.8517 - val_acc: 0.5796\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.57985\n",
      "Epoch 37/50\n",
      "237/237 [==============================] - 112s 471ms/step - loss: 1.2009 - acc: 0.8046 - val_loss: 2.8341 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.57985 to 0.57990, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 38/50\n",
      "237/237 [==============================] - 112s 472ms/step - loss: 1.1838 - acc: 0.8074 - val_loss: 2.8344 - val_acc: 0.5798\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.57990\n",
      "Epoch 39/50\n",
      "237/237 [==============================] - 114s 479ms/step - loss: 1.1685 - acc: 0.8099 - val_loss: 2.8131 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.57990\n",
      "Epoch 40/50\n",
      "237/237 [==============================] - 113s 478ms/step - loss: 1.1539 - acc: 0.8123 - val_loss: 2.8577 - val_acc: 0.5783\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.57990\n",
      "Epoch 41/50\n",
      "237/237 [==============================] - 113s 477ms/step - loss: 1.1392 - acc: 0.8146 - val_loss: 2.8505 - val_acc: 0.5790\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.57990\n",
      "Epoch 42/50\n",
      "237/237 [==============================] - 113s 478ms/step - loss: 1.1258 - acc: 0.8173 - val_loss: 2.8522 - val_acc: 0.5768\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.57990\n",
      "Epoch 43/50\n",
      "237/237 [==============================] - 115s 485ms/step - loss: 1.1130 - acc: 0.8190 - val_loss: 2.8427 - val_acc: 0.5805\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.57990 to 0.58048, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_tl_e.hdf5\n",
      "Epoch 44/50\n",
      "237/237 [==============================] - 115s 486ms/step - loss: 1.1016 - acc: 0.8213 - val_loss: 2.8305 - val_acc: 0.5785\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.58048\n",
      "Epoch 45/50\n",
      "237/237 [==============================] - 115s 487ms/step - loss: 1.0900 - acc: 0.8230 - val_loss: 2.8422 - val_acc: 0.5784\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.58048\n",
      "Epoch 46/50\n",
      "237/237 [==============================] - 113s 476ms/step - loss: 1.0809 - acc: 0.8243 - val_loss: 2.8535 - val_acc: 0.5772\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.58048\n",
      "Epoch 47/50\n",
      "237/237 [==============================] - 110s 462ms/step - loss: 1.0692 - acc: 0.8265 - val_loss: 2.8565 - val_acc: 0.5774\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.58048\n",
      "Epoch 48/50\n",
      "237/237 [==============================] - 111s 469ms/step - loss: 1.0586 - acc: 0.8283 - val_loss: 2.8546 - val_acc: 0.5794\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.58048\n",
      "Epoch 49/50\n",
      "237/237 [==============================] - 110s 465ms/step - loss: 1.0507 - acc: 0.8297 - val_loss: 2.8495 - val_acc: 0.5799\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.58048\n",
      "Epoch 50/50\n",
      "237/237 [==============================] - 113s 475ms/step - loss: 1.0408 - acc: 0.8309 - val_loss: 2.8784 - val_acc: 0.5766\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.58048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f96c0039358>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n",
    "                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n",
    "                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VRdA-3G8Lee1"
   },
   "source": [
    "#### 4.3 Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8B6oDJqsLee2"
   },
   "outputs": [],
   "source": [
    "model.save_weights(os.path.join(root, 'nmt_weights_en_ma_tl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFYkdLTcLee5"
   },
   "source": [
    "#### 4.4 Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvWzXHqHMEe-"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'nmt_weights_en_ma_tl_e.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3s531y3Lee_"
   },
   "source": [
    "### 5. Inference Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZapXObgLefC"
   },
   "outputs": [],
   "source": [
    "# Encoder-decoder model that uses trained weights from the original model to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kA9ZktGiLefH"
   },
   "source": [
    "#### 5.1 Inference Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLp33CktLefJ"
   },
   "outputs": [],
   "source": [
    "# Encoder model to create a thought vector from the input\n",
    "inference_encoder = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51w8NazaLefM"
   },
   "source": [
    "#### 5.2 Inference Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQjvRgCPLefN"
   },
   "outputs": [],
   "source": [
    "# For each time step, the decoder states from previous timestep would act as inputs\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Embedding\n",
    "decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "# LSTM\n",
    "decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n",
    "                                                                               initial_state=decoder_states_inputs)\n",
    "decoder_states_inference = [state_h_inference, state_c_inference]\n",
    "\n",
    "# Dense\n",
    "decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL7B1qchLefP"
   },
   "outputs": [],
   "source": [
    "# Decoder model\n",
    "inference_decoder = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inference] + decoder_states_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5562844,
     "status": "ok",
     "timestamp": 1554825734056,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "SvR0urBBLefR",
    "outputId": "59ec4883-b17e-41a8-d33d-30f43015f68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder_Inputs (InputLayer)  (None, None)              0         \n",
      "_________________________________________________________________\n",
      "English_Embedding_Layer (Emb (None, None, 128)         1117568   \n",
      "_________________________________________________________________\n",
      "Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n",
      "=================================================================\n",
      "Total params: 1,249,152\n",
      "Trainable params: 1,249,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5562219,
     "status": "ok",
     "timestamp": 1554825734058,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "PH3DCqVjLefV",
    "outputId": "b0271966-5093-45c0-c9ba-bb22f32d6721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Decoder_Inputs (InputLayer)     (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Output (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Inference_Decoder_Memory (Input (None, 128)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[1][0]    \n",
      "                                                                 Inference_Decoder_Output[0][0]   \n",
      "                                                                 Inference_Decoder_Memory[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,394,970\n",
      "Trainable params: 3,394,970\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inference_decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nlo9Ng46LefY"
   },
   "source": [
    "#### 5.3 Decode sample sequeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NUGmwBtLefZ"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_sequence):\n",
    "    # Get thought vector by encoding the input sequence\n",
    "    states_value = inference_encoder.predict(input_sequence)\n",
    "    \n",
    "    # Generate target sequence initialized with <START> character\n",
    "    target_sequence = np.zeros((1, 1))\n",
    "    target_sequence[0, 0] = target_dictionary['<START>']\n",
    "    \n",
    "    # To stop the recurrent loop\n",
    "    stop_condition = False\n",
    "    \n",
    "    # Final sentence\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        # Get next prediction\n",
    "        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n",
    "        \n",
    "        # Get the token with max probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_reverse_dictionary[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_word\n",
    "        \n",
    "        # Test for exit condition\n",
    "        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update the target sequence with current prediction\n",
    "        target_sequence = np.zeros((1, 1))\n",
    "        target_sequence[0, 0] = sampled_token_index\n",
    "        \n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eehBSrbvLefc"
   },
   "source": [
    "### 6. Evaluation on Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1554826570634,
     "user": {
      "displayName": "Nishit Jain",
      "photoUrl": "https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg",
      "userId": "00220384259459575150"
     },
     "user_tz": -330
    },
    "id": "s2D1wd2NLefl",
    "outputId": "de29413e-d366-4444-92a8-4d79939d6be9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तू कसा आहेस'"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = encode_input(['how are you'])\n",
    "decoded_sentence = decode_sequence(input_sequence)\n",
    "' '.join(decoded_sentence.split()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yM-WPO4E6P5H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Eng_Mar_TL_E.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
