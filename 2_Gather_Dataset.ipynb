{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eX-1lnzMymvb"
   },
   "source": [
    "## This file curates a dataset for input to train a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwsWQdzgymvf"
   },
   "source": [
    "### 1. Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRVYTn2iymvg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_oxF7xoJymvq"
   },
   "source": [
    "### 2. Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_english():\n",
    "    \"\"\"\n",
    "        Call this function to merge cleaned english texts for word2vec model.\n",
    "    \"\"\"\n",
    "    # Open output file\n",
    "    f_out = open(os.path.join(root, 'mono.en'), 'w')\n",
    "    \n",
    "    # Open input file\n",
    "    with open(os.path.join(root, 'en-hi_cleaned.en')) as f:\n",
    "        # Read line and use tf.compat to make it compatible with all forms of Python\n",
    "        sentence = tf.compat.as_str(f.readline())\n",
    "        \n",
    "        # While a line has been read (i.e. document is not finished)\n",
    "        while sentence:\n",
    "            # Write the line to output file\n",
    "            f_out.write(sentence.strip() + ' ')\n",
    "            \n",
    "            # Read next line\n",
    "            sentence = tf.compat.as_str(f.readline())\n",
    "            \n",
    "    # Open input file\n",
    "    with open(os.path.join(root, 'en-mar_cleaned.en')) as f:\n",
    "        # Read line and use tf.compat to make it compatible with all forms of Python\n",
    "        sentence = tf.compat.as_str(f.readline())\n",
    "        \n",
    "        # While a line has been read (i.e. document is not finished)\n",
    "        while sentence:\n",
    "            # Write the line to output file\n",
    "            f_out.write(sentence.strip() + ' ')\n",
    "            \n",
    "            # Read next line\n",
    "            sentence = tf.compat.as_str(f.readline())\n",
    "            \n",
    "    # Close the output file\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_hindi():\n",
    "    \"\"\"\n",
    "        Call this function to merge cleaned Hindi texts for word2vec model.\n",
    "    \"\"\"\n",
    "    # Open output file\n",
    "    f_out = open(os.path.join(root, 'mono.hi'), 'w')\n",
    "    \n",
    "    # Open input file\n",
    "    with open(os.path.join(root, 'en-hi_cleaned.hi')) as f:\n",
    "        # Read line and use tf.compat to make it compatible with all forms of Python\n",
    "        sentence = tf.compat.as_str(f.readline())\n",
    "        \n",
    "        # While a line has been read (i.e. document is not finished)\n",
    "        while sentence:\n",
    "            # Write the line to output file\n",
    "            f_out.write(sentence.strip() + ' ')\n",
    "            \n",
    "            # Read next line\n",
    "            sentence = tf.compat.as_str(f.readline())\n",
    "            \n",
    "    # Close the output file\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Marathi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_marathi():\n",
    "    \"\"\"\n",
    "        Call this function to merge cleaned Marathi texts for word2vec model.\n",
    "    \"\"\"\n",
    "    # Open output file\n",
    "    f_out = open(os.path.join(root, 'mono.ma'), 'w')\n",
    "    \n",
    "    # Open input file\n",
    "    with open(os.path.join(root, 'en-mar_cleaned.ma')) as f:\n",
    "        # Read line and use tf.compat to make it compatible with all forms of Python\n",
    "        sentence = tf.compat.as_str(f.readline())\n",
    "        \n",
    "        # While a line has been read (i.e. document is not finished)\n",
    "        while sentence:\n",
    "            # Write the line to output file\n",
    "            f_out.write(sentence.strip() + ' ')\n",
    "            \n",
    "            # Read next line\n",
    "            sentence = tf.compat.as_str(f.readline())\n",
    "            \n",
    "    # Close the output file\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMF7YWlqS-gn"
   },
   "outputs": [],
   "source": [
    "# merge_english()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_hindi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_marathi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1_Gather_Dataset.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
