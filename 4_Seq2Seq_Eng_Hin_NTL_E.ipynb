{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_Seq2Seq_Eng_Hin_NTL_E.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805312671,"user_tz":-330,"elapsed":22477,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"gwTL36ttLedG","outputId":"5dc96f92-72ce-4a91-eb5c-e787a964630a","colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["# To mount Google drive on Google Colab environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","root = '/content/drive/My Drive/English Dataset'\n","# root = '.'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"Eb0tHTz1LedM"},"cell_type":"markdown","source":["### 1. Packages"]},{"metadata":{"colab_type":"code","id":"92RA6N5fLedO","colab":{}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","import re\n","import os\n","import matplotlib.pyplot as plt\n","import pickle\n","%matplotlib inline\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","from string import digits"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"q5-UJzoBLedS"},"cell_type":"markdown","source":["### 2. Data Preparation"]},{"metadata":{"colab_type":"code","id":"qEj_b0VSLedT","colab":{}},"cell_type":"code","source":["# Read dataset\n","lines = pd.read_pickle(os.path.join(root, 'hin-eng_cleaned.parallel'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805322792,"user_tz":-330,"elapsed":1952,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"D787xMeLLedV","outputId":"1db37ccf-d36d-4531-a45f-c3b97c61f1b2","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# View the shape of dataset\n","lines.shape"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(67700, 2)"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"colab_type":"code","id":"ZsqG7aFTLedd","colab":{}},"cell_type":"code","source":["# Add 'start' and 'end' tokens to target sentences\n","lines.Hin = lines.Hin.apply(lambda x: '<START> ' + x + ' <END>')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805327068,"user_tz":-330,"elapsed":1297,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"GbGtP_6VLedh","outputId":"bf54288e-669d-4c63-cff4-8d591b155cdc","colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# View a few samples of the dataset\n","lines.sample(5)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Hin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22830</th>\n","      <td>single step into function</td>\n","      <td>&lt;START&gt; एकल चरण फंक्शन &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>257</th>\n","      <td>selected columns</td>\n","      <td>&lt;START&gt; चुने गए स्तंभ &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>57714</th>\n","      <td>details</td>\n","      <td>&lt;START&gt; विवरण &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1500</th>\n","      <td>start</td>\n","      <td>&lt;START&gt; प्रारंभ &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>51556</th>\n","      <td>offline contacts</td>\n","      <td>&lt;START&gt; ऑफलाइन संपर्क दिखाएँ &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                             Eng                                 Hin\n","22830  single step into function        <START> एकल चरण फंक्शन <END>\n","257             selected columns         <START> चुने गए स्तंभ <END>\n","57714                    details                 <START> विवरण <END>\n","1500                       start               <START> प्रारंभ <END>\n","51556           offline contacts  <START> ऑफलाइन संपर्क दिखाएँ <END>"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"vfyObQaznW8n","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get vocabulary and embeddings\n","with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n","    english_summary = pickle.load(f)\n","    \n","with open(os.path.join(root, 'embeddings.hi'), 'rb') as f:\n","    hindi_summary = pickle.load(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MXKj_cpYnW8r","colab_type":"code","colab":{}},"cell_type":"code","source":["# Add start and end tokens to dictionary\n","for word in ['<START>', '<END>']:\n","    l = len(hindi_summary['dictionary'].keys())\n","    hindi_summary['dictionary'][word] = l\n","    hindi_summary['reverse_dictionary'][l] = word\n","    hindi_summary['embeddings'] = np.vstack((hindi_summary['embeddings'], np.zeros((1, hindi_summary['embeddings'].shape[1]))))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-_i-8ssyLedl","colab":{}},"cell_type":"code","source":["# English vocabulary\n","all_eng_words = set(list(english_summary['dictionary'].keys()))\n","        \n","# Hin vocabulary\n","all_hin_words = set(list(hindi_summary['dictionary'].keys()))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805353595,"user_tz":-330,"elapsed":1186,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"7QZaq1bQLedo","outputId":"5fd9a6e7-02d7-4d71-d656-c5d2818c6468","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of source sequence\n","max_length_src = 0\n","\n","for line in lines.Eng:\n","    if len(line.split(' ')) > max_length_src:\n","        max_length_src = len(line.split(' '))\n","        \n","max_length_src"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["54"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805355611,"user_tz":-330,"elapsed":1327,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"SHtikVcQLedu","outputId":"8e3ee884-f4af-4bdf-d2e3-c2090fda0301","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of target sequence\n","max_length_tar = 0\n","\n","for line in lines.Hin:\n","    if len(line.split(' ')) > max_length_tar:\n","        max_length_tar = len(line.split(' '))\n","        \n","max_length_tar"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805357534,"user_tz":-330,"elapsed":1329,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"Eaj5LOJgLedz","outputId":"95392711-fd37-4d0c-a0c0-4df33f062a9f","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["num_encoder_tokens = len(all_eng_words)\n","num_decoder_tokens = len(all_hin_words)\n","num_encoder_tokens, num_decoder_tokens"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8731, 6566)"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"colab_type":"code","id":"FNryqdRvLed3","colab":{}},"cell_type":"code","source":["source_dictionary = english_summary['dictionary']\n","target_dictionary = hindi_summary['dictionary']"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"W0bt1VxLLed5","colab":{}},"cell_type":"code","source":["source_reverse_dictionary = english_summary['reverse_dictionary']\n","target_reverse_dictionary = hindi_summary['reverse_dictionary']"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805372565,"user_tz":-330,"elapsed":1591,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"v9Z2BiygLed9","outputId":"52bd682e-294c-4fae-ac24-5a4188f03652","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":359}},"cell_type":"code","source":["lines = shuffle(lines)\n","lines.head(10)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Hin</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29806</th>\n","      <td>type your keywords or choose all files from th...</td>\n","      <td>&lt;START&gt; मेन्यू से चुनने के लिए अपना बीजशब्द टा...</td>\n","    </tr>\n","    <tr>\n","      <th>6697</th>\n","      <td>datetime</td>\n","      <td>&lt;START&gt; समय &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>34794</th>\n","      <td>song information for track i</td>\n","      <td>&lt;START&gt; ट्रैक के लिए गीत जानकारी &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>33283</th>\n","      <td>all files</td>\n","      <td>&lt;START&gt; सभी फ़ाइलें &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>26816</th>\n","      <td>accessible table row description</td>\n","      <td>&lt;START&gt; पहुँच योग्य सारणी पंक्ति वर्णन &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>67241</th>\n","      <td>open the door</td>\n","      <td>&lt;START&gt; दरवाज़ा खोलो &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>16493</th>\n","      <td>s install it from s</td>\n","      <td>&lt;START&gt; से संस्थापित करें से से नहीं &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1209</th>\n","      <td>the layout for the top panel pluginview</td>\n","      <td>&lt;START&gt; शीर्ष पैनल के लिए लेआउट &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>8205</th>\n","      <td>general project information</td>\n","      <td>&lt;START&gt; सामान्य प्रोजेक्ट सूचना &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>17243</th>\n","      <td>missing name</td>\n","      <td>&lt;START&gt; अनुपस्थित नाम &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                     Eng  \\\n","29806  type your keywords or choose all files from th...   \n","6697                                            datetime   \n","34794                       song information for track i   \n","33283                                          all files   \n","26816                   accessible table row description   \n","67241                                      open the door   \n","16493                                s install it from s   \n","1209             the layout for the top panel pluginview   \n","8205                         general project information   \n","17243                                       missing name   \n","\n","                                                     Hin  \n","29806  <START> मेन्यू से चुनने के लिए अपना बीजशब्द टा...  \n","6697                                   <START> समय <END>  \n","34794             <START> ट्रैक के लिए गीत जानकारी <END>  \n","33283                          <START> सभी फ़ाइलें <END>  \n","26816       <START> पहुँच योग्य सारणी पंक्ति वर्णन <END>  \n","67241                         <START> दरवाज़ा खोलो <END>  \n","16493         <START> से संस्थापित करें से से नहीं <END>  \n","1209               <START> शीर्ष पैनल के लिए लेआउट <END>  \n","8205               <START> सामान्य प्रोजेक्ट सूचना <END>  \n","17243                        <START> अनुपस्थित नाम <END>  "]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"colab_type":"text","id":"OpwDCXjSLeeC"},"cell_type":"markdown","source":["### 3. Batch Generator"]},{"metadata":{"colab_type":"code","id":"7bUerHhNLeeD","colab":{}},"cell_type":"code","source":["def encode_input(X):\n","    \"\"\"\n","        X = batch of inputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(X)\n","    \n","    # Create a numpy array of zeros to hold input\n","    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n","    \n","    for i, input_text in enumerate(X):\n","        for t, word in enumerate(input_text.split()):\n","            if word not in source_dictionary.keys():\n","                word = 'UNK'\n","            encoder_input_data[i, t] = source_dictionary[word]\n","            \n","    return encoder_input_data\n","\n","def encode_target(y):\n","    \"\"\"\n","        y = batch of outputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(y)\n","    \n","    # Create numpy arrays of zeros to hold encoded targets\n","    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n","    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n","    \n","    for i, target_text in enumerate(y):\n","        for t, word in enumerate(target_text.split()):\n","            if t < len(target_text.split()) - 1:\n","                decoder_input_data[i, t] = target_dictionary[word]\n","                \n","            if t > 0:\n","                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n","                \n","    return decoder_input_data, decoder_target_data"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"GiOFeb9vLeeH","colab":{}},"cell_type":"code","source":["def generate_batch(X, y, batch_size=128):\n","    \"\"\"\n","        X = Source dataset\n","        y = Target dataset\n","        batch_size = Size of each batch\n","    \"\"\"\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            encoder_input_data = encode_input(X[j:j+batch_size])\n","            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n","            \n","            yield([encoder_input_data, decoder_input_data], decoder_target_data)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"V-x4hM2sLeeL"},"cell_type":"markdown","source":["### 4. Encoder - Decoder Model Architecture"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805383358,"user_tz":-330,"elapsed":761,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"1UtH1Hp3LeeN","outputId":"3a533387-3deb-4552-cc06-64a36eb933ea","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Train-test split\n","X, y = lines.Eng, lines.Hin\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","X_train.shape, X_test.shape"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((60930,), (6770,))"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"colab_type":"code","id":"2CUiDGfCLeeS","colab":{}},"cell_type":"code","source":["latent_dim = 128"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"H6hMfdyQLeeW","colab":{}},"cell_type":"code","source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","batch_size = 128\n","epochs = 50"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"IxWNZCbELeeZ"},"cell_type":"markdown","source":["#### 4.1 Encoder"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805399577,"user_tz":-330,"elapsed":3843,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"aGdBX4MhLeeZ","outputId":"2cd949f3-dac5-4eaa-85a8-bdd3a7ec8796","colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["# Inputs\n","encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n","\n","# Embedding Lookup\n","encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n","                                    weights=[english_summary['embeddings']], \n","                                    name='English_Embedding_Layer_NT')\n","encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n","\n","# LSTM\n","encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n","\n","# Keeping only the states and discarding encoder outputs\n","encoder_states = [state_h, state_c]"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"TqcAW1TRLeed"},"cell_type":"markdown","source":["#### 4.2 Decoder"]},{"metadata":{"colab_type":"code","id":"pT4GcwdKLeee","colab":{}},"cell_type":"code","source":["# Inputs\n","decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n","\n","# Embedding\n","decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n","                                    weights=[hindi_summary['embeddings']], \n","                                    name='Hindi_Embedding_Layer_NT')\n","decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n","decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n","\n","# Dense output layer\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense_NT')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7zUNups0Leei","colab":{}},"cell_type":"code","source":["# Define a model with these layers\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554805410160,"user_tz":-330,"elapsed":1403,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"EmPdHO_sLeel","outputId":"50060315-9c60-4e4e-b5df-b3f2a416b479","colab":{"base_uri":"https://localhost:8080/","height":428}},"cell_type":"code","source":["# Take a look at the model\n","model.summary()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Encoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","English_Embedding_Layer_NT (Emb (None, None, 128)    1117568     Encoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Hindi_Embedding_Layer_NT (Embed (None, None, 128)    840448      Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer_NT[0][0] \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Hindi_Embedding_Layer_NT[0][0]   \n","                                                                 Encoder_LSTM[0][1]               \n","                                                                 Encoder_LSTM[0][2]               \n","__________________________________________________________________________________________________\n","Decoder_Dense_NT (Dense)        (None, None, 6566)   847014      Decoder_LSTM[0][0]               \n","==================================================================================================\n","Total params: 3,068,198\n","Trainable params: 3,068,198\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"U-Upu1etLeep","colab":{}},"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"tJGZXMmsLeev","colab":{}},"cell_type":"code","source":["# Create checkpoints to save model from time to time\n","filepath = os.path.join(root, 'best_model_en_hi_ntl_e.hdf5')\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554817529575,"user_tz":-330,"elapsed":12113903,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"z-FyOS1lLeey","outputId":"dd9bcb01-2ad0-42a4-d3a0-997e5ad9a115","colab":{"base_uri":"https://localhost:8080/","height":3590}},"cell_type":"code","source":["model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n","                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n","                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Epoch 1/50\n","476/476 [==============================] - 249s 523ms/step - loss: 5.4680 - acc: 0.2134 - val_loss: 4.8490 - val_acc: 0.2577\n","\n","Epoch 00001: val_acc improved from -inf to 0.25774, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/50\n","476/476 [==============================] - 242s 508ms/step - loss: 4.4186 - acc: 0.2975 - val_loss: 4.0302 - val_acc: 0.3450\n","\n","Epoch 00002: val_acc improved from 0.25774 to 0.34501, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 3/50\n","476/476 [==============================] - 241s 507ms/step - loss: 3.6594 - acc: 0.3933 - val_loss: 3.3715 - val_acc: 0.4431\n","\n","Epoch 00003: val_acc improved from 0.34501 to 0.44307, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 4/50\n","476/476 [==============================] - 242s 508ms/step - loss: 3.0369 - acc: 0.4869 - val_loss: 2.8736 - val_acc: 0.5197\n","\n","Epoch 00004: val_acc improved from 0.44307 to 0.51969, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 5/50\n","476/476 [==============================] - 237s 498ms/step - loss: 2.5557 - acc: 0.5643 - val_loss: 2.4740 - val_acc: 0.5898\n","\n","Epoch 00005: val_acc improved from 0.51969 to 0.58976, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 6/50\n","476/476 [==============================] - 236s 497ms/step - loss: 2.1826 - acc: 0.6302 - val_loss: 2.1729 - val_acc: 0.6410\n","\n","Epoch 00006: val_acc improved from 0.58976 to 0.64102, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 7/50\n","476/476 [==============================] - 238s 499ms/step - loss: 1.8916 - acc: 0.6851 - val_loss: 1.9431 - val_acc: 0.6898\n","\n","Epoch 00007: val_acc improved from 0.64102 to 0.68977, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 8/50\n","476/476 [==============================] - 243s 511ms/step - loss: 1.6653 - acc: 0.7290 - val_loss: 1.7621 - val_acc: 0.7228\n","\n","Epoch 00008: val_acc improved from 0.68977 to 0.72284, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 9/50\n","476/476 [==============================] - 244s 513ms/step - loss: 1.4845 - acc: 0.7645 - val_loss: 1.6152 - val_acc: 0.7513\n","\n","Epoch 00009: val_acc improved from 0.72284 to 0.75132, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 10/50\n","476/476 [==============================] - 244s 512ms/step - loss: 1.3401 - acc: 0.7925 - val_loss: 1.5043 - val_acc: 0.7732\n","\n","Epoch 00010: val_acc improved from 0.75132 to 0.77323, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 11/50\n","476/476 [==============================] - 241s 507ms/step - loss: 1.2205 - acc: 0.8148 - val_loss: 1.4040 - val_acc: 0.7922\n","\n","Epoch 00011: val_acc improved from 0.77323 to 0.79220, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 12/50\n","476/476 [==============================] - 241s 505ms/step - loss: 1.1238 - acc: 0.8318 - val_loss: 1.3309 - val_acc: 0.8076\n","\n","Epoch 00012: val_acc improved from 0.79220 to 0.80763, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 13/50\n","476/476 [==============================] - 241s 506ms/step - loss: 1.0416 - acc: 0.8462 - val_loss: 1.2656 - val_acc: 0.8180\n","\n","Epoch 00013: val_acc improved from 0.80763 to 0.81799, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 14/50\n","476/476 [==============================] - 236s 497ms/step - loss: 0.9742 - acc: 0.8578 - val_loss: 1.2084 - val_acc: 0.8273\n","\n","Epoch 00014: val_acc improved from 0.81799 to 0.82727, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 15/50\n","476/476 [==============================] - 238s 500ms/step - loss: 0.9182 - acc: 0.8674 - val_loss: 1.1756 - val_acc: 0.8347\n","\n","Epoch 00015: val_acc improved from 0.82727 to 0.83467, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 16/50\n","476/476 [==============================] - 242s 508ms/step - loss: 0.8714 - acc: 0.8754 - val_loss: 1.1406 - val_acc: 0.8405\n","\n","Epoch 00016: val_acc improved from 0.83467 to 0.84047, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 17/50\n","476/476 [==============================] - 246s 516ms/step - loss: 0.8306 - acc: 0.8825 - val_loss: 1.1166 - val_acc: 0.8443\n","\n","Epoch 00017: val_acc improved from 0.84047 to 0.84432, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 18/50\n","476/476 [==============================] - 244s 513ms/step - loss: 0.7966 - acc: 0.8882 - val_loss: 1.0905 - val_acc: 0.8508\n","\n","Epoch 00018: val_acc improved from 0.84432 to 0.85083, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 19/50\n","476/476 [==============================] - 244s 513ms/step - loss: 0.7670 - acc: 0.8933 - val_loss: 1.0627 - val_acc: 0.8561\n","\n","Epoch 00019: val_acc improved from 0.85083 to 0.85610, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 20/50\n","476/476 [==============================] - 242s 509ms/step - loss: 0.7407 - acc: 0.8979 - val_loss: 1.0464 - val_acc: 0.8569\n","\n","Epoch 00020: val_acc improved from 0.85610 to 0.85689, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 21/50\n","476/476 [==============================] - 240s 505ms/step - loss: 0.7158 - acc: 0.9022 - val_loss: 1.0310 - val_acc: 0.8612\n","\n","Epoch 00021: val_acc improved from 0.85689 to 0.86116, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 22/50\n","476/476 [==============================] - 240s 504ms/step - loss: 0.6948 - acc: 0.9054 - val_loss: 1.0111 - val_acc: 0.8644\n","\n","Epoch 00022: val_acc improved from 0.86116 to 0.86439, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 23/50\n","476/476 [==============================] - 237s 498ms/step - loss: 0.6753 - acc: 0.9088 - val_loss: 1.0057 - val_acc: 0.8662\n","\n","Epoch 00023: val_acc improved from 0.86439 to 0.86619, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 24/50\n","476/476 [==============================] - 236s 496ms/step - loss: 0.6563 - acc: 0.9116 - val_loss: 0.9789 - val_acc: 0.8700\n","\n","Epoch 00024: val_acc improved from 0.86619 to 0.87004, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 25/50\n","476/476 [==============================] - 236s 496ms/step - loss: 0.6402 - acc: 0.9142 - val_loss: 0.9766 - val_acc: 0.8699\n","\n","Epoch 00025: val_acc did not improve from 0.87004\n","Epoch 26/50\n","476/476 [==============================] - 239s 502ms/step - loss: 0.6244 - acc: 0.9166 - val_loss: 0.9717 - val_acc: 0.8717\n","\n","Epoch 00026: val_acc improved from 0.87004 to 0.87166, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 27/50\n","476/476 [==============================] - 245s 515ms/step - loss: 0.6104 - acc: 0.9187 - val_loss: 0.9588 - val_acc: 0.8731\n","\n","Epoch 00027: val_acc improved from 0.87166 to 0.87307, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 28/50\n","476/476 [==============================] - 246s 517ms/step - loss: 0.5975 - acc: 0.9205 - val_loss: 0.9504 - val_acc: 0.8738\n","\n","Epoch 00028: val_acc improved from 0.87307 to 0.87376, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 29/50\n","476/476 [==============================] - 243s 511ms/step - loss: 0.5843 - acc: 0.9224 - val_loss: 0.9399 - val_acc: 0.8754\n","\n","Epoch 00029: val_acc improved from 0.87376 to 0.87542, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 30/50\n","476/476 [==============================] - 242s 509ms/step - loss: 0.5729 - acc: 0.9239 - val_loss: 0.9341 - val_acc: 0.8767\n","\n","Epoch 00030: val_acc improved from 0.87542 to 0.87670, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 31/50\n","476/476 [==============================] - 240s 504ms/step - loss: 0.5618 - acc: 0.9257 - val_loss: 0.9140 - val_acc: 0.8795\n","\n","Epoch 00031: val_acc improved from 0.87670 to 0.87953, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 32/50\n","476/476 [==============================] - 239s 502ms/step - loss: 0.5526 - acc: 0.9270 - val_loss: 0.9065 - val_acc: 0.8802\n","\n","Epoch 00032: val_acc improved from 0.87953 to 0.88021, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 33/50\n","476/476 [==============================] - 239s 502ms/step - loss: 0.5428 - acc: 0.9283 - val_loss: 0.9046 - val_acc: 0.8809\n","\n","Epoch 00033: val_acc improved from 0.88021 to 0.88090, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 34/50\n","476/476 [==============================] - 237s 499ms/step - loss: 0.5338 - acc: 0.9295 - val_loss: 0.9013 - val_acc: 0.8805\n","\n","Epoch 00034: val_acc did not improve from 0.88090\n","Epoch 35/50\n","476/476 [==============================] - 241s 505ms/step - loss: 0.5262 - acc: 0.9303 - val_loss: 0.9015 - val_acc: 0.8816\n","\n","Epoch 00035: val_acc improved from 0.88090 to 0.88159, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 36/50\n","476/476 [==============================] - 246s 518ms/step - loss: 0.5190 - acc: 0.9313 - val_loss: 0.8926 - val_acc: 0.8822\n","\n","Epoch 00036: val_acc improved from 0.88159 to 0.88217, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 37/50\n","476/476 [==============================] - 246s 517ms/step - loss: 0.5112 - acc: 0.9324 - val_loss: 0.8877 - val_acc: 0.8830\n","\n","Epoch 00037: val_acc improved from 0.88217 to 0.88302, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 38/50\n","476/476 [==============================] - 244s 513ms/step - loss: 0.5052 - acc: 0.9332 - val_loss: 0.8873 - val_acc: 0.8834\n","\n","Epoch 00038: val_acc improved from 0.88302 to 0.88343, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 39/50\n","476/476 [==============================] - 243s 510ms/step - loss: 0.4990 - acc: 0.9342 - val_loss: 0.8779 - val_acc: 0.8843\n","\n","Epoch 00039: val_acc improved from 0.88343 to 0.88428, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 40/50\n","476/476 [==============================] - 242s 508ms/step - loss: 0.4927 - acc: 0.9350 - val_loss: 0.8790 - val_acc: 0.8847\n","\n","Epoch 00040: val_acc improved from 0.88428 to 0.88475, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 41/50\n","476/476 [==============================] - 241s 506ms/step - loss: 0.4871 - acc: 0.9356 - val_loss: 0.8658 - val_acc: 0.8857\n","\n","Epoch 00041: val_acc improved from 0.88475 to 0.88570, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 42/50\n","476/476 [==============================] - 240s 505ms/step - loss: 0.4825 - acc: 0.9362 - val_loss: 0.8606 - val_acc: 0.8869\n","\n","Epoch 00042: val_acc improved from 0.88570 to 0.88687, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 43/50\n","476/476 [==============================] - 240s 504ms/step - loss: 0.4776 - acc: 0.9371 - val_loss: 0.8640 - val_acc: 0.8863\n","\n","Epoch 00043: val_acc did not improve from 0.88687\n","Epoch 44/50\n","476/476 [==============================] - 240s 504ms/step - loss: 0.4725 - acc: 0.9375 - val_loss: 0.8602 - val_acc: 0.8877\n","\n","Epoch 00044: val_acc improved from 0.88687 to 0.88774, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 45/50\n","476/476 [==============================] - 246s 516ms/step - loss: 0.4686 - acc: 0.9383 - val_loss: 0.8636 - val_acc: 0.8860\n","\n","Epoch 00045: val_acc did not improve from 0.88774\n","Epoch 46/50\n","476/476 [==============================] - 247s 518ms/step - loss: 0.4655 - acc: 0.9386 - val_loss: 0.8566 - val_acc: 0.8886\n","\n","Epoch 00046: val_acc improved from 0.88774 to 0.88858, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 47/50\n","476/476 [==============================] - 245s 514ms/step - loss: 0.4620 - acc: 0.9390 - val_loss: 0.8510 - val_acc: 0.8880\n","\n","Epoch 00047: val_acc did not improve from 0.88858\n","Epoch 48/50\n","476/476 [==============================] - 242s 509ms/step - loss: 0.4580 - acc: 0.9396 - val_loss: 0.8568 - val_acc: 0.8880\n","\n","Epoch 00048: val_acc did not improve from 0.88858\n","Epoch 49/50\n","476/476 [==============================] - 243s 510ms/step - loss: 0.4551 - acc: 0.9400 - val_loss: 0.8485 - val_acc: 0.8891\n","\n","Epoch 00049: val_acc improved from 0.88858 to 0.88914, saving model to /content/drive/My Drive/English Dataset/best_model_en_hi_ntl_e.hdf5\n","Epoch 50/50\n","476/476 [==============================] - 242s 507ms/step - loss: 0.4509 - acc: 0.9405 - val_loss: 0.8440 - val_acc: 0.8889\n","\n","Epoch 00050: val_acc did not improve from 0.88914\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3960aa9400>"]},"metadata":{"tags":[]},"execution_count":31}]},{"metadata":{"colab_type":"text","id":"VRdA-3G8Lee1"},"cell_type":"markdown","source":["#### 4.3 Save Model"]},{"metadata":{"colab_type":"code","id":"8B6oDJqsLee2","colab":{}},"cell_type":"code","source":["model.save_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"qFYkdLTcLee5"},"cell_type":"markdown","source":["#### 4.4 Load model"]},{"metadata":{"colab_type":"code","id":"NvWzXHqHMEe-","colab":{}},"cell_type":"code","source":["model.load_weights(os.path.join(root, 'nmt_weights_en_hi_ntl_e.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"y3s531y3Lee_"},"cell_type":"markdown","source":["### 5. Inference Setup"]},{"metadata":{"colab_type":"code","id":"IZapXObgLefC","colab":{}},"cell_type":"code","source":["# Encoder-decoder model that uses trained weights from the original model to make predictions"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"kA9ZktGiLefH"},"cell_type":"markdown","source":["#### 5.1 Inference Encoder"]},{"metadata":{"colab_type":"code","id":"xLp33CktLefJ","colab":{}},"cell_type":"code","source":["# Encoder model to create a thought vector from the input\n","inference_encoder = Model(encoder_inputs, encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"51w8NazaLefM"},"cell_type":"markdown","source":["#### 5.2 Inference Decoder"]},{"metadata":{"colab_type":"code","id":"YQjvRgCPLefN","colab":{}},"cell_type":"code","source":["# For each time step, the decoder states from previous timestep would act as inputs\n","decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n","decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# Embedding\n","decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n","                                                                               initial_state=decoder_states_inputs)\n","decoder_states_inference = [state_h_inference, state_c_inference]\n","\n","# Dense\n","decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"IL7B1qchLefP","colab":{}},"cell_type":"code","source":["# Decoder model\n","inference_decoder = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs_inference] + decoder_states_inference\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554817533561,"user_tz":-330,"elapsed":12109845,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"SvR0urBBLefR","outputId":"27ffbc57-7a08-4d36-9bc7-792369e800d5","colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["inference_encoder.summary()"],"execution_count":38,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoder_Inputs (InputLayer)  (None, None)              0         \n","_________________________________________________________________\n","English_Embedding_Layer_NT ( (None, None, 128)         1117568   \n","_________________________________________________________________\n","Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n","=================================================================\n","Total params: 1,249,152\n","Trainable params: 1,249,152\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554817533564,"user_tz":-330,"elapsed":12109160,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"PH3DCqVjLefV","outputId":"aea46be9-4e54-4c05-e50f-ad43b77caf7e","colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":["inference_decoder.summary()"],"execution_count":39,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Hindi_Embedding_Layer_NT (Embed (None, None, 128)    840448      Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Inference_Decoder_Output (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Inference_Decoder_Memory (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Hindi_Embedding_Layer_NT[1][0]   \n","                                                                 Inference_Decoder_Output[0][0]   \n","                                                                 Inference_Decoder_Memory[0][0]   \n","__________________________________________________________________________________________________\n","Decoder_Dense_NT (Dense)        (None, None, 6566)   847014      Decoder_LSTM[1][0]               \n","==================================================================================================\n","Total params: 1,819,046\n","Trainable params: 1,819,046\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"nlo9Ng46LefY"},"cell_type":"markdown","source":["#### 5.3 Decode sample sequeces"]},{"metadata":{"colab_type":"code","id":"3NUGmwBtLefZ","colab":{}},"cell_type":"code","source":["def decode_sequence(input_sequence):\n","    # Get thought vector by encoding the input sequence\n","    states_value = inference_encoder.predict(input_sequence)\n","    \n","    # Generate target sequence initialized with <START> character\n","    target_sequence = np.zeros((1, 1))\n","    target_sequence[0, 0] = target_dictionary['<START>']\n","    \n","    # To stop the recurrent loop\n","    stop_condition = False\n","    \n","    # Final sentence\n","    decoded_sentence = ''\n","    \n","    while not stop_condition:\n","        # Get next prediction\n","        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n","        \n","        # Get the token with max probability\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = target_reverse_dictionary[sampled_token_index]\n","        decoded_sentence += ' ' + sampled_word\n","        \n","        # Test for exit condition\n","        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n","            stop_condition = True\n","            \n","        # Update the target sequence with current prediction\n","        target_sequence = np.zeros((1, 1))\n","        target_sequence[0, 0] = sampled_token_index\n","        \n","        # Update states\n","        states_value = [h, c]\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"eehBSrbvLefc"},"cell_type":"markdown","source":["### 6. Evaluation on Train Dataset"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554817533568,"user_tz":-330,"elapsed":12106989,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"s2D1wd2NLefl","outputId":"58d9e05f-6016-420c-f016-51aee3044049","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["input_sequence = encode_input(['looking for work'])\n","decoded_sentence = decode_sequence(input_sequence)\n","' '.join(decoded_sentence.split()[:-1])"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'काम की कृपया को यह'"]},"metadata":{"tags":[]},"execution_count":41}]},{"metadata":{"colab_type":"code","id":"ApsARXqWtUcj","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}