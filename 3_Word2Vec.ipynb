{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lQHUvhlcSUR6",
    "outputId": "cec9fb2a-4666-4dd4-d135-3eaf17531ef0"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sblMzq0nSTa6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HrGr_l-STbA"
   },
   "outputs": [],
   "source": [
    "filename = os.path.join(root, 'mono.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ycVuwT3YSTbD",
    "outputId": "413088b6-67d8-4be9-92ff-4c20c2fd3612"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 463477\n"
     ]
    }
   ],
   "source": [
    "def read_data(filename):\n",
    "    words = list()\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        c = tf.compat.as_str(f.read(1))\n",
    "        \n",
    "        while c:\n",
    "            word = ''\n",
    "            \n",
    "            while c != ' ':\n",
    "                word += c\n",
    "                \n",
    "                c = tf.compat.as_str(f.read(1))\n",
    "            \n",
    "            words.append(word)\n",
    "                \n",
    "            c = tf.compat.as_str(f.read(1))\n",
    "            \n",
    "    return words\n",
    "\n",
    "words = read_data(filename)\n",
    "print(\"Data size %d\" % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sXJOKPjUTN_e",
    "outputId": "33a01b86-3f35-484a-faf5-2314b73687ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8730"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "qzxYNJAWSTbL",
    "outputId": "2cca520c-29c7-4f01-fa6b-74114e49c954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 0], ('the', 22887), ('to', 13574), ('a', 9482), ('you', 8308)]\n",
      "Sample data [177, 22, 228, 36, 1007, 3618, 1561, 1007, 2534, 1]\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(set(words)) +1\n",
    "\n",
    "def build_dataset(words):\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(vocabulary_size-1))\n",
    "    dictionary = dict()\n",
    "    \n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    \n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    \n",
    "    count[0][1] = unk_count\n",
    "    \n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(words)\n",
    "print(\"Most common words (+UNK)\", count[:5])\n",
    "print(\"Sample data\", data[:10])\n",
    "del words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "XgT6UcEpSTbO",
    "outputId": "fe31cfbf-7f29-4fd5-a220-a27af04b57a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: ['give', 'your', 'application', 'an', 'accessibility', 'workout', 'accerciser', 'accessibility']\n",
      "\n",
      "with num_skips = 2 and skip_window = 1:\n",
      "    batch: ['your', 'your', 'application', 'application', 'an', 'an', 'accessibility', 'accessibility']\n",
      "    labels: ['give', 'application', 'an', 'your', 'accessibility', 'application', 'workout', 'an']\n",
      "\n",
      "with num_skips = 4 and skip_window = 2:\n",
      "    batch: ['application', 'application', 'application', 'application', 'an', 'an', 'an', 'an']\n",
      "    labels: ['give', 'your', 'accessibility', 'an', 'accessibility', 'your', 'workout', 'application']\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "\n",
    "def generate_batch(batch_size, num_skips, skip_window):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    \n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1\n",
    "    buffer = collections.deque(maxlen=span)\n",
    "    \n",
    "    for _ in range(span):\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    \n",
    "    for i in range(batch_size // num_skips):\n",
    "        target = skip_window\n",
    "        targets_to_avoid = [skip_window]\n",
    "        \n",
    "        for j in range(num_skips):\n",
    "            while target in targets_to_avoid:\n",
    "                target = random.randint(0, span-1)\n",
    "            targets_to_avoid.append(target)\n",
    "            batch[i * num_skips + j] = buffer[skip_window]\n",
    "            labels[i * num_skips + j, 0] = buffer[target]\n",
    "        buffer.append(data[data_index])\n",
    "        data_index = (data_index + 1) % len(data)\n",
    "    return batch, labels\n",
    "\n",
    "print(\"Data:\", [reverse_dictionary[di] for di in data[:8]])\n",
    "\n",
    "for num_skips, skip_window in [(2, 1), (4, 2)]:\n",
    "    data_index = 0\n",
    "    batch, labels = generate_batch(batch_size=8, num_skips=num_skips, skip_window=skip_window)\n",
    "    print(\"\\nwith num_skips = %d and skip_window = %d:\" % (num_skips, skip_window))\n",
    "    print(\"    batch:\", [reverse_dictionary[bi] for bi in batch])\n",
    "    print(\"    labels:\", [reverse_dictionary[di] for di in labels.reshape(8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "nxiQasQjSTbS",
    "outputId": "aff61be9-e83e-48e5-b30e-9ea4e011590d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:1344: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 128\n",
    "skip_window = 1\n",
    "num_skips = 2\n",
    "valid_size = 16\n",
    "valid_window = 100\n",
    "valid_examples = np.array(random.sample(range(valid_window), valid_size))\n",
    "num_sampled = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default(), tf.device('/cpu:0'):\n",
    "    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "    softmax_weights = tf.Variable(tf.truncated_normal([vocabulary_size, embedding_size], stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "    \n",
    "    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n",
    "    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=softmax_weights, biases=softmax_biases, inputs=embed,\n",
    "                                                    labels=train_labels, num_sampled=num_sampled, num_classes=vocabulary_size))\n",
    "    \n",
    "    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n",
    "    \n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keepdims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7463
    },
    "colab_type": "code",
    "id": "GH8-7TyESTbV",
    "outputId": "74cb282b-0b00-4de3-f1dd-ed940a5013cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Average loss at step 0: 6.340580\n",
      "Nearest to go: stuttering, tenthirty, newlibrary…, rang, z, reached, faces, mountainous,\n",
      "Nearest to no: thursday, goodfornothing, bedrooms, prime, commenting, barbecue, consists, ugly,\n",
      "Nearest to should: cheers, kilo, debugger, queens, washed, alpha, blamed, variable…,\n",
      "Nearest to from: heroin, ammunition, buddhist, remind, gently, requires, invitation, grade,\n",
      "Nearest to with: undefined, forgave, proven, able, parenthese, fastball, price, acceptsave,\n",
      "Nearest to do: frozen, nap, norway, treaty, creative, sinners, jpg, gym,\n",
      "Nearest to my: imported, typhoon, distant, steak, software…, entity, disturbed, resulting,\n",
      "Nearest to if: entertaining, sdlimage, dial, gummy, lays, frame, thats, ask,\n",
      "Nearest to will: sworn, none, float, well, falls, sysfs, insect, meal,\n",
      "Nearest to one: merge, wheat, refcount, malformed, mince, indicated, dialed, backrub,\n",
      "Nearest to be: einstein, sieve, voices, expedited, read, permanently, philosophy, innumerable,\n",
      "Nearest to have: damacus, licenses, addon, xml, threes, together, globale, forklift,\n",
      "Nearest to dont: aggressive, wondering, peanut, incident, gather, screw, sinking, military,\n",
      "Nearest to know: adultery, place, caution, commerce, calcutta, doll, developers, only,\n",
      "Nearest to his: lend, closet, technology, pushes, margins, chased, bothers, advantage,\n",
      "Nearest to set: swim, caviar, numbers, wealthy, live, oiled, exgirlfriend, dots,\n",
      "Average loss at step 2000: 2.629986\n",
      "Average loss at step 4000: 2.488193\n",
      "Average loss at step 6000: 3.697950\n",
      "Average loss at step 8000: 2.571178\n",
      "Average loss at step 10000: 1.919287\n",
      "Nearest to go: vcdimager, come, forbarhebrew, chose, teach, z, fitness, fantastic,\n",
      "Nearest to no: considering, been, morocco, teachers, eighth, disappearing, italy, detroit,\n",
      "Nearest to should: heroin, can, atoms, popup, washed, arrogance, economically, capability,\n",
      "Nearest to from: garbage, compressed, heroin, screen, requires, database, arbfp, with,\n",
      "Nearest to with: parenthese, giraffes, autocomplete, price, jesus, from, liberal, acceptsave,\n",
      "Nearest to do: did, cvsheader, are, hockey, encodingsbarjapanese, jpg, you’ve, were,\n",
      "Nearest to my: his, her, your, toms, our, loses, beatnik, tom,\n",
      "Nearest to if: divorce, xyz, cattle, dies, forward, throwing, connecting…, functions,\n",
      "Nearest to will: can, antialias, specialist, investigating, jackson, perth, cant, as,\n",
      "Nearest to one: two, refcount, senate, compilation, clearhistory, england, plains, osmosis,\n",
      "Nearest to be: voices, third, greeks, sieve, join…, baltimore, smoke, goalkeeper,\n",
      "Nearest to have: damacus, imapsubfolder, want, imitate, chaucer, are, need, agnes,\n",
      "Nearest to dont: cant, didnt, comments, flown, breathe, choosen, am, monopoly,\n",
      "Nearest to know: want, downloader, throw, see, reopen, caution, dsl, imaginary,\n",
      "Nearest to his: my, her, toms, closely, speeds, roosevelt, citizens, your,\n",
      "Nearest to set: wealthy, everest, oiled, superpowers, traveled, options, saslmechanism, ownfonts,\n",
      "Average loss at step 12000: 2.589905\n",
      "Average loss at step 14000: 2.858740\n",
      "Average loss at step 16000: 1.735587\n",
      "Average loss at step 18000: 1.830444\n",
      "Average loss at step 20000: 2.876381\n",
      "Nearest to go: went, going, come, websites, stay, decide, chose, broccoli,\n",
      "Nearest to no: adaptation, goodfornothing, renamed, gay, teachers, considering, signature, morocco,\n",
      "Nearest to should: will, can, would, wont, motioned, might, popup, could,\n",
      "Nearest to from: heroin, dvdcss, garbage, gaga, with, presence, murders, decay,\n",
      "Nearest to with: in, to, parenthese, guitarist, pie, from, logic, acceptsave,\n",
      "Nearest to do: did, expressions, mexico, buy, speak, have, sow, cvsheader,\n",
      "Nearest to my: your, his, toms, her, our, the, beatnik, ináñez,\n",
      "Nearest to if: brunch, smallest, vomited, teach, connecting…, dies, divorce, adaptation,\n",
      "Nearest to will: cant, can, must, should, may, ill, antialias, could,\n",
      "Nearest to one: two, refcount, england, longer, appetite, plenty, senate, newspapers,\n",
      "Nearest to be: normalization, sinners, ride, come, join…, greeks, been, wake,\n",
      "Nearest to have: want, need, ive, has, were, damacus, yet, do,\n",
      "Nearest to dont: didnt, cant, doesnt, can, continuation, wont, trains, choosen,\n",
      "Nearest to know: need, knows, want, see, found, laugh, noguchi, understand,\n",
      "Nearest to his: her, my, your, our, toms, andy, community, marys,\n",
      "Nearest to set: driving, addbookmark…, traveled, plates, chocolates, saslmechanism, everest, superpowers,\n",
      "Average loss at step 22000: 2.052005\n",
      "Average loss at step 24000: 1.672658\n",
      "Average loss at step 26000: 2.362910\n",
      "Average loss at step 28000: 2.467690\n",
      "Average loss at step 30000: 1.641777\n",
      "Nearest to go: plates, maximumjitter, went, chose, decide, canary, sickness, transcode,\n",
      "Nearest to no: detroit, been, eighth, teachers, renamed, shanghai, goodfornothing, nails,\n",
      "Nearest to should: can, will, org, did, affair, motioned, memory, ©,\n",
      "Nearest to from: vietnamese, garbage, heroin, constitution, barin, clearall, dvdcss, snapped,\n",
      "Nearest to with: parenthese, price, deer, harrisons, proven, liberal, churches, manipulate,\n",
      "Nearest to do: did, are, execute, cvsheader, karima, buy, expressions, inaccurate,\n",
      "Nearest to my: her, his, toms, our, your, marys, ináñez, bookmarksbarmost,\n",
      "Nearest to if: divorce, may, identity, smallest, sexual, cdrkit, highly, whitespaces,\n",
      "Nearest to will: may, cant, should, can, could, must, antialias, communism,\n",
      "Nearest to one: venice, two, refcount, longer, begining, senate, otoole, contact,\n",
      "Nearest to be: been, voices, smoke, have, normalization, goalkeeper, experiment, baltimore,\n",
      "Nearest to have: damacus, want, need, stubborn, be, imitate, mosques, debug,\n",
      "Nearest to dont: didnt, cant, doesnt, wouldnt, may, wont, trains, am,\n",
      "Nearest to know: need, want, knows, laugh, understand, noguchi, downloader, throw,\n",
      "Nearest to his: my, her, our, toms, your, marys, syne, common,\n",
      "Nearest to set: tower, extents, saslmechanism, bounding, everest, nile, plates, abnormal,\n",
      "Average loss at step 32000: 1.764108\n",
      "Average loss at step 34000: 2.638814\n",
      "Average loss at step 36000: 1.793865\n",
      "Average loss at step 38000: 1.588282\n",
      "Average loss at step 40000: 2.337518\n",
      "Nearest to go: went, going, broccoli, sickness, timetable, teach, websites, decide,\n",
      "Nearest to no: goodfornothing, teachers, renamed, gay, authentification, eighth, morocco, yakitori,\n",
      "Nearest to should: will, did, can, huh, anyway, must, heroin, dont,\n",
      "Nearest to from: heroin, gaga, dvdcss, on, compressed, presence, drama, snapped,\n",
      "Nearest to with: parenthese, in, churches, muhammad, fired, traditionally, shadows, shepard,\n",
      "Nearest to do: buy, matching, reap, eat, did, like, learn, she,\n",
      "Nearest to my: your, his, our, toms, skating, her, ináñez, thai,\n",
      "Nearest to if: smallest, may, fried, divorce, thats, symlink, functions, arent,\n",
      "Nearest to will: should, cant, must, ill, could, can, may, clarinetist,\n",
      "Nearest to one: longer, two, refcount, nothing, england, appetite, newspapers, secondhand,\n",
      "Nearest to be: attack, walk, everybody, been, behave, voices, join…, not,\n",
      "Nearest to have: want, need, had, m, ordered, wish, damacus, brazilian,\n",
      "Nearest to dont: didnt, cant, wouldnt, doesnt, wont, you, may, trains,\n",
      "Nearest to know: want, need, understand, forget, knows, see, remember, laugh,\n",
      "Nearest to his: her, my, our, your, toms, marys, he, andy,\n",
      "Nearest to set: driving, addbookmark…, saslmechanism, wealthy, everest, extent, traveled, superpowers,\n",
      "Average loss at step 42000: 2.281899\n",
      "Average loss at step 44000: 1.526574\n",
      "Average loss at step 46000: 1.789275\n",
      "Average loss at step 48000: 2.521681\n",
      "Average loss at step 50000: 1.718467\n",
      "Nearest to go: went, teach, plates, sickness, maximumjitter, decide, sandy, “online”,\n",
      "Nearest to no: districts, goodfornothing, bearing, missing, checkimap, considering, library…, detroit,\n",
      "Nearest to should: will, can, memory, must, vob, org, anyway, notice,\n",
      "Nearest to from: barin, clearall, on, substitute, snapped, “smb”, decay, database,\n",
      "Nearest to with: parenthese, harrisons, typical, deleteall, pepperoni, stylesheet, shiitake, gdb,\n",
      "Nearest to do: did, buy, will, karima, expressions, reap, don, execute,\n",
      "Nearest to my: her, toms, our, his, bookmarksbarmost, your, marys, ebay,\n",
      "Nearest to if: divorce, neighborhood, symlink, smallest, connecting…, may, sexual, pipeline,\n",
      "Nearest to will: should, can, cant, must, could, processtree, may, antialias,\n",
      "Nearest to one: two, longer, appetite, encodingsbartraditional, venice, demands, nothing, congas,\n",
      "Nearest to be: been, goalkeeper, attack, have, permanently, products, allies, experiment,\n",
      "Nearest to have: need, want, imitate, damacus, provide, shouldve, mosques, be,\n",
      "Nearest to dont: didnt, cant, doesnt, wouldnt, wont, trains, choosen, cannot,\n",
      "Nearest to know: want, understand, need, knows, laugh, lie, celebrating, accessibles,\n",
      "Nearest to his: her, our, toms, my, your, syne, marys, citizens,\n",
      "Nearest to set: driving, bounding, addbookmark…, extent, layered, stop, ask, tower,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss at step 52000: 1.477781\n",
      "Average loss at step 54000: 2.339341\n",
      "Average loss at step 56000: 2.129961\n",
      "Average loss at step 58000: 1.450757\n",
      "Average loss at step 60000: 1.861714\n",
      "Nearest to go: went, going, teach, broccoli, bilinear, sandy, sickness, help,\n",
      "Nearest to no: teachers, goodfornothing, districts, irresponsible, blondes, gay, authentification, detroit,\n",
      "Nearest to should: will, can, huh, must, did, won, motioned, wont,\n",
      "Nearest to from: heroin, gaga, murders, includes, forgave, faucet, garbage, clearall,\n",
      "Nearest to with: parenthese, recognize, traditionally, churches, goggles, fired, phone, logic,\n",
      "Nearest to do: buy, understood, matching, eat, did, crybaby, reap, ski,\n",
      "Nearest to my: your, our, his, toms, marys, the, wheres, bookmarksbarmost,\n",
      "Nearest to if: smallest, symlink, neighborhood, look, sexual, highly, whitespaces, fried,\n",
      "Nearest to will: cant, should, must, can, may, ill, wont, to,\n",
      "Nearest to one: senate, longer, two, colds, refcount, venice, war, somebody,\n",
      "Nearest to be: attack, been, he, greeks, goalkeeper, voices, bit, escape,\n",
      "Nearest to have: want, need, had, m, buy, oclock, damacus, holiday,\n",
      "Nearest to dont: didnt, doesnt, cant, wouldnt, owe, can, wont, nauseous,\n",
      "Nearest to know: forget, understand, knows, need, want, understood, mean, laugh,\n",
      "Nearest to his: our, your, my, her, marys, published, health, andy,\n",
      "Nearest to set: saslmechanism, driving, pillows, layered, addbookmark…, she, bounding, tower,\n",
      "Average loss at step 62000: 2.436113\n",
      "Average loss at step 64000: 1.624965\n",
      "Average loss at step 66000: 1.424004\n",
      "Average loss at step 68000: 2.373896\n",
      "Average loss at step 70000: 2.006319\n",
      "Nearest to go: went, sickness, teach, going, decide, stay, scrub, transcode,\n",
      "Nearest to no: districts, hundreds, considering, checkimap, xul, missing, bearing, portrait,\n",
      "Nearest to should: will, wont, can, huh, won, heroin, anyway, vob,\n",
      "Nearest to from: sevens, heroin, on, tutorials, clearall, dvdcss, barin, constitution,\n",
      "Nearest to with: parenthese, in, traditionally, typical, native, goggles, harrisons, docked,\n",
      "Nearest to do: did, buy, reap, expressions, don, cvsheader, sow, matching,\n",
      "Nearest to my: his, her, marys, toms, our, bookmarksbarmost, your, skating,\n",
      "Nearest to if: repositry, connecting…, pipeline, highly, sexual, whitespaces, symlink, forward,\n",
      "Nearest to will: should, can, could, antialias, processtree, must, cant, ill,\n",
      "Nearest to one: two, colds, senate, independence, secondhand, encodingsbartraditional, congas, longer,\n",
      "Nearest to be: attack, goalkeeper, normalization, become, allies, permanently, seahaven, baltimore,\n",
      "Nearest to have: need, want, ive, shouldve, imitate, had, havent, provide,\n",
      "Nearest to dont: didnt, cant, doesnt, wouldnt, wont, trains, owe, cannot,\n",
      "Nearest to know: understand, want, need, knows, laugh, celebrating, forget, remember,\n",
      "Nearest to his: my, her, our, toms, your, marys, syne, authorization,\n",
      "Nearest to set: saslmechanism, driving, extents, markers, enableall, bounding, authentic, fit,\n",
      "Average loss at step 72000: 1.415657\n",
      "Average loss at step 74000: 1.923058\n",
      "Average loss at step 76000: 2.375341\n",
      "Average loss at step 78000: 1.522501\n",
      "Average loss at step 80000: 1.414463\n",
      "Nearest to go: went, plates, teach, pack, sickness, sandy, come, draftbox,\n",
      "Nearest to no: missing, districts, teachers, portrait, gay, toc, considering, blondes,\n",
      "Nearest to should: will, huh, can, dial, tidy, heroin, dwelling, org,\n",
      "Nearest to from: heroin, displaying, snapped, vietnamese, decay, clearall, collection, colorize,\n",
      "Nearest to with: parenthese, autocomplete, jhbuild, stylesheet, typical, link…, minimum, swallowed,\n",
      "Nearest to do: did, are, don, buy, protocol, asdata, vps, matching,\n",
      "Nearest to my: your, our, leadout, his, toms, marys, her, machines,\n",
      "Nearest to if: smallest, whitespaces, neighborhood, symlink, sexual, thorough, highly, bold,\n",
      "Nearest to will: should, must, can, processtree, could, may, ill, cant,\n",
      "Nearest to one: senate, two, congas, factor, opens, colds, markers, switches,\n",
      "Nearest to be: been, goalkeeper, permanently, behave, halloween, have, resulting, allies,\n",
      "Nearest to have: need, want, imitate, colds, damacus, mosques, be, css,\n",
      "Nearest to dont: didnt, cant, wouldnt, doesnt, trains, wont, owe, havent,\n",
      "Nearest to know: understand, need, forget, want, celebrating, remember, prove, verify,\n",
      "Nearest to his: toms, her, marys, our, my, syne, honshu, citizens,\n",
      "Nearest to set: fit, driving, pillows, tower, layered, printed, addbookmark…, revoked,\n",
      "Average loss at step 82000: 2.394325\n",
      "Average loss at step 84000: 1.877731\n",
      "Average loss at step 86000: 1.436717\n",
      "Average loss at step 88000: 1.953875\n",
      "Average loss at step 90000: 2.283966\n",
      "Nearest to go: went, come, teach, going, wake, stay, sickness, cry,\n",
      "Nearest to no: goodfornothing, missing, rebel, portrait, hundreds, districts, bearing, blondes,\n",
      "Nearest to should: will, huh, can, wont, did, motioned, cant, chapstick,\n",
      "Nearest to from: heroin, aliens, faucet, forgave, vietnamese, constitution, includes, forbarunified,\n",
      "Nearest to with: parenthese, traditionally, goggles, guest, swallowed, docked, typical, logic,\n",
      "Nearest to do: buy, barack, reap, did, homeless, chew, teach, forgive,\n",
      "Nearest to my: your, her, his, bookmarksbarmost, our, marys, toms, compared,\n",
      "Nearest to if: sexual, dont, when, smallest, paying, packets, repositry, homestead,\n",
      "Nearest to will: should, can, cant, wont, could, must, ill, may,\n",
      "Nearest to one: two, colds, longer, senate, forest, newspapers, tokyo, independence,\n",
      "Nearest to be: attack, allies, become, been, look, get, take, behave,\n",
      "Nearest to have: ive, need, want, had, havent, trains, shouldve, colds,\n",
      "Nearest to dont: cant, wouldnt, didnt, doesnt, can, wont, cannot, may,\n",
      "Nearest to know: understand, remember, want, forget, need, celebrating, touch, understood,\n",
      "Nearest to his: our, my, your, her, toms, syne, marys, sentenced,\n",
      "Nearest to set: driving, layered, pillows, fit, revoked, extent, marconi, printed,\n",
      "Average loss at step 92000: 1.460043\n",
      "Average loss at step 94000: 1.438633\n",
      "Average loss at step 96000: 2.416611\n",
      "Average loss at step 98000: 1.763228\n",
      "Average loss at step 100000: 1.459321\n",
      "Nearest to go: teach, went, sickness, sandy, maximumjitter, transcode, “online”, folk,\n",
      "Nearest to no: portrait, bearing, districts, toc, missing, goodfornothing, earning, there,\n",
      "Nearest to should: will, huh, memory, heroin, can, motioned, objective, org,\n",
      "Nearest to from: vietnamese, tutorials, snapped, heroin, presence, barin, suspend, decay,\n",
      "Nearest to with: parenthese, jhbuild, deleteall, stylesheet, typical, price, proceeding, without,\n",
      "Nearest to do: did, are, buy, don, closedtab, protocol, asdata, gamma,\n",
      "Nearest to my: his, our, bookmarksbarmost, toms, your, marys, leadout, her,\n",
      "Nearest to if: forward, neighborhood, repositry, whitespaces, smallest, sexual, canceled, symlink,\n",
      "Nearest to will: should, could, may, must, can, processtree, communism, fontconfig,\n",
      "Nearest to one: two, senate, giants, linear, congas, colds, longer, rabat,\n",
      "Nearest to be: have, been, greeks, resulting, experiment, baltimore, seahaven, permanently,\n",
      "Nearest to have: need, imitate, be, want, shouldve, damacus, mosques, colds,\n",
      "Nearest to dont: didnt, wouldnt, doesnt, cant, wont, trains, owe, justice,\n",
      "Nearest to know: understand, want, mean, need, remember, verify, laugh, celebrating,\n",
      "Nearest to his: our, my, her, marys, toms, syne, jpg, honshu,\n",
      "Nearest to set: shrink, driving, fit, pillows, addbookmark…, entertaining, hummingbird, marconi,\n"
     ]
    }
   ],
   "source": [
    "num_steps = 100001\n",
    "loss_list = list()\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(\"Initialized\")\n",
    "    average_loss = 0\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        batch_data, batch_labels = generate_batch(batch_size, num_skips, skip_window)\n",
    "        feed_dict = {train_dataset:batch_data, train_labels:batch_labels}\n",
    "        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n",
    "        average_loss += l\n",
    "        \n",
    "        if step % 2000 == 0:\n",
    "            if step > 0:\n",
    "                average_loss = average_loss / 2000\n",
    "            \n",
    "            print(\"Average loss at step %d: %f\" % (step, average_loss))\n",
    "            loss_list.append(average_loss)\n",
    "            \n",
    "            average_loss = 0\n",
    "        \n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in range(valid_size):\n",
    "                valid_word = reverse_dictionary[valid_examples[i]]\n",
    "                top_k = 8\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                log = 'Nearest to %s:' % valid_word\n",
    "                for k in range(top_k):\n",
    "                    close_word = reverse_dictionary[nearest[k]]\n",
    "                    log = '%s %s,' % (log, close_word)\n",
    "                print(log)\n",
    "    final_embeddings = normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "6Mr5Q6PiT83x",
    "outputId": "2751fae5-13b8-4f55-a387-3980ddf313f0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(range(0, 100001, 2000)), loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1pxA-9mSTbZ"
   },
   "outputs": [],
   "source": [
    "output = {\n",
    "    'embeddings': final_embeddings,\n",
    "    'dictionary': dictionary,\n",
    "    'reverse_dictionary': reverse_dictionary\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-1QXDppfSTbc"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'embeddings.en'), 'wb') as f:\n",
    "    pickle.dump(output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3_Word2Vec.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
