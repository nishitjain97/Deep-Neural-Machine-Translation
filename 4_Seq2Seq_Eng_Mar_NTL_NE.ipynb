{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_Seq2Seq_Eng_Mar_NTL_NE.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"gwTL36ttLedG","colab_type":"code","outputId":"524a74cb-b89f-4b2f-d3e7-9efb444b7878","executionInfo":{"status":"ok","timestamp":1554647017331,"user_tz":-330,"elapsed":27067,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["# To mount Google drive on Google Colab environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","root = '/content/drive/My Drive/English Dataset'\n","# root = '.'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"Eb0tHTz1LedM","colab_type":"text"},"cell_type":"markdown","source":["### 1. Packages"]},{"metadata":{"id":"92RA6N5fLedO","colab_type":"code","outputId":"4846f9ac-5957-4d73-ada2-d20e4a7ca872","executionInfo":{"status":"ok","timestamp":1554647020992,"user_tz":-330,"elapsed":2457,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","import re\n","import os\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","from string import digits"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"q5-UJzoBLedS","colab_type":"text"},"cell_type":"markdown","source":["### 2. Data Preparation"]},{"metadata":{"id":"qEj_b0VSLedT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Read dataset\n","lines = pd.read_pickle(os.path.join(root, 'mar-eng_cleaned.parallel'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D787xMeLLedV","colab_type":"code","outputId":"39f0a78d-49d6-4734-c581-9fda8fd90dcc","executionInfo":{"status":"ok","timestamp":1554647030105,"user_tz":-330,"elapsed":1227,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# View the shape of dataset\n","lines.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33725, 2)"]},"metadata":{"tags":[]},"execution_count":5}]},{"metadata":{"id":"ZsqG7aFTLedd","colab_type":"code","colab":{}},"cell_type":"code","source":["# Add 'start' and 'end' tokens to target sentences\n","lines.Mar = lines.Mar.apply(lambda x: '<START> ' + x + ' <END>')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GbGtP_6VLedh","colab_type":"code","outputId":"ddd76360-2e94-4837-ce8d-a0319c1c43e4","executionInfo":{"status":"ok","timestamp":1554647034726,"user_tz":-330,"elapsed":1452,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# View a few samples of the dataset\n","lines.sample(5)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Mar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>32500</th>\n","      <td>all of the students at our school study french</td>\n","      <td>&lt;START&gt; आमच्या शाळेतील सर्व विद्यार्थी फ्रेंच ...</td>\n","    </tr>\n","    <tr>\n","      <th>12535</th>\n","      <td>tom wants a sandwich</td>\n","      <td>&lt;START&gt; टॉमला सँडविच हवं आहे &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>30684</th>\n","      <td>tom used to play the guitar didnt he</td>\n","      <td>&lt;START&gt; टॉम गिटार वाजवायचा नाही का &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>16749</th>\n","      <td>i want to sing the song</td>\n","      <td>&lt;START&gt; मला ते गाणं गायचं आहे &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>13841</th>\n","      <td>my uncle plays guitar</td>\n","      <td>&lt;START&gt; माझा मामा गिटार वाजवतो &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                  Eng  \\\n","32500  all of the students at our school study french   \n","12535                            tom wants a sandwich   \n","30684            tom used to play the guitar didnt he   \n","16749                         i want to sing the song   \n","13841                           my uncle plays guitar   \n","\n","                                                     Mar  \n","32500  <START> आमच्या शाळेतील सर्व विद्यार्थी फ्रेंच ...  \n","12535                 <START> टॉमला सँडविच हवं आहे <END>  \n","30684           <START> टॉम गिटार वाजवायचा नाही का <END>  \n","16749                <START> मला ते गाणं गायचं आहे <END>  \n","13841               <START> माझा मामा गिटार वाजवतो <END>  "]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"-_i-8ssyLedl","colab_type":"code","colab":{}},"cell_type":"code","source":["# English vocabulary\n","all_eng_words = set()\n","for line in lines.Eng:\n","    for word in line.split():\n","        all_eng_words.add(word)\n","        \n","# Marathi vocabulary\n","all_mar_words = set()\n","for line in lines.Mar:\n","    for word in line.split():\n","        all_mar_words.add(word)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7QZaq1bQLedo","colab_type":"code","outputId":"0b7c956a-c161-471a-e834-e3a17b213e9a","executionInfo":{"status":"ok","timestamp":1554647040458,"user_tz":-330,"elapsed":975,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of source sequence\n","max_length_src = 0\n","\n","for line in lines.Eng:\n","    if len(line.split(' ')) > max_length_src:\n","        max_length_src = len(line.split(' '))\n","        \n","max_length_src"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"SHtikVcQLedu","colab_type":"code","outputId":"ca0e3cd0-6933-42e2-d638-eef34906ee73","executionInfo":{"status":"ok","timestamp":1554647042449,"user_tz":-330,"elapsed":1149,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of target sequence\n","max_length_tar = 0\n","\n","for line in lines.Mar:\n","    if len(line.split(' ')) > max_length_tar:\n","        max_length_tar = len(line.split(' '))\n","        \n","max_length_tar"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"Eaj5LOJgLedz","colab_type":"code","outputId":"cc6c7f65-2689-4364-9447-00206f4fac3b","executionInfo":{"status":"ok","timestamp":1554647045266,"user_tz":-330,"elapsed":1305,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["num_encoder_tokens = len(all_eng_words)\n","num_decoder_tokens = len(all_mar_words) + 1\n","num_encoder_tokens, num_decoder_tokens"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5388, 12698)"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"id":"FNryqdRvLed3","colab_type":"code","colab":{}},"cell_type":"code","source":["source_dictionary = dict([(word, i+1) for i, word in enumerate(sorted(all_eng_words))])\n","target_dictionary = dict([(word, i+1) for i, word in enumerate(sorted(all_mar_words))])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W0bt1VxLLed5","colab_type":"code","colab":{}},"cell_type":"code","source":["source_reverse_dictionary = dict([(i, word) for word, i in source_dictionary.items()])\n","target_reverse_dictionary = dict([(i, word) for word, i in target_dictionary.items()])"],"execution_count":0,"outputs":[]},{"metadata":{"scrolled":true,"id":"v9Z2BiygLed9","colab_type":"code","outputId":"a6f3b8fb-030d-4ab3-9683-bd7873a396cd","executionInfo":{"status":"ok","timestamp":1554647050189,"user_tz":-330,"elapsed":724,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":359}},"cell_type":"code","source":["lines = shuffle(lines)\n","lines.head(10)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Mar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1664</th>\n","      <td>give me a day</td>\n","      <td>&lt;START&gt; मला एक दिवस दे &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>7627</th>\n","      <td>are you really tom</td>\n","      <td>&lt;START&gt; तू खरच टॉम आहेस का &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4856</th>\n","      <td>he was in france</td>\n","      <td>&lt;START&gt; ते फ्रान्समध्ये होते &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>23695</th>\n","      <td>it was dark under the bridge</td>\n","      <td>&lt;START&gt; पुलाखाली अंधार होता &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>6816</th>\n","      <td>she must be angry</td>\n","      <td>&lt;START&gt; तिला राग आलेला असेल &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>19239</th>\n","      <td>do they know that we know</td>\n","      <td>&lt;START&gt; आपल्याला माहीत आहे हे त्यांना माहीत आह...</td>\n","    </tr>\n","    <tr>\n","      <th>9883</th>\n","      <td>i used to play here</td>\n","      <td>&lt;START&gt; मी इथे वाजवायचो &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>28038</th>\n","      <td>they speak english in new zealand</td>\n","      <td>&lt;START&gt; न्यूझीलंडमध्ये इंग्रजी बोलली जाते &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>27303</th>\n","      <td>tell us what happened that night</td>\n","      <td>&lt;START&gt; त्या रात्री काय घडलं हे आम्हाला सांग &lt;...</td>\n","    </tr>\n","    <tr>\n","      <th>9870</th>\n","      <td>i think she is sick</td>\n","      <td>&lt;START&gt; मला वाटतं ती आजारी आहे &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                     Eng  \\\n","1664                       give me a day   \n","7627                  are you really tom   \n","4856                    he was in france   \n","23695       it was dark under the bridge   \n","6816                   she must be angry   \n","19239          do they know that we know   \n","9883                 i used to play here   \n","28038  they speak english in new zealand   \n","27303   tell us what happened that night   \n","9870                 i think she is sick   \n","\n","                                                     Mar  \n","1664                        <START> मला एक दिवस दे <END>  \n","7627                    <START> तू खरच टॉम आहेस का <END>  \n","4856                  <START> ते फ्रान्समध्ये होते <END>  \n","23695                  <START> पुलाखाली अंधार होता <END>  \n","6816                   <START> तिला राग आलेला असेल <END>  \n","19239  <START> आपल्याला माहीत आहे हे त्यांना माहीत आह...  \n","9883                       <START> मी इथे वाजवायचो <END>  \n","28038    <START> न्यूझीलंडमध्ये इंग्रजी बोलली जाते <END>  \n","27303  <START> त्या रात्री काय घडलं हे आम्हाला सांग <...  \n","9870                <START> मला वाटतं ती आजारी आहे <END>  "]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"OpwDCXjSLeeC","colab_type":"text"},"cell_type":"markdown","source":["### 3. Batch Generator"]},{"metadata":{"id":"7bUerHhNLeeD","colab_type":"code","colab":{}},"cell_type":"code","source":["def encode_input(X):\n","    \"\"\"\n","        X = batch of inputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(X)\n","    \n","    # Create a numpy array of zeros to hold input\n","    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n","    \n","    for i, input_text in enumerate(X):\n","        for t, word in enumerate(input_text.split()):\n","            encoder_input_data[i, t] = source_dictionary[word]\n","            \n","    return encoder_input_data\n","\n","def encode_target(y):\n","    \"\"\"\n","        y = batch of outputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(y)\n","    \n","    # Create numpy arrays of zeros to hold encoded targets\n","    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n","    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n","    \n","    for i, target_text in enumerate(y):\n","        for t, word in enumerate(target_text.split()):\n","            if t < len(target_text.split()) - 1:\n","                decoder_input_data[i, t] = target_dictionary[word]\n","                \n","            if t > 0:\n","                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n","                \n","    return decoder_input_data, decoder_target_data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GiOFeb9vLeeH","colab_type":"code","colab":{}},"cell_type":"code","source":["def generate_batch(X, y, batch_size=128):\n","    \"\"\"\n","        X = Source dataset\n","        y = Target dataset\n","        batch_size = Size of each batch\n","    \"\"\"\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            encoder_input_data = encode_input(X[j:j+batch_size])\n","            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n","            \n","            yield([encoder_input_data, decoder_input_data], decoder_target_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V-x4hM2sLeeL","colab_type":"text"},"cell_type":"markdown","source":["### 4. Encoder - Decoder Model Architecture"]},{"metadata":{"id":"1UtH1Hp3LeeN","colab_type":"code","outputId":"121a81d5-90b8-4370-82be-382ef99891af","executionInfo":{"status":"ok","timestamp":1554647056691,"user_tz":-330,"elapsed":1130,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Train-test split\n","X, y = lines.Eng, lines.Mar\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","X_train.shape, X_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((30352,), (3373,))"]},"metadata":{"tags":[]},"execution_count":17}]},{"metadata":{"id":"2CUiDGfCLeeS","colab_type":"code","colab":{}},"cell_type":"code","source":["latent_dim = 128"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H6hMfdyQLeeW","colab_type":"code","colab":{}},"cell_type":"code","source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","batch_size = 128\n","epochs = 50"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IxWNZCbELeeZ","colab_type":"text"},"cell_type":"markdown","source":["#### 4.1 Encoder"]},{"metadata":{"id":"aGdBX4MhLeeZ","colab_type":"code","outputId":"d65a0535-7b7e-4a06-f99c-13e599670e3f","executionInfo":{"status":"ok","timestamp":1554647063252,"user_tz":-330,"elapsed":1262,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["# Inputs\n","encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n","\n","# Embedding Lookup\n","encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, name='English_Embedding_Layer')\n","encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n","\n","# LSTM\n","encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n","\n","# Keeping only the states and discarding encoder outputs\n","encoder_states = [state_h, state_c]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"id":"TqcAW1TRLeed","colab_type":"text"},"cell_type":"markdown","source":["#### 4.2 Decoder"]},{"metadata":{"id":"pT4GcwdKLeee","colab_type":"code","colab":{}},"cell_type":"code","source":["# Inputs\n","decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n","\n","# Embedding\n","decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, name='Marathi_Embedding_Layer')\n","decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n","decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n","\n","# Dense output layer\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7zUNups0Leei","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define a model with these layers\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EmPdHO_sLeel","colab_type":"code","outputId":"45188734-773f-4f40-a0b7-545b6d3d703f","executionInfo":{"status":"ok","timestamp":1554647070780,"user_tz":-330,"elapsed":907,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":428}},"cell_type":"code","source":["# Take a look at the model\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Encoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","English_Embedding_Layer (Embedd (None, None, 128)    689664      Encoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer[0][0]    \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[0][0]    \n","                                                                 Encoder_LSTM[0][1]               \n","                                                                 Encoder_LSTM[0][2]               \n","__________________________________________________________________________________________________\n","Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[0][0]               \n","==================================================================================================\n","Total params: 4,216,218\n","Trainable params: 4,216,218\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"U-Upu1etLeep","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tJGZXMmsLeev","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create checkpoints to save model from time to time\n","filepath = os.path.join(root, 'best_model_en_ma.hdf5')\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z-FyOS1lLeey","colab_type":"code","outputId":"ba55301a-8dca-43c2-b2a2-eedb123dab9d","executionInfo":{"status":"ok","timestamp":1554652290308,"user_tz":-330,"elapsed":3725559,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":3590}},"cell_type":"code","source":["model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n","                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n","                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Epoch 1/50\n","237/237 [==============================] - 107s 454ms/step - loss: 6.0456 - acc: 0.1947 - val_loss: 5.5243 - val_acc: 0.2194\n","\n","Epoch 00001: val_acc improved from -inf to 0.21940, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/50\n","237/237 [==============================] - 103s 435ms/step - loss: 5.2911 - acc: 0.2394 - val_loss: 5.1407 - val_acc: 0.2616\n","\n","Epoch 00002: val_acc improved from 0.21940 to 0.26159, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 3/50\n","237/237 [==============================] - 103s 434ms/step - loss: 4.9254 - acc: 0.2734 - val_loss: 4.8531 - val_acc: 0.2914\n","\n","Epoch 00003: val_acc improved from 0.26159 to 0.29135, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 4/50\n","237/237 [==============================] - 103s 434ms/step - loss: 4.6141 - acc: 0.3037 - val_loss: 4.6092 - val_acc: 0.3224\n","\n","Epoch 00004: val_acc improved from 0.29135 to 0.32243, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 5/50\n","237/237 [==============================] - 103s 436ms/step - loss: 4.3319 - acc: 0.3381 - val_loss: 4.4380 - val_acc: 0.3465\n","\n","Epoch 00005: val_acc improved from 0.32243 to 0.34649, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 6/50\n","237/237 [==============================] - 103s 436ms/step - loss: 4.0803 - acc: 0.3674 - val_loss: 4.2341 - val_acc: 0.3736\n","\n","Epoch 00006: val_acc improved from 0.34649 to 0.37357, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 7/50\n","237/237 [==============================] - 103s 434ms/step - loss: 3.8561 - acc: 0.3937 - val_loss: 4.0624 - val_acc: 0.3945\n","\n","Epoch 00007: val_acc improved from 0.37357 to 0.39446, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 8/50\n","237/237 [==============================] - 103s 434ms/step - loss: 3.6492 - acc: 0.4184 - val_loss: 3.9050 - val_acc: 0.4192\n","\n","Epoch 00008: val_acc improved from 0.39446 to 0.41920, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 9/50\n","237/237 [==============================] - 103s 435ms/step - loss: 3.4563 - acc: 0.4419 - val_loss: 3.7722 - val_acc: 0.4355\n","\n","Epoch 00009: val_acc improved from 0.41920 to 0.43550, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 10/50\n","237/237 [==============================] - 104s 438ms/step - loss: 3.2802 - acc: 0.4640 - val_loss: 3.6361 - val_acc: 0.4532\n","\n","Epoch 00010: val_acc improved from 0.43550 to 0.45319, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 11/50\n","237/237 [==============================] - 103s 436ms/step - loss: 3.1195 - acc: 0.4850 - val_loss: 3.5410 - val_acc: 0.4676\n","\n","Epoch 00011: val_acc improved from 0.45319 to 0.46758, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 12/50\n","237/237 [==============================] - 103s 435ms/step - loss: 2.9742 - acc: 0.5058 - val_loss: 3.4520 - val_acc: 0.4760\n","\n","Epoch 00012: val_acc improved from 0.46758 to 0.47597, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 13/50\n","237/237 [==============================] - 103s 436ms/step - loss: 2.8460 - acc: 0.5250 - val_loss: 3.3833 - val_acc: 0.4905\n","\n","Epoch 00013: val_acc improved from 0.47597 to 0.49054, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 14/50\n","237/237 [==============================] - 103s 434ms/step - loss: 2.7289 - acc: 0.5424 - val_loss: 3.3035 - val_acc: 0.4980\n","\n","Epoch 00014: val_acc improved from 0.49054 to 0.49801, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 15/50\n","237/237 [==============================] - 104s 439ms/step - loss: 2.6218 - acc: 0.5593 - val_loss: 3.2245 - val_acc: 0.5112\n","\n","Epoch 00015: val_acc improved from 0.49801 to 0.51119, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 16/50\n","237/237 [==============================] - 103s 437ms/step - loss: 2.5196 - acc: 0.5747 - val_loss: 3.1717 - val_acc: 0.5192\n","\n","Epoch 00016: val_acc improved from 0.51119 to 0.51917, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 17/50\n","237/237 [==============================] - 104s 437ms/step - loss: 2.4259 - acc: 0.5899 - val_loss: 3.1154 - val_acc: 0.5283\n","\n","Epoch 00017: val_acc improved from 0.51917 to 0.52831, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 18/50\n","237/237 [==============================] - 104s 438ms/step - loss: 2.3421 - acc: 0.6039 - val_loss: 3.0873 - val_acc: 0.5326\n","\n","Epoch 00018: val_acc improved from 0.52831 to 0.53257, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 19/50\n","237/237 [==============================] - 103s 436ms/step - loss: 2.2692 - acc: 0.6173 - val_loss: 3.0502 - val_acc: 0.5395\n","\n","Epoch 00019: val_acc improved from 0.53257 to 0.53952, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 20/50\n","237/237 [==============================] - 104s 438ms/step - loss: 2.2000 - acc: 0.6296 - val_loss: 3.0080 - val_acc: 0.5449\n","\n","Epoch 00020: val_acc improved from 0.53952 to 0.54492, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 21/50\n","237/237 [==============================] - 104s 438ms/step - loss: 2.1356 - acc: 0.6414 - val_loss: 2.9727 - val_acc: 0.5501\n","\n","Epoch 00021: val_acc improved from 0.54492 to 0.55015, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 22/50\n","237/237 [==============================] - 104s 438ms/step - loss: 2.0752 - acc: 0.6521 - val_loss: 2.9401 - val_acc: 0.5545\n","\n","Epoch 00022: val_acc improved from 0.55015 to 0.55449, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 23/50\n","237/237 [==============================] - 104s 441ms/step - loss: 2.0188 - acc: 0.6625 - val_loss: 2.9219 - val_acc: 0.5573\n","\n","Epoch 00023: val_acc improved from 0.55449 to 0.55731, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 24/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.9663 - acc: 0.6718 - val_loss: 2.9078 - val_acc: 0.5609\n","\n","Epoch 00024: val_acc improved from 0.55731 to 0.56087, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 25/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.9174 - acc: 0.6806 - val_loss: 2.8868 - val_acc: 0.5634\n","\n","Epoch 00025: val_acc improved from 0.56087 to 0.56343, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 26/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.8711 - acc: 0.6888 - val_loss: 2.8719 - val_acc: 0.5665\n","\n","Epoch 00026: val_acc improved from 0.56343 to 0.56654, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 27/50\n","237/237 [==============================] - 104s 437ms/step - loss: 1.8265 - acc: 0.6974 - val_loss: 2.8605 - val_acc: 0.5680\n","\n","Epoch 00027: val_acc improved from 0.56654 to 0.56801, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 28/50\n","237/237 [==============================] - 104s 437ms/step - loss: 1.7850 - acc: 0.7048 - val_loss: 2.8446 - val_acc: 0.5705\n","\n","Epoch 00028: val_acc improved from 0.56801 to 0.57050, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 29/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.7460 - acc: 0.7115 - val_loss: 2.8293 - val_acc: 0.5734\n","\n","Epoch 00029: val_acc improved from 0.57050 to 0.57335, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 30/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.7103 - acc: 0.7183 - val_loss: 2.8285 - val_acc: 0.5730\n","\n","Epoch 00030: val_acc did not improve from 0.57335\n","Epoch 31/50\n","237/237 [==============================] - 103s 435ms/step - loss: 1.6755 - acc: 0.7253 - val_loss: 2.8124 - val_acc: 0.5741\n","\n","Epoch 00031: val_acc improved from 0.57335 to 0.57410, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 32/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.6429 - acc: 0.7310 - val_loss: 2.8167 - val_acc: 0.5746\n","\n","Epoch 00032: val_acc improved from 0.57410 to 0.57465, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 33/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.6140 - acc: 0.7366 - val_loss: 2.8061 - val_acc: 0.5774\n","\n","Epoch 00033: val_acc improved from 0.57465 to 0.57736, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 34/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.5864 - acc: 0.7417 - val_loss: 2.7937 - val_acc: 0.5799\n","\n","Epoch 00034: val_acc improved from 0.57736 to 0.57992, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 35/50\n","237/237 [==============================] - 104s 437ms/step - loss: 1.5578 - acc: 0.7468 - val_loss: 2.7949 - val_acc: 0.5783\n","\n","Epoch 00035: val_acc did not improve from 0.57992\n","Epoch 36/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.5312 - acc: 0.7508 - val_loss: 2.7887 - val_acc: 0.5784\n","\n","Epoch 00036: val_acc did not improve from 0.57992\n","Epoch 37/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.5082 - acc: 0.7550 - val_loss: 2.7719 - val_acc: 0.5793\n","\n","Epoch 00037: val_acc did not improve from 0.57992\n","Epoch 38/50\n","237/237 [==============================] - 104s 439ms/step - loss: 1.4847 - acc: 0.7598 - val_loss: 2.7905 - val_acc: 0.5790\n","\n","Epoch 00038: val_acc did not improve from 0.57992\n","Epoch 39/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.4625 - acc: 0.7640 - val_loss: 2.7866 - val_acc: 0.5789\n","\n","Epoch 00039: val_acc did not improve from 0.57992\n","Epoch 40/50\n","237/237 [==============================] - 104s 437ms/step - loss: 1.4408 - acc: 0.7678 - val_loss: 2.7813 - val_acc: 0.5786\n","\n","Epoch 00040: val_acc did not improve from 0.57992\n","Epoch 41/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.4198 - acc: 0.7717 - val_loss: 2.7715 - val_acc: 0.5822\n","\n","Epoch 00041: val_acc improved from 0.57992 to 0.58224, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 42/50\n","237/237 [==============================] - 104s 437ms/step - loss: 1.4012 - acc: 0.7746 - val_loss: 2.7492 - val_acc: 0.5860\n","\n","Epoch 00042: val_acc improved from 0.58224 to 0.58600, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 43/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.3833 - acc: 0.7789 - val_loss: 2.7531 - val_acc: 0.5854\n","\n","Epoch 00043: val_acc did not improve from 0.58600\n","Epoch 44/50\n","237/237 [==============================] - 104s 439ms/step - loss: 1.3679 - acc: 0.7812 - val_loss: 2.7485 - val_acc: 0.5859\n","\n","Epoch 00044: val_acc did not improve from 0.58600\n","Epoch 45/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.3540 - acc: 0.7838 - val_loss: 2.7604 - val_acc: 0.5836\n","\n","Epoch 00045: val_acc did not improve from 0.58600\n","Epoch 46/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.3390 - acc: 0.7864 - val_loss: 2.7697 - val_acc: 0.5837\n","\n","Epoch 00046: val_acc did not improve from 0.58600\n","Epoch 47/50\n","237/237 [==============================] - 104s 439ms/step - loss: 1.3245 - acc: 0.7888 - val_loss: 2.7528 - val_acc: 0.5850\n","\n","Epoch 00047: val_acc did not improve from 0.58600\n","Epoch 48/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.3091 - acc: 0.7910 - val_loss: 2.7543 - val_acc: 0.5863\n","\n","Epoch 00048: val_acc improved from 0.58600 to 0.58628, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma.hdf5\n","Epoch 49/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.2953 - acc: 0.7947 - val_loss: 2.7581 - val_acc: 0.5843\n","\n","Epoch 00049: val_acc did not improve from 0.58628\n","Epoch 50/50\n","237/237 [==============================] - 104s 440ms/step - loss: 1.2805 - acc: 0.7972 - val_loss: 2.7667 - val_acc: 0.5843\n","\n","Epoch 00050: val_acc did not improve from 0.58628\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f85ab064be0>"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"VRdA-3G8Lee1","colab_type":"text"},"cell_type":"markdown","source":["#### 4.3 Save Model"]},{"metadata":{"id":"8B6oDJqsLee2","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save_weights(os.path.join(root, 'nmt_weights.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qFYkdLTcLee5","colab_type":"text"},"cell_type":"markdown","source":["#### 4.4 Load model"]},{"metadata":{"id":"NvWzXHqHMEe-","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load_weights(os.path.join(root, 'nmt_weights.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"y3s531y3Lee_","colab_type":"text"},"cell_type":"markdown","source":["### 5. Inference Setup"]},{"metadata":{"id":"IZapXObgLefC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Encoder-decoder model that uses trained weights from the original model to make predictions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kA9ZktGiLefH","colab_type":"text"},"cell_type":"markdown","source":["#### 5.1 Inference Encoder"]},{"metadata":{"id":"xLp33CktLefJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Encoder model to create a thought vector from the input\n","inference_encoder = Model(encoder_inputs, encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"51w8NazaLefM","colab_type":"text"},"cell_type":"markdown","source":["#### 5.2 Inference Decoder"]},{"metadata":{"id":"YQjvRgCPLefN","colab_type":"code","colab":{}},"cell_type":"code","source":["# For each time step, the decoder states from previous timestep would act as inputs\n","decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n","decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# Embedding\n","decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n","                                                                               initial_state=decoder_states_inputs)\n","decoder_states_inference = [state_h_inference, state_c_inference]\n","\n","# Dense\n","decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IL7B1qchLefP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Decoder model\n","inference_decoder = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs_inference] + decoder_states_inference\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SvR0urBBLefR","colab_type":"code","outputId":"30f6e780-dbd7-4331-fdf3-46fb54438193","executionInfo":{"status":"ok","timestamp":1554652319063,"user_tz":-330,"elapsed":1206,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["inference_encoder.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoder_Inputs (InputLayer)  (None, None)              0         \n","_________________________________________________________________\n","English_Embedding_Layer (Emb (None, None, 128)         689664    \n","_________________________________________________________________\n","Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n","=================================================================\n","Total params: 821,248\n","Trainable params: 821,248\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"PH3DCqVjLefV","colab_type":"code","outputId":"d30f547b-f9a6-46e1-8e75-a3832fe65167","executionInfo":{"status":"ok","timestamp":1554652322955,"user_tz":-330,"elapsed":1358,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":["inference_decoder.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Inference_Decoder_Output (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Inference_Decoder_Memory (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[1][0]    \n","                                                                 Inference_Decoder_Output[0][0]   \n","                                                                 Inference_Decoder_Memory[0][0]   \n","__________________________________________________________________________________________________\n","Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[1][0]               \n","==================================================================================================\n","Total params: 3,394,970\n","Trainable params: 3,394,970\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"nlo9Ng46LefY","colab_type":"text"},"cell_type":"markdown","source":["#### 5.3 Decode sample sequeces"]},{"metadata":{"id":"3NUGmwBtLefZ","colab_type":"code","colab":{}},"cell_type":"code","source":["def decode_sequence(input_sequence):\n","    # Get thought vector by encoding the input sequence\n","    states_value = inference_encoder.predict(input_sequence)\n","    \n","    # Generate target sequence initialized with <START> character\n","    target_sequence = np.zeros((1, 1))\n","    target_sequence[0, 0] = target_dictionary['<START>']\n","    \n","    # To stop the recurrent loop\n","    stop_condition = False\n","    \n","    # Final sentence\n","    decoded_sentence = ''\n","    \n","    while not stop_condition:\n","        # Get next prediction\n","        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n","        \n","        # Get the token with max probability\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = target_reverse_dictionary[sampled_token_index]\n","        decoded_sentence += ' ' + sampled_word\n","        \n","        # Test for exit condition\n","        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n","            stop_condition = True\n","            \n","        # Update the target sequence with current prediction\n","        target_sequence = np.zeros((1, 1))\n","        target_sequence[0, 0] = sampled_token_index\n","        \n","        # Update states\n","        states_value = [h, c]\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eehBSrbvLefc","colab_type":"text"},"cell_type":"markdown","source":["### 6. Evaluation on Train Dataset"]},{"metadata":{"id":"s2D1wd2NLefl","colab_type":"code","outputId":"93119a2c-7b4c-46ee-ebd4-dde6114250bd","executionInfo":{"status":"ok","timestamp":1554652407029,"user_tz":-330,"elapsed":1582,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["input_sequence = encode_input(['you are a man'])\n","decoded_sentence = decode_sequence(input_sequence)\n","' '.join(decoded_sentence.split()[:-1])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'तुम्ही माणूस आहात'"]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"7lfjO1PMMOfC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}