{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_Seq2Seq_Eng_Mar_NTL_E.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793094988,"user_tz":-330,"elapsed":76055,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"gwTL36ttLedG","outputId":"3c6783be-6108-4e7e-af9e-4dd2b8409210","colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["# To mount Google drive on Google Colab environment\n","from google.colab import drive\n","drive.mount('/content/drive')\n","root = '/content/drive/My Drive/English Dataset'\n","# root = '.'"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"Eb0tHTz1LedM"},"cell_type":"markdown","source":["### 1. Packages"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793104453,"user_tz":-330,"elapsed":2604,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"92RA6N5fLedO","outputId":"db838591-c04a-49ed-c09b-57ca9dec199b","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","import re\n","import pickle\n","import os\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","from string import digits"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"colab_type":"text","id":"q5-UJzoBLedS"},"cell_type":"markdown","source":["### 2. Data Preparation"]},{"metadata":{"colab_type":"code","id":"qEj_b0VSLedT","colab":{}},"cell_type":"code","source":["# Read dataset\n","lines = pd.read_pickle(os.path.join(root, 'mar-eng_cleaned.parallel'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793108285,"user_tz":-330,"elapsed":1228,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"D787xMeLLedV","outputId":"38ca493e-3cb8-4be6-970e-9c926f394902","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# View the shape of dataset\n","lines.shape"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33725, 2)"]},"metadata":{"tags":[]},"execution_count":4}]},{"metadata":{"colab_type":"code","id":"ZsqG7aFTLedd","colab":{}},"cell_type":"code","source":["# Add 'start' and 'end' tokens to target sentences\n","lines.Mar = lines.Mar.apply(lambda x: '<START> ' + x + ' <END>')"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793192576,"user_tz":-330,"elapsed":871,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"GbGtP_6VLedh","outputId":"d535e68c-6722-4e18-ec43-9ee48044b9c8","colab":{"base_uri":"https://localhost:8080/","height":204}},"cell_type":"code","source":["# View a few samples of the dataset\n","lines.sample(5)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Mar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25122</th>\n","      <td>tom went to boston a year ago</td>\n","      <td>&lt;START&gt; टॉम एक वर्षापूर्वी बॉस्टनला गेला &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>7121</th>\n","      <td>tom left his wife</td>\n","      <td>&lt;START&gt; टॉम त्याच्या पत्नीला सोडून गेला &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>11622</th>\n","      <td>i have a credit card</td>\n","      <td>&lt;START&gt; माझ्याकडे क्रेडिट कार्ड आहे &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>22226</th>\n","      <td>i can only import gif files</td>\n","      <td>&lt;START&gt; मला फक्त जीआयएफ फायली इम्पोर्ट करता ये...</td>\n","    </tr>\n","    <tr>\n","      <th>32478</th>\n","      <td>when i was reading a book the telephone rang</td>\n","      <td>&lt;START&gt; मी एक पुस्तक वाचत असताना फोन वाजला &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                Eng  \\\n","25122                 tom went to boston a year ago   \n","7121                              tom left his wife   \n","11622                          i have a credit card   \n","22226                   i can only import gif files   \n","32478  when i was reading a book the telephone rang   \n","\n","                                                     Mar  \n","25122     <START> टॉम एक वर्षापूर्वी बॉस्टनला गेला <END>  \n","7121       <START> टॉम त्याच्या पत्नीला सोडून गेला <END>  \n","11622          <START> माझ्याकडे क्रेडिट कार्ड आहे <END>  \n","22226  <START> मला फक्त जीआयएफ फायली इम्पोर्ट करता ये...  \n","32478   <START> मी एक पुस्तक वाचत असताना फोन वाजला <END>  "]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"OCXugjOO_-v_","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get vocabulary and embeddings\n","with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n","    english_summary = pickle.load(f)\n","    \n","with open(os.path.join(root, 'embeddings.ma'), 'rb') as f:\n","    marathi_summary = pickle.load(f)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_W9WhAqyB_ZC","colab_type":"code","colab":{}},"cell_type":"code","source":["# Add start and end tokens to dictionary\n","for word in ['<START>', '<END>']:\n","    l = len(marathi_summary['dictionary'].keys())\n","    marathi_summary['dictionary'][word] = l\n","    marathi_summary['reverse_dictionary'][l] = word\n","    marathi_summary['embeddings'] = np.vstack((marathi_summary['embeddings'], np.zeros((1, marathi_summary['embeddings'].shape[1]))))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"-_i-8ssyLedl","colab":{}},"cell_type":"code","source":["# English vocabulary\n","all_eng_words = set(list(english_summary['dictionary'].keys()))\n","        \n","# Marathi vocabulary\n","all_mar_words = set(list(marathi_summary['dictionary'].keys()))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793205159,"user_tz":-330,"elapsed":651,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"7QZaq1bQLedo","outputId":"25372e5a-8bb3-445f-b1da-9a72a33e21e3","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of source sequence\n","max_length_src = 0\n","\n","for line in lines.Eng:\n","    if len(line.split(' ')) > max_length_src:\n","        max_length_src = len(line.split(' '))\n","        \n","max_length_src"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["34"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793207319,"user_tz":-330,"elapsed":1068,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"SHtikVcQLedu","outputId":"f48d9db5-9d3a-4909-843e-69bb876fddc8","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Max length of target sequence\n","max_length_tar = 0\n","\n","for line in lines.Mar:\n","    if len(line.split(' ')) > max_length_tar:\n","        max_length_tar = len(line.split(' '))\n","        \n","max_length_tar"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{"tags":[]},"execution_count":11}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793211837,"user_tz":-330,"elapsed":630,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"Eaj5LOJgLedz","outputId":"745ec89a-5806-48b0-991d-d3a379e18b13","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["num_encoder_tokens = len(all_eng_words)\n","num_decoder_tokens = len(all_mar_words)\n","num_encoder_tokens, num_decoder_tokens"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8731, 12698)"]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"colab_type":"code","id":"FNryqdRvLed3","colab":{}},"cell_type":"code","source":["source_dictionary = english_summary['dictionary']\n","target_dictionary = marathi_summary['dictionary']"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"W0bt1VxLLed5","colab":{}},"cell_type":"code","source":["source_reverse_dictionary = english_summary['reverse_dictionary']\n","target_reverse_dictionary = marathi_summary['reverse_dictionary']"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793218589,"user_tz":-330,"elapsed":1004,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"v9Z2BiygLed9","outputId":"2dcec176-4eb0-4714-f08a-f8956b4ecac7","scrolled":true,"colab":{"base_uri":"https://localhost:8080/","height":359}},"cell_type":"code","source":["lines = shuffle(lines)\n","lines.head(10)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Eng</th>\n","      <th>Mar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>24489</th>\n","      <td>i am decorating the classroom</td>\n","      <td>&lt;START&gt; मी वर्ग सजवतो आहे &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>21998</th>\n","      <td>do you play soccer or rugby</td>\n","      <td>&lt;START&gt; तुम्ही फुटबॉल खेळता की रग्बी &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>20627</th>\n","      <td>come and look for yourself</td>\n","      <td>&lt;START&gt; स्वतः येऊन बघ &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>28716</th>\n","      <td>tom and mary danced all night long</td>\n","      <td>&lt;START&gt; टॉम व मेरी रात्रभर नाचत राहिले &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>6220</th>\n","      <td>hes already left</td>\n","      <td>&lt;START&gt; तो आधिच निघालाय &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>23214</th>\n","      <td>buy four big potatoes for me</td>\n","      <td>&lt;START&gt; माझ्यासाठी चार मोठे बटाटे विकत आणा &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>16207</th>\n","      <td>you seem to like fruit</td>\n","      <td>&lt;START&gt; तुला फळं आवडतात असं वाटतंय &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>18826</th>\n","      <td>tom looked into the tank</td>\n","      <td>&lt;START&gt; टॉमने टाकीत पाहिलं &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>492</th>\n","      <td>i want you</td>\n","      <td>&lt;START&gt; मला तू हवी आहेस &lt;END&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>5463</th>\n","      <td>they dug a grave</td>\n","      <td>&lt;START&gt; त्यांनी एक कबर खोदली &lt;END&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                      Eng  \\\n","24489       i am decorating the classroom   \n","21998         do you play soccer or rugby   \n","20627          come and look for yourself   \n","28716  tom and mary danced all night long   \n","6220                     hes already left   \n","23214        buy four big potatoes for me   \n","16207              you seem to like fruit   \n","18826            tom looked into the tank   \n","492                            i want you   \n","5463                     they dug a grave   \n","\n","                                                    Mar  \n","24489                   <START> मी वर्ग सजवतो आहे <END>  \n","21998        <START> तुम्ही फुटबॉल खेळता की रग्बी <END>  \n","20627                       <START> स्वतः येऊन बघ <END>  \n","28716      <START> टॉम व मेरी रात्रभर नाचत राहिले <END>  \n","6220                      <START> तो आधिच निघालाय <END>  \n","23214  <START> माझ्यासाठी चार मोठे बटाटे विकत आणा <END>  \n","16207          <START> तुला फळं आवडतात असं वाटतंय <END>  \n","18826                  <START> टॉमने टाकीत पाहिलं <END>  \n","492                       <START> मला तू हवी आहेस <END>  \n","5463                 <START> त्यांनी एक कबर खोदली <END>  "]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"colab_type":"text","id":"OpwDCXjSLeeC"},"cell_type":"markdown","source":["### 3. Batch Generator"]},{"metadata":{"colab_type":"code","id":"7bUerHhNLeeD","colab":{}},"cell_type":"code","source":["def encode_input(X):\n","    \"\"\"\n","        X = batch of inputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(X)\n","    \n","    # Create a numpy array of zeros to hold input\n","    encoder_input_data = np.zeros((batch_size, max_length_src), dtype='float32')\n","    \n","    for i, input_text in enumerate(X):\n","        for t, word in enumerate(input_text.split()):\n","            if word not in source_dictionary.keys():\n","                word = 'UNK'\n","            encoder_input_data[i, t] = source_dictionary[word]\n","            \n","    return encoder_input_data\n","\n","def encode_target(y):\n","    \"\"\"\n","        y = batch of outputs\n","    \"\"\"\n","    # Get the batch_size\n","    batch_size = len(y)\n","    \n","    # Create numpy arrays of zeros to hold encoded targets\n","    decoder_input_data = np.zeros((batch_size, max_length_tar), dtype='float32')\n","    decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens), dtype='float32')\n","    \n","    for i, target_text in enumerate(y):\n","        for t, word in enumerate(target_text.split()):\n","            if t < len(target_text.split()) - 1:\n","                decoder_input_data[i, t] = target_dictionary[word]\n","                \n","            if t > 0:\n","                decoder_target_data[i, t-1, target_dictionary[word]] = 1.0\n","                \n","    return decoder_input_data, decoder_target_data"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"GiOFeb9vLeeH","colab":{}},"cell_type":"code","source":["def generate_batch(X, y, batch_size=128):\n","    \"\"\"\n","        X = Source dataset\n","        y = Target dataset\n","        batch_size = Size of each batch\n","    \"\"\"\n","    while True:\n","        for j in range(0, len(X), batch_size):\n","            encoder_input_data = encode_input(X[j:j+batch_size])\n","            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size])\n","            \n","            yield([encoder_input_data, decoder_input_data], decoder_target_data)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"V-x4hM2sLeeL"},"cell_type":"markdown","source":["### 4. Encoder - Decoder Model Architecture"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793226710,"user_tz":-330,"elapsed":1203,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"1UtH1Hp3LeeN","outputId":"a7a88e4a-362e-48dc-9fa7-6381e1121204","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["# Train-test split\n","X, y = lines.Eng, lines.Mar\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n","X_train.shape, X_test.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((30352,), (3373,))"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"colab_type":"code","id":"2CUiDGfCLeeS","colab":{}},"cell_type":"code","source":["latent_dim = 128"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"H6hMfdyQLeeW","colab":{}},"cell_type":"code","source":["train_samples = len(X_train)\n","val_samples = len(X_test)\n","batch_size = 128\n","epochs = 50"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"IxWNZCbELeeZ"},"cell_type":"markdown","source":["#### 4.1 Encoder"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793231752,"user_tz":-330,"elapsed":3399,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"aGdBX4MhLeeZ","outputId":"9b49d050-e7ac-4260-ebdf-3c14c4dffebf","colab":{"base_uri":"https://localhost:8080/","height":88}},"cell_type":"code","source":["# Inputs\n","encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n","\n","# Embedding Lookup\n","encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n","                                    weights=[english_summary['embeddings']], \n","                                    name='English_Embedding_Layer')\n","encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n","\n","# LSTM\n","encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n","\n","# Keeping only the states and discarding encoder outputs\n","encoder_states = [state_h, state_c]"],"execution_count":21,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"TqcAW1TRLeed"},"cell_type":"markdown","source":["#### 4.2 Decoder"]},{"metadata":{"colab_type":"code","id":"pT4GcwdKLeee","colab":{}},"cell_type":"code","source":["# Inputs\n","decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n","\n","# Embedding\n","decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n","                                    weights=[marathi_summary['embeddings']], \n","                                    name='Marathi_Embedding_Layer')\n","decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n","decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n","\n","# Dense output layer\n","decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Decoder_Dense')\n","decoder_outputs = decoder_dense(decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"7zUNups0Leei","colab":{}},"cell_type":"code","source":["# Define a model with these layers\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793246122,"user_tz":-330,"elapsed":1772,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"EmPdHO_sLeel","outputId":"045451eb-c79b-40a1-df0d-9fefae62b82a","colab":{"base_uri":"https://localhost:8080/","height":428}},"cell_type":"code","source":["# Take a look at the model\n","model.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Encoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","English_Embedding_Layer (Embedd (None, None, 128)    1117568     Encoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Encoder_LSTM (LSTM)             [(None, 128), (None, 131584      English_Embedding_Layer[0][0]    \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[0][0]    \n","                                                                 Encoder_LSTM[0][1]               \n","                                                                 Encoder_LSTM[0][2]               \n","__________________________________________________________________________________________________\n","Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[0][0]               \n","==================================================================================================\n","Total params: 4,644,122\n","Trainable params: 4,644,122\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","id":"U-Upu1etLeep","colab":{}},"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FFHzeRT25jMR","colab_type":"code","colab":{}},"cell_type":"code","source":["model.load_weights(os.path.join(root, 'best_model_en_ma_ntl_e.hdf5'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"tJGZXMmsLeev","colab":{}},"cell_type":"code","source":["# Create checkpoints to save model from time to time\n","filepath = os.path.join(root, 'best_model_en_ma_ntl_e.hdf5')\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554700772656,"user_tz":-330,"elapsed":5360822,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"z-FyOS1lLeey","outputId":"0545c2d6-4e5c-4b31-d63e-933e2639aee6","colab":{"base_uri":"https://localhost:8080/","height":3590}},"cell_type":"code","source":["model.fit_generator(generator=generate_batch(X_train, y_train, batch_size), steps_per_epoch=train_samples//batch_size, \n","                    epochs=epochs, validation_data=generate_batch(X_test, y_test, batch_size), \n","                    validation_steps=val_samples//batch_size, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Deprecated in favor of operator or tf.math.divide.\n","Epoch 1/50\n","237/237 [==============================] - 110s 466ms/step - loss: 6.0075 - acc: 0.1985 - val_loss: 5.5365 - val_acc: 0.2245\n","\n","Epoch 00001: val_acc improved from -inf to 0.22455, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n","  '. They will not be included '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 2/50\n","237/237 [==============================] - 108s 455ms/step - loss: 5.2119 - acc: 0.2564 - val_loss: 5.0641 - val_acc: 0.2839\n","\n","Epoch 00002: val_acc improved from 0.22455 to 0.28387, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 3/50\n","237/237 [==============================] - 109s 460ms/step - loss: 4.7623 - acc: 0.2995 - val_loss: 4.7215 - val_acc: 0.3208\n","\n","Epoch 00003: val_acc improved from 0.28387 to 0.32084, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 4/50\n","237/237 [==============================] - 111s 467ms/step - loss: 4.3951 - acc: 0.3381 - val_loss: 4.4286 - val_acc: 0.3559\n","\n","Epoch 00004: val_acc improved from 0.32084 to 0.35588, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 5/50\n","237/237 [==============================] - 110s 462ms/step - loss: 4.0806 - acc: 0.3732 - val_loss: 4.1953 - val_acc: 0.3816\n","\n","Epoch 00005: val_acc improved from 0.35588 to 0.38164, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 6/50\n","237/237 [==============================] - 109s 460ms/step - loss: 3.8081 - acc: 0.4054 - val_loss: 4.0190 - val_acc: 0.4095\n","\n","Epoch 00006: val_acc improved from 0.38164 to 0.40951, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 7/50\n","237/237 [==============================] - 109s 459ms/step - loss: 3.5689 - acc: 0.4333 - val_loss: 3.8496 - val_acc: 0.4329\n","\n","Epoch 00007: val_acc improved from 0.40951 to 0.43289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 8/50\n","237/237 [==============================] - 107s 454ms/step - loss: 3.3554 - acc: 0.4602 - val_loss: 3.6989 - val_acc: 0.4513\n","\n","Epoch 00008: val_acc improved from 0.43289 to 0.45126, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 9/50\n","237/237 [==============================] - 108s 454ms/step - loss: 3.1666 - acc: 0.4855 - val_loss: 3.5884 - val_acc: 0.4642\n","\n","Epoch 00009: val_acc improved from 0.45126 to 0.46421, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 10/50\n","237/237 [==============================] - 109s 458ms/step - loss: 2.9972 - acc: 0.5093 - val_loss: 3.4774 - val_acc: 0.4825\n","\n","Epoch 00010: val_acc improved from 0.46421 to 0.48245, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 11/50\n","237/237 [==============================] - 110s 462ms/step - loss: 2.8495 - acc: 0.5299 - val_loss: 3.3880 - val_acc: 0.4945\n","\n","Epoch 00011: val_acc improved from 0.48245 to 0.49451, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 12/50\n","237/237 [==============================] - 110s 462ms/step - loss: 2.7132 - acc: 0.5495 - val_loss: 3.2880 - val_acc: 0.5051\n","\n","Epoch 00012: val_acc improved from 0.49451 to 0.50513, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 13/50\n","237/237 [==============================] - 109s 460ms/step - loss: 2.5881 - acc: 0.5687 - val_loss: 3.2099 - val_acc: 0.5174\n","\n","Epoch 00013: val_acc improved from 0.50513 to 0.51743, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 14/50\n","237/237 [==============================] - 109s 458ms/step - loss: 2.4721 - acc: 0.5864 - val_loss: 3.1375 - val_acc: 0.5276\n","\n","Epoch 00014: val_acc improved from 0.51743 to 0.52760, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 15/50\n","237/237 [==============================] - 106s 449ms/step - loss: 2.3676 - acc: 0.6027 - val_loss: 3.0835 - val_acc: 0.5340\n","\n","Epoch 00015: val_acc improved from 0.52760 to 0.53404, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 16/50\n","237/237 [==============================] - 104s 441ms/step - loss: 2.2744 - acc: 0.6176 - val_loss: 3.0389 - val_acc: 0.5395\n","\n","Epoch 00016: val_acc improved from 0.53404 to 0.53947, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 17/50\n","237/237 [==============================] - 104s 441ms/step - loss: 2.1931 - acc: 0.6310 - val_loss: 3.0162 - val_acc: 0.5447\n","\n","Epoch 00017: val_acc improved from 0.53947 to 0.54472, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 18/50\n","237/237 [==============================] - 105s 442ms/step - loss: 2.1179 - acc: 0.6439 - val_loss: 2.9590 - val_acc: 0.5513\n","\n","Epoch 00018: val_acc improved from 0.54472 to 0.55128, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 19/50\n","237/237 [==============================] - 107s 450ms/step - loss: 2.0515 - acc: 0.6560 - val_loss: 2.9572 - val_acc: 0.5522\n","\n","Epoch 00019: val_acc improved from 0.55128 to 0.55220, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 20/50\n","237/237 [==============================] - 107s 450ms/step - loss: 1.9898 - acc: 0.6670 - val_loss: 2.9443 - val_acc: 0.5557\n","\n","Epoch 00020: val_acc improved from 0.55220 to 0.55575, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 21/50\n","237/237 [==============================] - 107s 450ms/step - loss: 1.9321 - acc: 0.6776 - val_loss: 2.9216 - val_acc: 0.5608\n","\n","Epoch 00021: val_acc improved from 0.55575 to 0.56077, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 22/50\n","237/237 [==============================] - 107s 450ms/step - loss: 1.8804 - acc: 0.6868 - val_loss: 2.8985 - val_acc: 0.5629\n","\n","Epoch 00022: val_acc improved from 0.56077 to 0.56289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 23/50\n","237/237 [==============================] - 106s 447ms/step - loss: 1.8305 - acc: 0.6959 - val_loss: 2.8746 - val_acc: 0.5672\n","\n","Epoch 00023: val_acc improved from 0.56289 to 0.56716, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 24/50\n","237/237 [==============================] - 105s 442ms/step - loss: 1.7846 - acc: 0.7043 - val_loss: 2.8592 - val_acc: 0.5698\n","\n","Epoch 00024: val_acc improved from 0.56716 to 0.56976, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 25/50\n","237/237 [==============================] - 104s 440ms/step - loss: 1.7418 - acc: 0.7131 - val_loss: 2.8493 - val_acc: 0.5735\n","\n","Epoch 00025: val_acc improved from 0.56976 to 0.57354, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 26/50\n","237/237 [==============================] - 104s 438ms/step - loss: 1.7013 - acc: 0.7202 - val_loss: 2.8222 - val_acc: 0.5800\n","\n","Epoch 00026: val_acc improved from 0.57354 to 0.58003, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 27/50\n","237/237 [==============================] - 105s 442ms/step - loss: 1.6596 - acc: 0.7274 - val_loss: 2.8289 - val_acc: 0.5771\n","\n","Epoch 00027: val_acc did not improve from 0.58003\n","Epoch 28/50\n","237/237 [==============================] - 107s 453ms/step - loss: 1.6190 - acc: 0.7339 - val_loss: 2.8040 - val_acc: 0.5811\n","\n","Epoch 00028: val_acc improved from 0.58003 to 0.58106, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 29/50\n","237/237 [==============================] - 108s 455ms/step - loss: 1.5805 - acc: 0.7411 - val_loss: 2.8083 - val_acc: 0.5789\n","\n","Epoch 00029: val_acc did not improve from 0.58106\n","Epoch 30/50\n","237/237 [==============================] - 108s 456ms/step - loss: 1.5510 - acc: 0.7467 - val_loss: 2.8003 - val_acc: 0.5805\n","\n","Epoch 00030: val_acc did not improve from 0.58106\n","Epoch 31/50\n","237/237 [==============================] - 108s 455ms/step - loss: 1.5218 - acc: 0.7520 - val_loss: 2.7819 - val_acc: 0.5829\n","\n","Epoch 00031: val_acc improved from 0.58106 to 0.58289, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 32/50\n","237/237 [==============================] - 108s 455ms/step - loss: 1.4958 - acc: 0.7572 - val_loss: 2.7751 - val_acc: 0.5859\n","\n","Epoch 00032: val_acc improved from 0.58289 to 0.58590, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 33/50\n","237/237 [==============================] - 108s 454ms/step - loss: 1.4704 - acc: 0.7617 - val_loss: 2.7827 - val_acc: 0.5834\n","\n","Epoch 00033: val_acc did not improve from 0.58590\n","Epoch 34/50\n","237/237 [==============================] - 108s 456ms/step - loss: 1.4466 - acc: 0.7658 - val_loss: 2.7774 - val_acc: 0.5844\n","\n","Epoch 00034: val_acc did not improve from 0.58590\n","Epoch 35/50\n","237/237 [==============================] - 108s 456ms/step - loss: 1.4254 - acc: 0.7698 - val_loss: 2.7663 - val_acc: 0.5864\n","\n","Epoch 00035: val_acc improved from 0.58590 to 0.58643, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 36/50\n","237/237 [==============================] - 107s 451ms/step - loss: 1.4056 - acc: 0.7744 - val_loss: 2.7760 - val_acc: 0.5839\n","\n","Epoch 00036: val_acc did not improve from 0.58643\n","Epoch 37/50\n","237/237 [==============================] - 107s 450ms/step - loss: 1.3855 - acc: 0.7786 - val_loss: 2.7740 - val_acc: 0.5820\n","\n","Epoch 00037: val_acc did not improve from 0.58643\n","Epoch 38/50\n","237/237 [==============================] - 107s 451ms/step - loss: 1.3681 - acc: 0.7818 - val_loss: 2.7559 - val_acc: 0.5852\n","\n","Epoch 00038: val_acc did not improve from 0.58643\n","Epoch 39/50\n","237/237 [==============================] - 106s 449ms/step - loss: 1.3497 - acc: 0.7852 - val_loss: 2.7559 - val_acc: 0.5869\n","\n","Epoch 00039: val_acc improved from 0.58643 to 0.58686, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 40/50\n","237/237 [==============================] - 106s 448ms/step - loss: 1.3347 - acc: 0.7884 - val_loss: 2.7522 - val_acc: 0.5845\n","\n","Epoch 00040: val_acc did not improve from 0.58686\n","Epoch 41/50\n","237/237 [==============================] - 105s 444ms/step - loss: 1.3191 - acc: 0.7913 - val_loss: 2.7400 - val_acc: 0.5892\n","\n","Epoch 00041: val_acc improved from 0.58686 to 0.58920, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 42/50\n","237/237 [==============================] - 105s 441ms/step - loss: 1.3045 - acc: 0.7941 - val_loss: 2.7462 - val_acc: 0.5902\n","\n","Epoch 00042: val_acc improved from 0.58920 to 0.59023, saving model to /content/drive/My Drive/English Dataset/best_model_en_ma_ntl_e.hdf5\n","Epoch 43/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.2898 - acc: 0.7968 - val_loss: 2.7496 - val_acc: 0.5877\n","\n","Epoch 00043: val_acc did not improve from 0.59023\n","Epoch 44/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.2757 - acc: 0.7996 - val_loss: 2.7711 - val_acc: 0.5873\n","\n","Epoch 00044: val_acc did not improve from 0.59023\n","Epoch 45/50\n","237/237 [==============================] - 103s 437ms/step - loss: 1.2644 - acc: 0.8016 - val_loss: 2.7469 - val_acc: 0.5869\n","\n","Epoch 00045: val_acc did not improve from 0.59023\n","Epoch 46/50\n","237/237 [==============================] - 103s 435ms/step - loss: 1.2521 - acc: 0.8038 - val_loss: 2.7739 - val_acc: 0.5860\n","\n","Epoch 00046: val_acc did not improve from 0.59023\n","Epoch 47/50\n","237/237 [==============================] - 103s 435ms/step - loss: 1.2379 - acc: 0.8063 - val_loss: 2.7858 - val_acc: 0.5841\n","\n","Epoch 00047: val_acc did not improve from 0.59023\n","Epoch 48/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.2271 - acc: 0.8085 - val_loss: 2.7709 - val_acc: 0.5867\n","\n","Epoch 00048: val_acc did not improve from 0.59023\n","Epoch 49/50\n","237/237 [==============================] - 103s 436ms/step - loss: 1.2167 - acc: 0.8095 - val_loss: 2.7664 - val_acc: 0.5868\n","\n","Epoch 00049: val_acc did not improve from 0.59023\n","Epoch 50/50\n","237/237 [==============================] - 103s 435ms/step - loss: 1.2048 - acc: 0.8117 - val_loss: 2.7639 - val_acc: 0.5861\n","\n","Epoch 00050: val_acc did not improve from 0.59023\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fe011426b70>"]},"metadata":{"tags":[]},"execution_count":27}]},{"metadata":{"colab_type":"text","id":"VRdA-3G8Lee1"},"cell_type":"markdown","source":["#### 4.3 Save Model"]},{"metadata":{"colab_type":"code","id":"8B6oDJqsLee2","colab":{}},"cell_type":"code","source":["model.save_weights(os.path.join(root, 'nmt_weights_en_ma_ntl_e.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"qFYkdLTcLee5"},"cell_type":"markdown","source":["#### 4.4 Load model"]},{"metadata":{"colab_type":"code","id":"NvWzXHqHMEe-","colab":{}},"cell_type":"code","source":["model.load_weights(os.path.join(root, 'nmt_weights_en_ma_ntl_e.h5'))"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"y3s531y3Lee_"},"cell_type":"markdown","source":["### 5. Inference Setup"]},{"metadata":{"colab_type":"code","id":"IZapXObgLefC","colab":{}},"cell_type":"code","source":["# Encoder-decoder model that uses trained weights from the original model to make predictions"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"kA9ZktGiLefH"},"cell_type":"markdown","source":["#### 5.1 Inference Encoder"]},{"metadata":{"colab_type":"code","id":"xLp33CktLefJ","colab":{}},"cell_type":"code","source":["# Encoder model to create a thought vector from the input\n","inference_encoder = Model(encoder_inputs, encoder_states)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"51w8NazaLefM"},"cell_type":"markdown","source":["#### 5.2 Inference Decoder"]},{"metadata":{"colab_type":"code","id":"YQjvRgCPLefN","colab":{}},"cell_type":"code","source":["# For each time step, the decoder states from previous timestep would act as inputs\n","decoder_state_input_h = Input(shape=(latent_dim, ), name='Inference_Decoder_Output')\n","decoder_state_input_c = Input(shape=(latent_dim, ), name='Inference_Decoder_Memory')\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# Embedding\n","decoder_embeddings_inference = decoder_embedding_layer(decoder_inputs)\n","\n","# LSTM\n","decoder_outputs_inference, state_h_inference, state_c_inference = decoder_lstm(decoder_embeddings_inference, \n","                                                                               initial_state=decoder_states_inputs)\n","decoder_states_inference = [state_h_inference, state_c_inference]\n","\n","# Dense\n","decoder_outputs_inference = decoder_dense(decoder_outputs_inference)"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","id":"IL7B1qchLefP","colab":{}},"cell_type":"code","source":["# Decoder model\n","inference_decoder = Model(\n","    [decoder_inputs] + decoder_states_inputs,\n","    [decoder_outputs_inference] + decoder_states_inference\n",")"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793294310,"user_tz":-330,"elapsed":1495,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"SvR0urBBLefR","outputId":"87e9e85d-48e7-402b-e4b8-93373a8c4127","colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["inference_encoder.summary()"],"execution_count":31,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","Encoder_Inputs (InputLayer)  (None, None)              0         \n","_________________________________________________________________\n","English_Embedding_Layer (Emb (None, None, 128)         1117568   \n","_________________________________________________________________\n","Encoder_LSTM (LSTM)          [(None, 128), (None, 128) 131584    \n","=================================================================\n","Total params: 1,249,152\n","Trainable params: 1,249,152\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793296809,"user_tz":-330,"elapsed":1077,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"PH3DCqVjLefV","outputId":"23ccd248-deb9-4e94-ea6b-16df9bfbc936","colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":["inference_decoder.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","Decoder_Inputs (InputLayer)     (None, None)         0                                            \n","__________________________________________________________________________________________________\n","Marathi_Embedding_Layer (Embedd (None, None, 128)    1625344     Decoder_Inputs[0][0]             \n","__________________________________________________________________________________________________\n","Inference_Decoder_Output (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Inference_Decoder_Memory (Input (None, 128)          0                                            \n","__________________________________________________________________________________________________\n","Decoder_LSTM (LSTM)             [(None, None, 128),  131584      Marathi_Embedding_Layer[1][0]    \n","                                                                 Inference_Decoder_Output[0][0]   \n","                                                                 Inference_Decoder_Memory[0][0]   \n","__________________________________________________________________________________________________\n","Decoder_Dense (Dense)           (None, None, 12698)  1638042     Decoder_LSTM[1][0]               \n","==================================================================================================\n","Total params: 3,394,970\n","Trainable params: 3,394,970\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"colab_type":"text","id":"nlo9Ng46LefY"},"cell_type":"markdown","source":["#### 5.3 Decode sample sequeces"]},{"metadata":{"colab_type":"code","id":"3NUGmwBtLefZ","colab":{}},"cell_type":"code","source":["def decode_sequence(input_sequence):\n","    # Get thought vector by encoding the input sequence\n","    states_value = inference_encoder.predict(input_sequence)\n","    \n","    # Generate target sequence initialized with <START> character\n","    target_sequence = np.zeros((1, 1))\n","    target_sequence[0, 0] = target_dictionary['<START>']\n","    \n","    # To stop the recurrent loop\n","    stop_condition = False\n","    \n","    # Final sentence\n","    decoded_sentence = ''\n","    \n","    while not stop_condition:\n","        # Get next prediction\n","        output_tokens, h, c = inference_decoder.predict([target_sequence] + states_value)\n","        \n","        # Get the token with max probability\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_word = target_reverse_dictionary[sampled_token_index]\n","        decoded_sentence += ' ' + sampled_word\n","        \n","        # Test for exit condition\n","        if (sampled_word == '<END>') or (len(decoded_sentence) > 50):\n","            stop_condition = True\n","            \n","        # Update the target sequence with current prediction\n","        target_sequence = np.zeros((1, 1))\n","        target_sequence[0, 0] = sampled_token_index\n","        \n","        # Update states\n","        states_value = [h, c]\n","    return decoded_sentence"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"text","id":"eehBSrbvLefc"},"cell_type":"markdown","source":["### 6. Evaluation on Train Dataset"]},{"metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1554793582924,"user_tz":-330,"elapsed":1345,"user":{"displayName":"Nishit Jain","photoUrl":"https://lh3.googleusercontent.com/-t8Yv52GhJHs/AAAAAAAAAAI/AAAAAAAABPE/8bbheaBAj4s/s64/photo.jpg","userId":"00220384259459575150"}},"id":"s2D1wd2NLefl","outputId":"77554d99-9f3c-45a7-b19d-bb7f6f5980be","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["input_sequence = encode_input([''])\n","decoded_sentence = decode_sequence(input_sequence)\n","' '.join(decoded_sentence.split()[:-1])"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'माझं नाव आहे'"]},"metadata":{"tags":[]},"execution_count":43}]},{"metadata":{"id":"yM-WPO4E6P5H","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}