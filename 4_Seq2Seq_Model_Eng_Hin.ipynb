{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uLi2DmWTEhAs",
    "outputId": "fe8daca1-d551-4adc-f2a1-a231684647f4"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rM5YLYnEaIC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, CuDNNLSTM, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'en-hi_cleaned.en')) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = pd.DataFrame(lines, columns=['Src'])\n",
    "lines['Tar'] = None\n",
    "\n",
    "with open(os.path.join(root, 'en-hi_cleaned.hi')) as f:\n",
    "    lines['Tar'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JZ93EncFMAI"
   },
   "outputs": [],
   "source": [
    "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
    "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
    "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P-1ZpmG5EaIS",
    "outputId": "ffe2a57e-43fe-4a3c-c3fb-48f71b5929e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jbggjuAlEaIY",
    "outputId": "199696d0-ad6c-444f-b473-ef46069d3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>version</td>\n",
       "      <td>&lt;START&gt; संस्करण &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>name x y</td>\n",
       "      <td>&lt;START&gt; नाम &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>widget</td>\n",
       "      <td>&lt;START&gt; विडजेट &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>co mponent</td>\n",
       "      <td>&lt;START&gt; घटक &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>selected accessible</td>\n",
       "      <td>&lt;START&gt; चुने गए एक्सेसेबेल &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the color and opacity of the highlight fill</td>\n",
       "      <td>&lt;START&gt; हाइलाइट किया गया भराई का रंग और पारदर्...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>highlight border color</td>\n",
       "      <td>&lt;START&gt; सीमांत बोर्डर के रंग को हाइलाइट करें &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>c lear selection</td>\n",
       "      <td>&lt;START&gt; चुनाव को हटाएं &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>offset</td>\n",
       "      <td>&lt;START&gt; ओफसेट &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>uri</td>\n",
       "      <td>&lt;START&gt; यूआरआई &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Src  \\\n",
       "39                                      version   \n",
       "69                                     name x y   \n",
       "45                                       widget   \n",
       "50                                   co mponent   \n",
       "24                          selected accessible   \n",
       "10  the color and opacity of the highlight fill   \n",
       "7                        highlight border color   \n",
       "21                             c lear selection   \n",
       "76                                       offset   \n",
       "88                                          uri   \n",
       "\n",
       "                                                  Tar  \n",
       "39                              <START> संस्करण <END>  \n",
       "69                                  <START> नाम <END>  \n",
       "45                               <START> विडजेट <END>  \n",
       "50                                  <START> घटक <END>  \n",
       "24                   <START> चुने गए एक्सेसेबेल <END>  \n",
       "10  <START> हाइलाइट किया गया भराई का रंग और पारदर्...  \n",
       "7   <START> सीमांत बोर्डर के रंग को हाइलाइट करें <...  \n",
       "21                       <START> चुनाव को हटाएं <END>  \n",
       "76                                <START> ओफसेट <END>  \n",
       "88                               <START> यूआरआई <END>  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n",
    "    src_summary = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(root, 'embeddings.hi'), 'rb') as f:\n",
    "    tar_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['<START>', '<END>']:\n",
    "    length_of_dict = len(tar_summary['dictionary'])\n",
    "    tar_summary['dictionary'][word] = length_of_dict\n",
    "    tar_summary['reverse_dictionary'][length_of_dict] = word\n",
    "    tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8RpqWyHEaIh"
   },
   "outputs": [],
   "source": [
    "all_src_words = src_summary['dictionary'].keys()\n",
    "all_tar_words = tar_summary['dictionary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUSc8xudEaIj",
    "outputId": "81501477-dade-4de8-f4ed-c84c8a5b042f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
    "max_len_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIpfnXPuEaIr",
    "outputId": "9f019370-7208-4399-8d35-8533e9eaaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
    "max_len_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y9wvsBmEaIu",
    "outputId": "914dd109-d172-45f5-e5b2-8c5d3f8e6b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8333, 4605)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_src_words)\n",
    "num_decoder_tokens = len(all_tar_words)\n",
    "(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mLxuTbVfEaIy",
    "outputId": "cacd96de-0904-4df3-defc-d3a1a509e531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>end</td>\n",
       "      <td>&lt;START&gt; अंत &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>hyperlink</td>\n",
       "      <td>&lt;START&gt; हाइपरकड़ी &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>acti on</td>\n",
       "      <td>&lt;START&gt; कार्रवाई &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a list of plugins that are disabled by default</td>\n",
       "      <td>&lt;START&gt; उन प्लग इनों की सूची जिन्हें डिफोल्ट र...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>header</td>\n",
       "      <td>&lt;START&gt; शीर्षकः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>everything</td>\n",
       "      <td>&lt;START&gt; सभी &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>api browser</td>\n",
       "      <td>&lt;START&gt; एपीआई विचरक &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>col lection</td>\n",
       "      <td>&lt;START&gt; संग्रह &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>not implemented</td>\n",
       "      <td>&lt;START&gt; क्रियान्वित नहीं हुआ है &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>version</td>\n",
       "      <td>&lt;START&gt; संस्करण &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Src  \\\n",
       "90                                             end   \n",
       "54                                       hyperlink   \n",
       "36                                         acti on   \n",
       "4   a list of plugins that are disabled by default   \n",
       "70                                          header   \n",
       "22                                      everything   \n",
       "11                                     api browser   \n",
       "41                                     col lection   \n",
       "86                                 not implemented   \n",
       "39                                         version   \n",
       "\n",
       "                                                  Tar  \n",
       "90                                  <START> अंत <END>  \n",
       "54                            <START> हाइपरकड़ी <END>  \n",
       "36                             <START> कार्रवाई <END>  \n",
       "4   <START> उन प्लग इनों की सूची जिन्हें डिफोल्ट र...  \n",
       "70                              <START> शीर्षकः <END>  \n",
       "22                                  <START> सभी <END>  \n",
       "11                          <START> एपीआई विचरक <END>  \n",
       "41                               <START> संग्रह <END>  \n",
       "86              <START> क्रियान्वित नहीं हुआ है <END>  \n",
       "39                              <START> संस्करण <END>  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_source(batch_input, batch_size):\n",
    "    encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(batch_input):\n",
    "        for t, word in enumerate(input_text.split(' ')):\n",
    "            if word not in src_summary['dictionary'].keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            encoder_input_data[i, t] = src_summary['dictionary'][word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(batch_output, batch_size):\n",
    "    decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(batch_output):\n",
    "        for t, word in enumerate(target_text.split(' ')):\n",
    "            if word not in tar_summary['dictionary'].keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            if t < len(target_text.split())-1:\n",
    "                decoder_input_data[i, t-1] = tar_summary['dictionary'][word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, tar_summary['dictionary'][word]] = 1\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_source(X[j:j+batch_size], batch_size)\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size], batch_size)\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90,), (10,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.Src, lines.Tar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = src_summary['embeddings'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 10\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, ), name='Inputs')\n",
    "encoder_embeddings = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, weights=[src_summary['embeddings']], name='English_Embeddings')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='Outputs')\n",
    "decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, weights=[tar_summary['embeddings']], name='Hindi_Embeddings')\n",
    "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense_Eng_Hin' + str(datetime.today().date()))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(root, \"best_model_en_hi.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 5s 542ms/step - loss: 6.3163 - acc: 0.0746 - val_loss: 5.2899 - val_acc: 0.0741\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.07461, saving model to ./best_model_en_hi.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "9/9 [==============================] - 3s 331ms/step - loss: 5.9277 - acc: 0.0629 - val_loss: 5.1470 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00002: acc did not improve\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 3s 347ms/step - loss: 4.9442 - acc: 0.0296 - val_loss: 4.9122 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00003: acc did not improve\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 3s 327ms/step - loss: 4.5311 - acc: 0.0303 - val_loss: 4.7434 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00004: acc did not improve\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 4.2912 - acc: 0.0303 - val_loss: 4.6407 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00005: acc did not improve\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 3s 338ms/step - loss: 4.1318 - acc: 0.0303 - val_loss: 4.5896 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00006: acc did not improve\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 4.0216 - acc: 0.0303 - val_loss: 4.5805 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00007: acc did not improve\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 3.9364 - acc: 0.0303 - val_loss: 4.5909 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00008: acc did not improve\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 3s 339ms/step - loss: 3.8659 - acc: 0.0303 - val_loss: 4.6029 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00009: acc did not improve\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 3s 307ms/step - loss: 3.8045 - acc: 0.0303 - val_loss: 4.6117 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00010: acc did not improve\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 3.7505 - acc: 0.0325 - val_loss: 4.6242 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00011: acc did not improve\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 3s 334ms/step - loss: 3.7046 - acc: 0.0325 - val_loss: 4.6379 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00012: acc did not improve\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 3s 342ms/step - loss: 3.6665 - acc: 0.0325 - val_loss: 4.6548 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00013: acc did not improve\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 3s 352ms/step - loss: 3.6338 - acc: 0.0375 - val_loss: 4.6695 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00014: acc did not improve\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 3s 352ms/step - loss: 3.6031 - acc: 0.0398 - val_loss: 4.6721 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00015: acc did not improve\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 3s 353ms/step - loss: 3.5732 - acc: 0.0441 - val_loss: 4.6805 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00016: acc did not improve\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 3.5417 - acc: 0.0490 - val_loss: 4.6785 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00017: acc did not improve\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 3.5095 - acc: 0.0541 - val_loss: 4.6890 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00018: acc did not improve\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 3.4739 - acc: 0.0617 - val_loss: 4.6804 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00019: acc did not improve\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 3s 332ms/step - loss: 3.4354 - acc: 0.0624 - val_loss: 4.6741 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00020: acc did not improve\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 3s 325ms/step - loss: 3.3912 - acc: 0.0670 - val_loss: 4.6597 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00021: acc did not improve\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 3s 322ms/step - loss: 3.3430 - acc: 0.0670 - val_loss: 4.6490 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00022: acc did not improve\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 3.2910 - acc: 0.0774 - val_loss: 4.6298 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00023: acc improved from 0.07461 to 0.07743, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 3s 339ms/step - loss: 3.2325 - acc: 0.0774 - val_loss: 4.6121 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00024: acc did not improve\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 3s 340ms/step - loss: 3.1698 - acc: 0.0886 - val_loss: 4.5875 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00025: acc improved from 0.07743 to 0.08859, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 3s 329ms/step - loss: 3.1046 - acc: 0.0932 - val_loss: 4.5649 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00026: acc improved from 0.08859 to 0.09323, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 3s 308ms/step - loss: 3.0312 - acc: 0.1082 - val_loss: 4.5390 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00027: acc improved from 0.09323 to 0.10817, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 2.9628 - acc: 0.1151 - val_loss: 4.5143 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00028: acc improved from 0.10817 to 0.11506, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 3s 355ms/step - loss: 2.8850 - acc: 0.1228 - val_loss: 4.4893 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00029: acc improved from 0.11506 to 0.12279, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 4s 452ms/step - loss: 2.8058 - acc: 0.1343 - val_loss: 4.4546 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00030: acc improved from 0.12279 to 0.13426, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 3s 371ms/step - loss: 2.7241 - acc: 0.1436 - val_loss: 4.4299 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00031: acc improved from 0.13426 to 0.14359, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 2.6413 - acc: 0.1674 - val_loss: 4.4076 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00032: acc improved from 0.14359 to 0.16743, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 2.5662 - acc: 0.1866 - val_loss: 4.3795 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00033: acc improved from 0.16743 to 0.18665, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 4s 414ms/step - loss: 2.4869 - acc: 0.2169 - val_loss: 4.3559 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00034: acc improved from 0.18665 to 0.21694, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 4s 452ms/step - loss: 2.3965 - acc: 0.2250 - val_loss: 4.3132 - val_acc: 0.0370\n",
      "\n",
      "Epoch 00035: acc improved from 0.21694 to 0.22505, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 3s 330ms/step - loss: 2.3134 - acc: 0.2492 - val_loss: 4.3003 - val_acc: 0.0741\n",
      "\n",
      "Epoch 00036: acc improved from 0.22505 to 0.24916, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 3s 335ms/step - loss: 2.2316 - acc: 0.2718 - val_loss: 4.2621 - val_acc: 0.0741\n",
      "\n",
      "Epoch 00037: acc improved from 0.24916 to 0.27176, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 3s 321ms/step - loss: 2.1530 - acc: 0.3010 - val_loss: 4.2353 - val_acc: 0.0741\n",
      "\n",
      "Epoch 00038: acc improved from 0.27176 to 0.30099, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 3s 312ms/step - loss: 2.0669 - acc: 0.3187 - val_loss: 4.2243 - val_acc: 0.0741\n",
      "\n",
      "Epoch 00039: acc improved from 0.30099 to 0.31874, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 4s 477ms/step - loss: 1.9855 - acc: 0.3425 - val_loss: 4.1893 - val_acc: 0.1111\n",
      "\n",
      "Epoch 00040: acc improved from 0.31874 to 0.34248, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 4s 409ms/step - loss: 1.9085 - acc: 0.3591 - val_loss: 4.1675 - val_acc: 0.1111\n",
      "\n",
      "Epoch 00041: acc improved from 0.34248 to 0.35912, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 3s 365ms/step - loss: 1.8308 - acc: 0.3871 - val_loss: 4.1506 - val_acc: 0.1111\n",
      "\n",
      "Epoch 00042: acc improved from 0.35912 to 0.38709, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 3s 333ms/step - loss: 1.7507 - acc: 0.4125 - val_loss: 4.1052 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00043: acc improved from 0.38709 to 0.41254, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 3s 336ms/step - loss: 1.6842 - acc: 0.4234 - val_loss: 4.0892 - val_acc: 0.1481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: acc improved from 0.41254 to 0.42343, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 3s 328ms/step - loss: 1.6095 - acc: 0.4304 - val_loss: 4.0608 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00045: acc improved from 0.42343 to 0.43040, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 3s 318ms/step - loss: 1.5354 - acc: 0.4445 - val_loss: 4.0278 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00046: acc improved from 0.43040 to 0.44453, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 4s 415ms/step - loss: 1.4718 - acc: 0.4557 - val_loss: 4.0005 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00047: acc improved from 0.44453 to 0.45565, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 4s 397ms/step - loss: 1.4082 - acc: 0.4754 - val_loss: 3.9744 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00048: acc improved from 0.45565 to 0.47543, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 4s 411ms/step - loss: 1.3558 - acc: 0.5043 - val_loss: 3.9344 - val_acc: 0.1481\n",
      "\n",
      "Epoch 00049: acc improved from 0.47543 to 0.50433, saving model to ./best_model_en_hi.hdf5\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 3s 351ms/step - loss: 1.2866 - acc: 0.5220 - val_loss: 3.9341 - val_acc: 0.1852\n",
      "\n",
      "Epoch 00050: acc improved from 0.50433 to 0.52196, saving model to ./best_model_en_hi.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1186941d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(root, 'translator_en_hi.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBZ7-lRCEaJa"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyCfJ_OBEaJd"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_summary['dictionary']['<START>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tar_summary['reverse_dictionary'][sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9B4W79kEaJf"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w840p8M2EaJi",
    "outputId": "202c4304-073f-47e7-acf5-8c354f8d0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: plugin with various methods of selecting accessibles quickly\n",
      "Actual Hindi Translation:  प्लग इन जिसमें हैं एक्सेसेबेलों को तेजी से चुनने के लिए कई विधियां \n",
      "Predicted Hindi Translation:  प्लग प्लग प्लग प्लग प्लग को को को को को को को को\n",
      "Input English sentence: selected cell\n",
      "Actual Hindi Translation:  चुनी गई कोशिका \n",
      "Predicted Hindi Translation:  चुनी गई कोशिका कोशिका कोशिका कोशिका कोशिका कोशि\n",
      "Input English sentence: accessible\n",
      "Actual Hindi Translation:  पहुंचनीय \n",
      "Predicted Hindi Translation:  चुने स्तंभ स्तंभ स्तंभ स्तंभ स्तंभ स्तंभ स्तंभ \n",
      "Input English sentence: too many selectable children\n",
      "Actual Hindi Translation:  बहुत अधिक चयनीय शिशु हैं \n",
      "Predicted Hindi Translation:  बहुत अधिक चयनीय शिशु हैं हैं हैं हैं हैं हैं है\n",
      "Input English sentence: value\n",
      "Actual Hindi Translation:  मान \n",
      "Predicted Hindi Translation:  मान मान मान मान मान मान मान मान मान मान मान मा\n",
      "Input English sentence: toolkit\n",
      "Actual Hindi Translation:  औजार बक्सा \n",
      "Predicted Hindi Translation:  औजार औजार बक्सा बक्सा बक्सा बक्सा बक्सा बक्सा \n",
      "Input English sentence: document\n",
      "Actual Hindi Translation:  प्रलेख \n",
      "Predicted Hindi Translation:  प्रलेख प्रलेख प्रलेख प्रलेख प्रलेख प्रलेख प्रलेख प\n",
      "Input English sentence: include defaults\n",
      "Actual Hindi Translation:  डिफोल्टों को शामिल करें \n",
      "Predicted Hindi Translation:  डिफोल्टों डिफोल्टों को करें करें करें करें करें\n",
      "Input English sentence: ipython console\n",
      "Actual Hindi Translation:  आईपाइथन कन्सोल \n",
      "Predicted Hindi Translation:  आईपाइथन आईपाइथन कन्सोल कन्सोल कन्सोल कन्सोल है \n",
      "Input English sentence: the color and opacity of the highlight fill\n",
      "Actual Hindi Translation:  हाइलाइट किया गया भराई का रंग और पारदर्शिता \n",
      "Predicted Hindi Translation:  हाइलाइट हाइलाइट हाइलाइट हाइलाइट हाइलाइट हाइलाइट हा\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    k+=1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Hindi Translation:', y_train[k:k+1].values[0][7:-5])\n",
    "    print('Predicted Hindi Translation:', decoded_sentence[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVzXHer8QdkW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
