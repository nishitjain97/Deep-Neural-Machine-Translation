{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uLi2DmWTEhAs",
    "outputId": "fe8daca1-d551-4adc-f2a1-a231684647f4"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rM5YLYnEaIC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import os\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, CuDNNLSTM, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'en-hi_cleaned.en')) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = pd.DataFrame(lines, columns=['Src'])\n",
    "lines['Tar'] = None\n",
    "\n",
    "with open(os.path.join(root, 'en-hi_cleaned.hi')) as f:\n",
    "    lines['Tar'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JZ93EncFMAI"
   },
   "outputs": [],
   "source": [
    "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
    "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
    "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P-1ZpmG5EaIS",
    "outputId": "ffe2a57e-43fe-4a3c-c3fb-48f71b5929e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jbggjuAlEaIY",
    "outputId": "199696d0-ad6c-444f-b473-ef46069d3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65231</th>\n",
       "      <td>import bookmarks…</td>\n",
       "      <td>&lt;START&gt; पसंद आयात करें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46727</th>\n",
       "      <td>c ase sensitive</td>\n",
       "      <td>&lt;START&gt; स्थिति के प्रति संवेदनशील &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>properties of s</td>\n",
       "      <td>&lt;START&gt; की विशेषता &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12478</th>\n",
       "      <td>interpreter</td>\n",
       "      <td>&lt;START&gt; इंटरफेस &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39760</th>\n",
       "      <td>burst mode</td>\n",
       "      <td>&lt;START&gt; बर्स्ट विधि &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14676</th>\n",
       "      <td>visible</td>\n",
       "      <td>&lt;START&gt; दृष्टिगोचर &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22104</th>\n",
       "      <td>retrieving status…</td>\n",
       "      <td>&lt;START&gt; पुनःप्राप्त कर रहा है स्थिति &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27816</th>\n",
       "      <td>could not create context</td>\n",
       "      <td>&lt;START&gt; अस्थायी फाईल बनाने में असमर्थ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>gtype</td>\n",
       "      <td>&lt;START&gt; क़िस्म &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31732</th>\n",
       "      <td>drag or copy files below to write them to disc</td>\n",
       "      <td>&lt;START&gt; फाइल को नीचे डिस्क में लिखने के लिए खी...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Src  \\\n",
       "65231                               import bookmarks…   \n",
       "46727                                 c ase sensitive   \n",
       "29642                                 properties of s   \n",
       "12478                                     interpreter   \n",
       "39760                                      burst mode   \n",
       "14676                                         visible   \n",
       "22104                              retrieving status…   \n",
       "27816                        could not create context   \n",
       "9289                                            gtype   \n",
       "31732  drag or copy files below to write them to disc   \n",
       "\n",
       "                                                     Tar  \n",
       "65231                       <START> पसंद आयात करें <END>  \n",
       "46727            <START> स्थिति के प्रति संवेदनशील <END>  \n",
       "29642                           <START> की विशेषता <END>  \n",
       "12478                              <START> इंटरफेस <END>  \n",
       "39760                          <START> बर्स्ट विधि <END>  \n",
       "14676                           <START> दृष्टिगोचर <END>  \n",
       "22104         <START> पुनःप्राप्त कर रहा है स्थिति <END>  \n",
       "27816        <START> अस्थायी फाईल बनाने में असमर्थ <END>  \n",
       "9289                                <START> क़िस्म <END>  \n",
       "31732  <START> फाइल को नीचे डिस्क में लिखने के लिए खी...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'embeddings.en'), 'rb') as f:\n",
    "    src_summary = pickle.load(f)\n",
    "    \n",
    "with open(os.path.join(root, 'embeddings.hi'), 'rb') as f:\n",
    "    tar_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in ['<START>', '<END>']:\n",
    "    length_of_dict = len(tar_summary['dictionary'])\n",
    "    tar_summary['dictionary'][word] = length_of_dict\n",
    "    tar_summary['reverse_dictionary'][length_of_dict] = word\n",
    "    tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8RpqWyHEaIh"
   },
   "outputs": [],
   "source": [
    "all_src_words = src_summary['dictionary'].keys()\n",
    "all_tar_words = tar_summary['dictionary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUSc8xudEaIj",
    "outputId": "81501477-dade-4de8-f4ed-c84c8a5b042f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
    "max_len_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIpfnXPuEaIr",
    "outputId": "9f019370-7208-4399-8d35-8533e9eaaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
    "max_len_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y9wvsBmEaIu",
    "outputId": "914dd109-d172-45f5-e5b2-8c5d3f8e6b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8333, 4605)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_src_words)\n",
    "num_decoder_tokens = len(all_tar_words)\n",
    "(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mLxuTbVfEaIy",
    "outputId": "cacd96de-0904-4df3-defc-d3a1a509e531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25443</th>\n",
       "      <td>fetch</td>\n",
       "      <td>&lt;START&gt; पाएँ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33633</th>\n",
       "      <td>blank disc…</td>\n",
       "      <td>&lt;START&gt; खाली डिस्क &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18060</th>\n",
       "      <td>create backup files</td>\n",
       "      <td>&lt;START&gt; बैकअप फ़ाइलें बनाएँ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57235</th>\n",
       "      <td>location at date</td>\n",
       "      <td>&lt;START&gt; स्थान तिथि पर &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22710</th>\n",
       "      <td>inline the declaration and implementation</td>\n",
       "      <td>&lt;START&gt; इनलाइल डिक्लेरेशन और कार्यान्वयन &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>path</td>\n",
       "      <td>&lt;START&gt; पथः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20929</th>\n",
       "      <td>source directories</td>\n",
       "      <td>&lt;START&gt; स्रोत निर्देशिकाएँ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46661</th>\n",
       "      <td>font for text with fixed width such as code ex...</td>\n",
       "      <td>&lt;START&gt; कोड उदाहरण के रूप में फिक्स्ड चौड़ाई क...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60504</th>\n",
       "      <td>open image</td>\n",
       "      <td>&lt;START&gt; चित्र खोलें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24837</th>\n",
       "      <td>program interrupt</td>\n",
       "      <td>&lt;START&gt; प्रोग्राम इंटरप्ट &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Src  \\\n",
       "25443                                              fetch   \n",
       "33633                                        blank disc…   \n",
       "18060                                create backup files   \n",
       "57235                                   location at date   \n",
       "22710          inline the declaration and implementation   \n",
       "25011                                               path   \n",
       "20929                                 source directories   \n",
       "46661  font for text with fixed width such as code ex...   \n",
       "60504                                         open image   \n",
       "24837                                  program interrupt   \n",
       "\n",
       "                                                     Tar  \n",
       "25443                                 <START> पाएँ <END>  \n",
       "33633                           <START> खाली डिस्क <END>  \n",
       "18060                  <START> बैकअप फ़ाइलें बनाएँ <END>  \n",
       "57235                        <START> स्थान तिथि पर <END>  \n",
       "22710     <START> इनलाइल डिक्लेरेशन और कार्यान्वयन <END>  \n",
       "25011                                  <START> पथः <END>  \n",
       "20929                   <START> स्रोत निर्देशिकाएँ <END>  \n",
       "46661  <START> कोड उदाहरण के रूप में फिक्स्ड चौड़ाई क...  \n",
       "60504                          <START> चित्र खोलें <END>  \n",
       "24837                    <START> प्रोग्राम इंटरप्ट <END>  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_source(batch_input, batch_size):\n",
    "    encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(batch_input):\n",
    "        for t, word in enumerate(input_text.split(' ')):\n",
    "            if word not in src_summary['dictionary'].keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            encoder_input_data[i, t] = src_summary['dictionary'][word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(batch_output, batch_size):\n",
    "    decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(batch_output):\n",
    "        for t, word in enumerate(target_text.split(' ')):\n",
    "            if word not in tar_summary['dictionary'].keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            if t < len(target_text.split())-1:\n",
    "                decoder_input_data[i, t-1] = tar_summary['dictionary'][word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, tar_summary['dictionary'][word]] = 1\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_source(X[j:j+batch_size], batch_size)\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size], batch_size)\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63000,), (7000,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.Src, lines.Tar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = src_summary['embeddings'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, ), name='Inputs')\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, weights=[src_summary['embeddings']], name='English_Embeddings')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='Outputs')\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, weights=[tar_summary['embeddings']], name='Hindi_Embeddings')\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense_Eng_Hin' + str(datetime.today().date()))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(root, \"best_model.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(root, 'translator' + str(datetime.today().date()) + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBZ7-lRCEaJa"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyCfJ_OBEaJd"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_summary['dictionary']['<START>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tar_summary['reverse_dictionary'][sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9B4W79kEaJf"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w840p8M2EaJi",
    "outputId": "202c4304-073f-47e7-acf5-8c354f8d0c1a"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    k+=1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Hindi Translation:', y_train[k:k+1].values[0][7:-5])\n",
    "    print('Predicted Hindi Translation:', decoded_sentence[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVzXHer8QdkW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
