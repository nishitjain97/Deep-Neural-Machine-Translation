{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uLi2DmWTEhAs",
    "outputId": "fe8daca1-d551-4adc-f2a1-a231684647f4"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rM5YLYnEaIC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, CuDNNLSTM, LSTM\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNIYiRcsEaIM"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'en-mar_cleaned.en')) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = pd.DataFrame(lines, columns=['Src'])\n",
    "lines['Tar'] = None\n",
    "\n",
    "with open(os.path.join(root, 'en-mar_cleaned.ma')) as f:\n",
    "    lines['Tar'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JZ93EncFMAI"
   },
   "outputs": [],
   "source": [
    "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
    "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
    "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P-1ZpmG5EaIS",
    "outputId": "ffe2a57e-43fe-4a3c-c3fb-48f71b5929e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jbggjuAlEaIY",
    "outputId": "199696d0-ad6c-444f-b473-ef46069d3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30563</th>\n",
       "      <td>copy cd dvd</td>\n",
       "      <td>&lt;START&gt; सीडी व डीवीडी की नक़ल करें &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>easthaven</td>\n",
       "      <td>&lt;START&gt; ईस्टहैवन &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27292</th>\n",
       "      <td>scroll pane</td>\n",
       "      <td>&lt;START&gt; स्क्रॉल फलक &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>golf</td>\n",
       "      <td>&lt;START&gt; गोल्फ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37067</th>\n",
       "      <td>if you import them you will be able to see and...</td>\n",
       "      <td>&lt;START&gt; यदि आप उन्हें आयात करते हैं तो आप एक ब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41266</th>\n",
       "      <td>whether the input cursor is visible</td>\n",
       "      <td>&lt;START&gt; क्या इनपुट संकेतक दिखाई देता है &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27277</th>\n",
       "      <td>menu bar</td>\n",
       "      <td>&lt;START&gt; मेन्यू पट्टी &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25783</th>\n",
       "      <td>plugin title</td>\n",
       "      <td>&lt;START&gt; प्लगइन शीर्षकः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10200</th>\n",
       "      <td>select file to add</td>\n",
       "      <td>&lt;START&gt; डैरक्टरी चुनो &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35184</th>\n",
       "      <td>do you really want to quit</td>\n",
       "      <td>&lt;START&gt; क्या आप सचमुच बाहर होना चाहते हैं &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Src  \\\n",
       "30563                                        copy cd dvd   \n",
       "4147                                           easthaven   \n",
       "27292                                        scroll pane   \n",
       "3059                                                golf   \n",
       "37067  if you import them you will be able to see and...   \n",
       "41266                whether the input cursor is visible   \n",
       "27277                                           menu bar   \n",
       "25783                                       plugin title   \n",
       "10200                                 select file to add   \n",
       "35184                         do you really want to quit   \n",
       "\n",
       "                                                     Tar  \n",
       "30563           <START> सीडी व डीवीडी की नक़ल करें <END>  \n",
       "4147                              <START> ईस्टहैवन <END>  \n",
       "27292                          <START> स्क्रॉल फलक <END>  \n",
       "3059                                 <START> गोल्फ <END>  \n",
       "37067  <START> यदि आप उन्हें आयात करते हैं तो आप एक ब...  \n",
       "41266      <START> क्या इनपुट संकेतक दिखाई देता है <END>  \n",
       "27277                         <START> मेन्यू पट्टी <END>  \n",
       "25783                       <START> प्लगइन शीर्षकः <END>  \n",
       "10200                        <START> डैरक्टरी चुनो <END>  \n",
       "35184    <START> क्या आप सचमुच बाहर होना चाहते हैं <END>  "
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeXniREjEaIe"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/English Dataset/embeddings.en', 'rb') as f:\n",
    "    src_summary = pickle.load(f)\n",
    "    \n",
    "with open('/content/drive/My Drive/English Dataset/embeddings.hi', 'rb') as f:\n",
    "    tar_summary = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "foNrsONtFlvO"
   },
   "outputs": [],
   "source": [
    "length_of_dict = len(tar_summary['dictionary'])\n",
    "tar_summary['dictionary']['<START>'] = length_of_dict\n",
    "tar_summary['reverse_dictionary'][length_of_dict] = '<START>'\n",
    "tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))\n",
    "\n",
    "length_of_dict = len(tar_summary['dictionary'])\n",
    "tar_summary['dictionary']['<END>'] = length_of_dict\n",
    "tar_summary['reverse_dictionary'][length_of_dict] = '<END>'\n",
    "tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a8RpqWyHEaIh"
   },
   "outputs": [],
   "source": [
    "all_src_words = src_summary['dictionary'].keys()\n",
    "all_tar_words = tar_summary['dictionary'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUSc8xudEaIj",
    "outputId": "81501477-dade-4de8-f4ed-c84c8a5b042f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
    "max_len_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIpfnXPuEaIr",
    "outputId": "9f019370-7208-4399-8d35-8533e9eaaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
    "max_len_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y9wvsBmEaIu",
    "outputId": "914dd109-d172-45f5-e5b2-8c5d3f8e6b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100002)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_src_words)\n",
    "num_decoder_tokens = len(all_tar_words)\n",
    "(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mLxuTbVfEaIy",
    "outputId": "cacd96de-0904-4df3-defc-d3a1a509e531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34932</th>\n",
       "      <td>with</td>\n",
       "      <td>&lt;START&gt; के साथ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17075</th>\n",
       "      <td>path</td>\n",
       "      <td>&lt;START&gt; पथ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>ten of spades</td>\n",
       "      <td>&lt;START&gt; हुकुम का दहला &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12304</th>\n",
       "      <td>parameters</td>\n",
       "      <td>&lt;START&gt; पैरामीटर्सः &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>additional object files for this target</td>\n",
       "      <td>&lt;START&gt; अतिरिक्त वस्तु फ़ाइल के लिए यह लक्ष्य ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21312</th>\n",
       "      <td>file manager</td>\n",
       "      <td>&lt;START&gt; फ़ाइल प्रबंधक &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37115</th>\n",
       "      <td>please insert a writable cd or dvd if you don ...</td>\n",
       "      <td>&lt;START&gt; कृपया एक लिखने योग्य सीडी या डीवीडी घु...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7742</th>\n",
       "      <td>a sample sdl project</td>\n",
       "      <td>&lt;START&gt; नमूना sdl प्रोजेक्ट &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40920</th>\n",
       "      <td>the rotation center on the x axis</td>\n",
       "      <td>&lt;START&gt; x अक्ष पर घुमाव कोण &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21557</th>\n",
       "      <td>revert a commit</td>\n",
       "      <td>&lt;START&gt; उलटें a &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Src  \\\n",
       "34932                                               with   \n",
       "17075                                               path   \n",
       "4856                                       ten of spades   \n",
       "12304                                         parameters   \n",
       "12787            additional object files for this target   \n",
       "21312                                       file manager   \n",
       "37115  please insert a writable cd or dvd if you don ...   \n",
       "7742                                a sample sdl project   \n",
       "40920                  the rotation center on the x axis   \n",
       "21557                                    revert a commit   \n",
       "\n",
       "                                                     Tar  \n",
       "34932                               <START> के साथ <END>  \n",
       "17075                                   <START> पथ <END>  \n",
       "4856                         <START> हुकुम का दहला <END>  \n",
       "12304                          <START> पैरामीटर्सः <END>  \n",
       "12787  <START> अतिरिक्त वस्तु फ़ाइल के लिए यह लक्ष्य ...  \n",
       "21312                        <START> फ़ाइल प्रबंधक <END>  \n",
       "37115  <START> कृपया एक लिखने योग्य सीडी या डीवीडी घु...  \n",
       "7742                   <START> नमूना sdl प्रोजेक्ट <END>  \n",
       "40920                  <START> x अक्ष पर घुमाव कोण <END>  \n",
       "21557                              <START> उलटें a <END>  "
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HQrGCSbUEaI7"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "  while True:\n",
    "    for j in range(0, len(X), batch_size):\n",
    "      encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
    "      decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
    "      decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
    "      \n",
    "      for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "          if word not in src_summary['dictionary'].keys():\n",
    "            word = 'UNK'\n",
    "          encoder_input_data[i, t] = src_summary['dictionary'][word]\n",
    "        \n",
    "        for t, word in enumerate(target_text.split()):\n",
    "          if word not in tar_summary['dictionary'].keys():\n",
    "            word = 'UNK'\n",
    "          \n",
    "          if t < len(target_text.split())-1:\n",
    "            decoder_input_data\n",
    "            \n",
    "          if t > 0:\n",
    "            decoder_target_data[i, t-1, tar_summary['dictionary'][word]] = 1\n",
    "            \n",
    "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1323
    },
    "colab_type": "code",
    "id": "E3FFBHD5GuiI",
    "outputId": "cbaae66c-07f2-47a1-87d1-ae2764493fda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set: 1\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-d1423a84aa67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                       validation_steps=val_samples//batch_size)\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/English Dataset/translator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,114,100002] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_4/RMSprop/gradients/loss_4/Dense_loss/truediv_grad/Neg}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node metrics_4/acc/Mean_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lines) // 1000):\n",
    "  print('Set:', i+1)\n",
    "  X, y = lines.Src[i * 1000:(i+1) * 1000], lines.Tar[i * 1000:(i+1) * 1000]\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "  \n",
    "  latent_dim = 64\n",
    "  \n",
    "  train_samples = len(X_train)\n",
    "  val_samples = len(X_test)\n",
    "  batch_size = 16\n",
    "  epochs = 5\n",
    "  \n",
    "  if i > 0:\n",
    "    model.load_weights('/content/drive/My Drive/English Dataset/translator.h5')\n",
    "  \n",
    "  ### Encoder ###\n",
    "  # Input layer\n",
    "  encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
    "\n",
    "  # Word2Vec embedding layer\n",
    "  encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, \n",
    "                                      weights=[src_summary['embeddings']], \n",
    "                                      name='English_Embeddings')\n",
    "  encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "  # Encoder LSTM layer\n",
    "  encoder_lstm = LSTM(64, return_state=True, name='Encoder_LSTM')\n",
    "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
    "\n",
    "  # Save states for decoder\n",
    "  encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "  ### Decoder ###\n",
    "  # Input layer\n",
    "  decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
    "\n",
    "  # Word2Vec embedding layer\n",
    "  decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, \n",
    "                                      weights=[tar_summary['embeddings']], \n",
    "                                      name='Hindi_Embeddings')\n",
    "  decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "  # Decoder LSTM layer\n",
    "  decoder_lstm = LSTM(64, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "  decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
    "\n",
    "  # Fully connected Softmax layer for predictions\n",
    "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense')\n",
    "  decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "  ### Model ###\n",
    "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "  model.fit_generator(generator=generate_batch(X_train, y_train, batch_size=batch_size), \n",
    "                      steps_per_epoch=train_samples//batch_size, \n",
    "                      epochs=epochs, \n",
    "                      validation_data=generate_batch(X_test, y_test, batch_size=batch_size), \n",
    "                      validation_steps=val_samples//batch_size)\n",
    "\n",
    "  model.save('/content/drive/My Drive/English Dataset/translator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DBZ7-lRCEaJa"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyCfJ_OBEaJd"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_summary['dictionary']['<START>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tar_summary['reverse_dictionary'][sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9B4W79kEaJf"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w840p8M2EaJi",
    "outputId": "202c4304-073f-47e7-acf5-8c354f8d0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: col lection\n",
      "Actual Hindi Translation:  संग्रह \n",
      "Predicted Hindi Translation:  विवरण विवरण \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][7:-5])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmkOOEZCEaJk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "Aay7cTRgEaJm",
    "outputId": "749e452f-bd3e-4c4f-9e4a-bbc5a546a899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
      "google.colab serverextension initialized.\n",
      "Serving notebooks from local directory: /\n",
      "0 active kernels\n",
      "The Jupyter Notebook is running at:\n",
      "http://172.28.0.2:9000/\n",
      "Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "Kernel started: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "2019-04-01 14:36:25.486024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-04-01 14:36:25.486495: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c2520 executing computations on platform Host. Devices:\n",
      "2019-04-01 14:36:25.486530: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-01 14:36:25.633812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 14:36:25.634531: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c1fa0 executing computations on platform CUDA. Devices:\n",
      "2019-04-01 14:36:25.634563: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-04-01 14:36:25.635939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 14:36:25.636333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-04-01 14:36:27.076814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-01 14:36:27.076971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-04-01 14:36:27.076992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-04-01 14:36:27.077415: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-04-01 14:36:27.077517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-04-01 14:36:34.217251: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7f392d9fe000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7f37ed304000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
      "KernelRestarter: restarting kernel (1/5), keep random ports\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "2019-04-01 14:42:23.533314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-04-01 14:42:23.534469: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5e520 executing computations on platform Host. Devices:\n",
      "2019-04-01 14:42:23.534510: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-01 14:42:23.695447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 14:42:23.696692: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5dfa0 executing computations on platform CUDA. Devices:\n",
      "2019-04-01 14:42:23.696758: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-04-01 14:42:23.697534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 14:42:23.697604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-04-01 14:42:24.745623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-01 14:42:24.745702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-04-01 14:42:24.745724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-04-01 14:42:24.746543: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-04-01 14:42:24.746716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x40360000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7fcfff906000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
      "KernelRestarter: restarting kernel (1/5), keep random ports\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
    "  for line in fo:\n",
    "    print(json.loads(line)['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVzXHer8QdkW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
