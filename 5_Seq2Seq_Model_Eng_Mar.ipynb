{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uLi2DmWTEhAs",
    "outputId": "fe8daca1-d551-4adc-f2a1-a231684647f4"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rM5YLYnEaIC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, CuDNNLSTM, LSTM\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNIYiRcsEaIM"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'en-mar_cleaned.en')) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = pd.DataFrame(lines, columns=['Src'])\n",
    "lines['Tar'] = None\n",
    "\n",
    "with open(os.path.join(root, 'en-mar_cleaned.ma')) as f:\n",
    "    lines['Tar'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JZ93EncFMAI"
   },
   "outputs": [],
   "source": [
    "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
    "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
    "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P-1ZpmG5EaIS",
    "outputId": "ffe2a57e-43fe-4a3c-c3fb-48f71b5929e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33725, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jbggjuAlEaIY",
    "outputId": "199696d0-ad6c-444f-b473-ef46069d3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>the keys are on the table</td>\n",
       "      <td>&lt;START&gt; चाव्या टेबलावर आहेत &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15399</th>\n",
       "      <td>im having lots of fun</td>\n",
       "      <td>&lt;START&gt; मला खूप मजा येत आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11963</th>\n",
       "      <td>it was fun yesterday</td>\n",
       "      <td>&lt;START&gt; काल मजा आली &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32258</th>\n",
       "      <td>there are many words that i dont understand</td>\n",
       "      <td>&lt;START&gt; असे भरपूर शब्द आहेत जे मला कळत नाहीत &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6934</th>\n",
       "      <td>the tank is empty</td>\n",
       "      <td>&lt;START&gt; टाकी रिकामी आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31835</th>\n",
       "      <td>the building on the right side is a school</td>\n",
       "      <td>&lt;START&gt; उजव्या बाजूला असलेली बिल्डिंग एक शाळा ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26584</th>\n",
       "      <td>night is when most people sleep</td>\n",
       "      <td>&lt;START&gt; बहुतेक लोकं रात्री झोपतात &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4784</th>\n",
       "      <td>give me your gun</td>\n",
       "      <td>&lt;START&gt; बंदूक दे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24859</th>\n",
       "      <td>she stayed there for a moment</td>\n",
       "      <td>&lt;START&gt; ती तिथे एक क्षण राहिली &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17746</th>\n",
       "      <td>did you feed the parrots</td>\n",
       "      <td>&lt;START&gt; पोपटांना खायला दिलंस का &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Src  \\\n",
       "20000                    the keys are on the table   \n",
       "15399                        im having lots of fun   \n",
       "11963                         it was fun yesterday   \n",
       "32258  there are many words that i dont understand   \n",
       "6934                             the tank is empty   \n",
       "31835   the building on the right side is a school   \n",
       "26584              night is when most people sleep   \n",
       "4784                              give me your gun   \n",
       "24859                she stayed there for a moment   \n",
       "17746                     did you feed the parrots   \n",
       "\n",
       "                                                     Tar  \n",
       "20000                  <START> चाव्या टेबलावर आहेत <END>  \n",
       "15399                  <START> मला खूप मजा येत आहे <END>  \n",
       "11963                          <START> काल मजा आली <END>  \n",
       "32258  <START> असे भरपूर शब्द आहेत जे मला कळत नाहीत <...  \n",
       "6934                       <START> टाकी रिकामी आहे <END>  \n",
       "31835  <START> उजव्या बाजूला असलेली बिल्डिंग एक शाळा ...  \n",
       "26584            <START> बहुतेक लोकं रात्री झोपतात <END>  \n",
       "4784                              <START> बंदूक दे <END>  \n",
       "24859               <START> ती तिथे एक क्षण राहिली <END>  \n",
       "17746              <START> पोपटांना खायला दिलंस का <END>  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeXniREjEaIe"
   },
   "outputs": [],
   "source": [
    "all_src_words = set()\n",
    "for line in lines.Src:\n",
    "    all_src_words = all_src_words.union(set(list(line.split(' '))))\n",
    "    \n",
    "all_tar_words = set()\n",
    "for line in lines.Tar:\n",
    "    all_tar_words = all_tar_words.union(set(list(line.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dict = dict()\n",
    "\n",
    "for index, word in enumerate(sorted(all_src_words)):\n",
    "    src_dict[word] = len(src_dict)\n",
    "    \n",
    "tar_dict = dict()\n",
    "\n",
    "for index, word in enumerate(sorted(all_tar_words)):\n",
    "    tar_dict[word] = len(tar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_rev_dict = dict()\n",
    "\n",
    "for key, value in src_dict.items():\n",
    "    src_rev_dict[value] = key\n",
    "    \n",
    "tar_rev_dict = dict()\n",
    "\n",
    "for key, value in tar_dict.items():\n",
    "    tar_rev_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUSc8xudEaIj",
    "outputId": "81501477-dade-4de8-f4ed-c84c8a5b042f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
    "max_len_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIpfnXPuEaIr",
    "outputId": "9f019370-7208-4399-8d35-8533e9eaaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
    "max_len_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y9wvsBmEaIu",
    "outputId": "914dd109-d172-45f5-e5b2-8c5d3f8e6b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5388, 12697)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_src_words)\n",
    "num_decoder_tokens = len(all_tar_words)\n",
    "(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mLxuTbVfEaIy",
    "outputId": "cacd96de-0904-4df3-defc-d3a1a509e531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17100</th>\n",
       "      <td>that isnt what i meant</td>\n",
       "      <td>&lt;START&gt; माझा तो अर्थ नव्हता &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>i was learning</td>\n",
       "      <td>&lt;START&gt; मी शिकत होते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15443</th>\n",
       "      <td>is everybody listening</td>\n",
       "      <td>&lt;START&gt; सगळे ऐकताहेत का &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27817</th>\n",
       "      <td>i like learning ancient languages</td>\n",
       "      <td>&lt;START&gt; मला प्राचीन भाषा शिकायला आवडतात &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22374</th>\n",
       "      <td>i will buy a car next month</td>\n",
       "      <td>&lt;START&gt; मी पुढच्या महिन्यात एक गाडी विकत घेईन ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>i have already eaten lunch</td>\n",
       "      <td>&lt;START&gt; मी आधीच जेवलो आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>i like bananas</td>\n",
       "      <td>&lt;START&gt; मला केळी आवडतात &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>where were you born</td>\n",
       "      <td>&lt;START&gt; तुझा जन्म कुठे झाला होता &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25422</th>\n",
       "      <td>dont forget to write the date</td>\n",
       "      <td>&lt;START&gt; दिनांक लिहायला विसरू नकोस &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>tom needs me</td>\n",
       "      <td>&lt;START&gt; टॉमला माझी गरज आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Src  \\\n",
       "17100             that isnt what i meant   \n",
       "2688                      i was learning   \n",
       "15443             is everybody listening   \n",
       "27817  i like learning ancient languages   \n",
       "22374        i will buy a car next month   \n",
       "20952         i have already eaten lunch   \n",
       "2616                      i like bananas   \n",
       "10996                where were you born   \n",
       "25422      dont forget to write the date   \n",
       "1448                        tom needs me   \n",
       "\n",
       "                                                     Tar  \n",
       "17100                  <START> माझा तो अर्थ नव्हता <END>  \n",
       "2688                          <START> मी शिकत होते <END>  \n",
       "15443                      <START> सगळे ऐकताहेत का <END>  \n",
       "27817      <START> मला प्राचीन भाषा शिकायला आवडतात <END>  \n",
       "22374  <START> मी पुढच्या महिन्यात एक गाडी विकत घेईन ...  \n",
       "20952                    <START> मी आधीच जेवलो आहे <END>  \n",
       "2616                       <START> मला केळी आवडतात <END>  \n",
       "10996             <START> तुझा जन्म कुठे झाला होता <END>  \n",
       "25422            <START> दिनांक लिहायला विसरू नकोस <END>  \n",
       "1448                    <START> टॉमला माझी गरज आहे <END>  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_source(batch_input, batch_size):\n",
    "    encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(batch_input):\n",
    "        for t, word in enumerate(input_text.split(' ')):\n",
    "            if word not in src_dict.keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            encoder_input_data[i, t] = src_dict[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(batch_output, batch_size):\n",
    "    decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(batch_output):\n",
    "        for t, word in enumerate(target_text.split(' ')):\n",
    "            if word not in tar_dict.keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            if t < len(target_text.split())-1:\n",
    "                decoder_input_data[i, t-1] = tar_dict[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, tar_dict[word]] = 1\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_source(X[j:j+batch_size], batch_size)\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size], batch_size)\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30352,), (3373,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.Src, lines.Tar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, ), name='Inputs')\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, name='English_Embeddings2')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='Outputs')\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, name='Marathi_Embeddings')\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense_Eng_Mar' + str(datetime.today().date()))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'translator_en_hi.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-caf3a7f1256a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'translator_en_hi.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'translator_en_hi.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "model.load_weights(os.path.join(root, 'translator_en_hi.h5'), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(root, \"best_model_en_ma.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(root, 'translator_en_ma.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_dict['<START>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tar_rev_dict[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9B4W79kEaJf"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w840p8M2EaJi",
    "outputId": "202c4304-073f-47e7-acf5-8c354f8d0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: col lection\n",
      "Actual Hindi Translation:  संग्रह \n",
      "Predicted Hindi Translation:  विवरण विवरण \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    k+=1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Marathi Translation:', y_train[k:k+1].values[0][7:-5])\n",
    "    print('Predicted Marathi Translation:', decoded_sentence[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmkOOEZCEaJk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "Aay7cTRgEaJm",
    "outputId": "749e452f-bd3e-4c4f-9e4a-bbc5a546a899"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
      "google.colab serverextension initialized.\n",
      "Serving notebooks from local directory: /\n",
      "0 active kernels\n",
      "The Jupyter Notebook is running at:\n",
      "http://172.28.0.2:9000/\n",
      "Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
      "Kernel started: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "2019-04-01 14:36:25.486024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-04-01 14:36:25.486495: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c2520 executing computations on platform Host. Devices:\n",
      "2019-04-01 14:36:25.486530: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-01 14:36:25.633812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 14:36:25.634531: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c1fa0 executing computations on platform CUDA. Devices:\n",
      "2019-04-01 14:36:25.634563: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-04-01 14:36:25.635939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 14:36:25.636333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-04-01 14:36:27.076814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-01 14:36:27.076971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-04-01 14:36:27.076992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-04-01 14:36:27.077415: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-04-01 14:36:27.077517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "2019-04-01 14:36:34.217251: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
      "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7f392d9fe000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7f37ed304000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
      "KernelRestarter: restarting kernel (1/5), keep random ports\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "2019-04-01 14:42:23.533314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
      "2019-04-01 14:42:23.534469: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5e520 executing computations on platform Host. Devices:\n",
      "2019-04-01 14:42:23.534510: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-04-01 14:42:23.695447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2019-04-01 14:42:23.696692: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5dfa0 executing computations on platform CUDA. Devices:\n",
      "2019-04-01 14:42:23.696758: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
      "2019-04-01 14:42:23.697534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
      "pciBusID: 0000:00:04.0\n",
      "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
      "2019-04-01 14:42:23.697604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2019-04-01 14:42:24.745623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-04-01 14:42:24.745702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2019-04-01 14:42:24.745724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2019-04-01 14:42:24.746543: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2019-04-01 14:42:24.746716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x40360000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
      "tcmalloc: large alloc 5376024576 bytes == 0x7fcfff906000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
      "KernelRestarter: restarting kernel (1/5), keep random ports\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
      "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
    "  for line in fo:\n",
    "    print(json.loads(line)['msg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MVzXHer8QdkW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
