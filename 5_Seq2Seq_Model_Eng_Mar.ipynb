{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uLi2DmWTEhAs",
    "outputId": "fe8daca1-d551-4adc-f2a1-a231684647f4"
   },
   "outputs": [],
   "source": [
    "# # Mount the Google drive onto Colab Virtual Environment\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "root = '.'\n",
    "# root = '/content/drive/My Drive/English Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rM5YLYnEaIC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, Embedding, Dense, CuDNNLSTM, LSTM\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNIYiRcsEaIM"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(root, 'en-mar_cleaned.en')) as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = pd.DataFrame(lines, columns=['Src'])\n",
    "lines['Tar'] = None\n",
    "\n",
    "with open(os.path.join(root, 'en-mar_cleaned.ma')) as f:\n",
    "    lines['Tar'] = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JZ93EncFMAI"
   },
   "outputs": [],
   "source": [
    "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
    "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
    "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P-1ZpmG5EaIS",
    "outputId": "ffe2a57e-43fe-4a3c-c3fb-48f71b5929e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33725, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "jbggjuAlEaIY",
    "outputId": "199696d0-ad6c-444f-b473-ef46069d3438"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>tom is out</td>\n",
       "      <td>&lt;START&gt; टॉम आउट झाला आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>look out</td>\n",
       "      <td>&lt;START&gt; सांभाळ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>i eat here</td>\n",
       "      <td>&lt;START&gt; मी इथे जेवतो &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>who fell</td>\n",
       "      <td>&lt;START&gt; कोण पडलं &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>ask anyone</td>\n",
       "      <td>&lt;START&gt; कोणालाही विचार &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>tom is dead</td>\n",
       "      <td>&lt;START&gt; टॉम मेला आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>he has wine</td>\n",
       "      <td>&lt;START&gt; त्याच्याकडे वाईन आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>we are here</td>\n",
       "      <td>&lt;START&gt; आम्ही इथे आहोत &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>lets talk</td>\n",
       "      <td>&lt;START&gt; बोलू या &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>this is mad</td>\n",
       "      <td>&lt;START&gt; हा वेडेपणा आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Src                                 Tar\n",
       "606   tom is out      <START> टॉम आउट झाला आहे <END>\n",
       "160     look out                <START> सांभाळ <END>\n",
       "457   i eat here          <START> मी इथे जेवतो <END>\n",
       "200     who fell              <START> कोण पडलं <END>\n",
       "405   ask anyone        <START> कोणालाही विचार <END>\n",
       "943  tom is dead          <START> टॉम मेला आहे <END>\n",
       "714  he has wine  <START> त्याच्याकडे वाईन आहे <END>\n",
       "991  we are here        <START> आम्ही इथे आहोत <END>\n",
       "552    lets talk               <START> बोलू या <END>\n",
       "935  this is mad        <START> हा वेडेपणा आहे <END>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeXniREjEaIe"
   },
   "outputs": [],
   "source": [
    "all_src_words = set()\n",
    "for line in lines.Src:\n",
    "    all_src_words = all_src_words.union(set(list(line.split(' '))))\n",
    "    \n",
    "all_tar_words = set()\n",
    "for line in lines.Tar:\n",
    "    all_tar_words = all_tar_words.union(set(list(line.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dict = dict()\n",
    "\n",
    "for index, word in enumerate(sorted(all_src_words)):\n",
    "    src_dict[word] = len(src_dict)\n",
    "    \n",
    "tar_dict = dict()\n",
    "\n",
    "for index, word in enumerate(sorted(all_tar_words)):\n",
    "    tar_dict[word] = len(tar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_rev_dict = dict()\n",
    "\n",
    "for key, value in src_dict.items():\n",
    "    src_rev_dict[value] = key\n",
    "    \n",
    "tar_rev_dict = dict()\n",
    "\n",
    "for key, value in tar_dict.items():\n",
    "    tar_rev_dict[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oUSc8xudEaIj",
    "outputId": "81501477-dade-4de8-f4ed-c84c8a5b042f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
    "max_len_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oIpfnXPuEaIr",
    "outputId": "9f019370-7208-4399-8d35-8533e9eaaed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
    "max_len_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y9wvsBmEaIu",
    "outputId": "914dd109-d172-45f5-e5b2-8c5d3f8e6b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(378, 680)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(all_src_words)\n",
    "num_decoder_tokens = len(all_tar_words)\n",
    "(num_encoder_tokens, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "mLxuTbVfEaIy",
    "outputId": "cacd96de-0904-4df3-defc-d3a1a509e531"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src</th>\n",
       "      <th>Tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>she bit him</td>\n",
       "      <td>&lt;START&gt; त्यांनी त्याला चावलं &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>i saw tom</td>\n",
       "      <td>&lt;START&gt; मी टॉमला बघितलं &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>its yours</td>\n",
       "      <td>&lt;START&gt; तुमचं आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>im resting</td>\n",
       "      <td>&lt;START&gt; मी आराम करतोय &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>im a liar</td>\n",
       "      <td>&lt;START&gt; मी खोटारडा आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>call me</td>\n",
       "      <td>&lt;START&gt; मला फोन करा &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>look again</td>\n",
       "      <td>&lt;START&gt; परत बघ &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>ill start</td>\n",
       "      <td>&lt;START&gt; मी सुरुवात करते &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>i can go</td>\n",
       "      <td>&lt;START&gt; मी जाऊ शकतो &lt;END&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>im tom</td>\n",
       "      <td>&lt;START&gt; मी टॉम आहे &lt;END&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Src                                 Tar\n",
       "900  she bit him  <START> त्यांनी त्याला चावलं <END>\n",
       "263    i saw tom       <START> मी टॉमला बघितलं <END>\n",
       "538    its yours             <START> तुमचं आहे <END>\n",
       "824   im resting         <START> मी आराम करतोय <END>\n",
       "500    im a liar        <START> मी खोटारडा आहे <END>\n",
       "56       call me           <START> मला फोन करा <END>\n",
       "553   look again                <START> परत बघ <END>\n",
       "499    ill start       <START> मी सुरुवात करते <END>\n",
       "132     i can go           <START> मी जाऊ शकतो <END>\n",
       "83        im tom            <START> मी टॉम आहे <END>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_source(batch_input, batch_size):\n",
    "    encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
    "    \n",
    "    for i, input_text in enumerate(batch_input):\n",
    "        for t, word in enumerate(input_text.split(' ')):\n",
    "            if word not in src_dict.keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            encoder_input_data[i, t] = src_dict[word]\n",
    "            \n",
    "    return encoder_input_data\n",
    "\n",
    "def encode_target(batch_output, batch_size):\n",
    "    decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
    "    decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
    "    \n",
    "    for i, target_text in enumerate(batch_output):\n",
    "        for t, word in enumerate(target_text.split(' ')):\n",
    "            if word not in tar_dict.keys():\n",
    "                word = 'UNK'\n",
    "                \n",
    "            if t < len(target_text.split())-1:\n",
    "                decoder_input_data[i, t-1] = tar_dict[word]\n",
    "                \n",
    "            if t > 0:\n",
    "                decoder_target_data[i, t-1, tar_dict[word]] = 1\n",
    "                \n",
    "    return decoder_input_data, decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, y, batch_size):\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = encode_source(X[j:j+batch_size], batch_size)\n",
    "            decoder_input_data, decoder_target_data = encode_target(y[j:j+batch_size], batch_size)\n",
    "            \n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900,), (100,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = lines.Src, lines.Tar\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 32\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, ), name='Inputs')\n",
    "enc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True, name='English_Embeddings2')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True, name='Encoder_LSTM')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='Outputs')\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True, name='Marathi_Embeddings')\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense_Eng_Mar' + str(datetime.today().date()))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(root, 'translator_en_hi.h5'), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(root, \"best_model_en_ma.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "28/28 [==============================] - 5s 191ms/step - loss: 4.3471 - acc: 0.1145 - val_loss: 4.0179 - val_acc: 0.0846\n",
      "\n",
      "Epoch 00001: acc improved from -inf to 0.11454, saving model to ./best_model_en_ma.hdf5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 3.7180 - acc: 0.1121 - val_loss: 3.7996 - val_acc: 0.0570\n",
      "\n",
      "Epoch 00002: acc did not improve\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 3s 100ms/step - loss: 3.4667 - acc: 0.1193 - val_loss: 3.6904 - val_acc: 0.1158\n",
      "\n",
      "Epoch 00003: acc improved from 0.11454 to 0.11934, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 3.2414 - acc: 0.1430 - val_loss: 3.5457 - val_acc: 0.1232\n",
      "\n",
      "Epoch 00004: acc improved from 0.11934 to 0.14296, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 3.0521 - acc: 0.1660 - val_loss: 3.3981 - val_acc: 0.1541\n",
      "\n",
      "Epoch 00005: acc improved from 0.14296 to 0.16597, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 2.8688 - acc: 0.1933 - val_loss: 3.0941 - val_acc: 0.1590\n",
      "\n",
      "Epoch 00006: acc improved from 0.16597 to 0.19327, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 2.6745 - acc: 0.2265 - val_loss: 3.0087 - val_acc: 0.1812\n",
      "\n",
      "Epoch 00007: acc improved from 0.19327 to 0.22655, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 2.5037 - acc: 0.2534 - val_loss: 2.9124 - val_acc: 0.2733\n",
      "\n",
      "Epoch 00008: acc improved from 0.22655 to 0.25335, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 2.3284 - acc: 0.2912 - val_loss: 2.8626 - val_acc: 0.2838\n",
      "\n",
      "Epoch 00009: acc improved from 0.25335 to 0.29124, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 3s 103ms/step - loss: 2.1855 - acc: 0.3178 - val_loss: 2.6020 - val_acc: 0.3097\n",
      "\n",
      "Epoch 00010: acc improved from 0.29124 to 0.31779, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 2.0321 - acc: 0.3479 - val_loss: 2.5690 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00011: acc improved from 0.31779 to 0.34795, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 1.8896 - acc: 0.3787 - val_loss: 2.5111 - val_acc: 0.3465\n",
      "\n",
      "Epoch 00012: acc improved from 0.34795 to 0.37870, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 1.7651 - acc: 0.4045 - val_loss: 2.5384 - val_acc: 0.3651\n",
      "\n",
      "Epoch 00013: acc improved from 0.37870 to 0.40454, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 1.6525 - acc: 0.4293 - val_loss: 2.3409 - val_acc: 0.3668\n",
      "\n",
      "Epoch 00014: acc improved from 0.40454 to 0.42929, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 1.5316 - acc: 0.4486 - val_loss: 2.3171 - val_acc: 0.3802\n",
      "\n",
      "Epoch 00015: acc improved from 0.42929 to 0.44862, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 2s 87ms/step - loss: 1.4326 - acc: 0.4704 - val_loss: 2.2751 - val_acc: 0.3842\n",
      "\n",
      "Epoch 00016: acc improved from 0.44862 to 0.47041, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 1.3205 - acc: 0.4916 - val_loss: 2.3763 - val_acc: 0.4005\n",
      "\n",
      "Epoch 00017: acc improved from 0.47041 to 0.49159, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 2s 75ms/step - loss: 1.2354 - acc: 0.5070 - val_loss: 2.1544 - val_acc: 0.4065\n",
      "\n",
      "Epoch 00018: acc improved from 0.49159 to 0.50696, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 2s 78ms/step - loss: 1.1475 - acc: 0.5231 - val_loss: 2.1707 - val_acc: 0.4303\n",
      "\n",
      "Epoch 00019: acc improved from 0.50696 to 0.52312, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 1.0573 - acc: 0.5439 - val_loss: 2.1071 - val_acc: 0.4342\n",
      "\n",
      "Epoch 00020: acc improved from 0.52312 to 0.54393, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.9826 - acc: 0.5552 - val_loss: 2.2570 - val_acc: 0.4431\n",
      "\n",
      "Epoch 00021: acc improved from 0.54393 to 0.55524, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.9110 - acc: 0.5693 - val_loss: 1.9943 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00022: acc improved from 0.55524 to 0.56926, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 3s 90ms/step - loss: 0.8411 - acc: 0.5833 - val_loss: 2.0553 - val_acc: 0.4638\n",
      "\n",
      "Epoch 00023: acc improved from 0.56926 to 0.58333, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.7695 - acc: 0.6002 - val_loss: 1.9519 - val_acc: 0.4767\n",
      "\n",
      "Epoch 00024: acc improved from 0.58333 to 0.60024, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 2s 74ms/step - loss: 0.7137 - acc: 0.6128 - val_loss: 2.1533 - val_acc: 0.4617\n",
      "\n",
      "Epoch 00025: acc improved from 0.60024 to 0.61280, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.6497 - acc: 0.6335 - val_loss: 1.8631 - val_acc: 0.4775\n",
      "\n",
      "Epoch 00026: acc improved from 0.61280 to 0.63353, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.5910 - acc: 0.6468 - val_loss: 1.9407 - val_acc: 0.4818\n",
      "\n",
      "Epoch 00027: acc improved from 0.63353 to 0.64679, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.5467 - acc: 0.6567 - val_loss: 1.8442 - val_acc: 0.4943\n",
      "\n",
      "Epoch 00028: acc improved from 0.64679 to 0.65672, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 2s 81ms/step - loss: 0.4951 - acc: 0.6673 - val_loss: 2.1206 - val_acc: 0.4957\n",
      "\n",
      "Epoch 00029: acc improved from 0.65672 to 0.66733, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 2s 77ms/step - loss: 0.4631 - acc: 0.6777 - val_loss: 1.7632 - val_acc: 0.5029\n",
      "\n",
      "Epoch 00030: acc improved from 0.66733 to 0.67771, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.4102 - acc: 0.6894 - val_loss: 1.8647 - val_acc: 0.5020\n",
      "\n",
      "Epoch 00031: acc improved from 0.67771 to 0.68942, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.3727 - acc: 0.6967 - val_loss: 1.7483 - val_acc: 0.5147\n",
      "\n",
      "Epoch 00032: acc improved from 0.68942 to 0.69672, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 2s 84ms/step - loss: 0.3380 - acc: 0.7021 - val_loss: 2.0803 - val_acc: 0.5126\n",
      "\n",
      "Epoch 00033: acc improved from 0.69672 to 0.70214, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.3036 - acc: 0.7079 - val_loss: 1.7150 - val_acc: 0.5029\n",
      "\n",
      "Epoch 00034: acc improved from 0.70214 to 0.70794, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 3s 91ms/step - loss: 0.2722 - acc: 0.7104 - val_loss: 1.8387 - val_acc: 0.5048\n",
      "\n",
      "Epoch 00035: acc improved from 0.70794 to 0.71038, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.2449 - acc: 0.7137 - val_loss: 1.7050 - val_acc: 0.5261\n",
      "\n",
      "Epoch 00036: acc improved from 0.71038 to 0.71371, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 3s 96ms/step - loss: 0.2182 - acc: 0.7162 - val_loss: 2.0679 - val_acc: 0.5243\n",
      "\n",
      "Epoch 00037: acc improved from 0.71371 to 0.71620, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.1964 - acc: 0.7159 - val_loss: 1.6577 - val_acc: 0.5092\n",
      "\n",
      "Epoch 00038: acc did not improve\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 2s 80ms/step - loss: 0.1745 - acc: 0.7163 - val_loss: 1.7982 - val_acc: 0.5103\n",
      "\n",
      "Epoch 00039: acc improved from 0.71620 to 0.71633, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 3s 103ms/step - loss: 0.1576 - acc: 0.7174 - val_loss: 1.6549 - val_acc: 0.5292\n",
      "\n",
      "Epoch 00040: acc improved from 0.71633 to 0.71741, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 2s 88ms/step - loss: 0.1378 - acc: 0.7176 - val_loss: 2.0385 - val_acc: 0.5276\n",
      "\n",
      "Epoch 00041: acc improved from 0.71741 to 0.71760, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.1227 - acc: 0.7179 - val_loss: 1.6152 - val_acc: 0.5156\n",
      "\n",
      "Epoch 00042: acc improved from 0.71760 to 0.71787, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.1093 - acc: 0.7176 - val_loss: 1.7772 - val_acc: 0.5228\n",
      "\n",
      "Epoch 00043: acc did not improve\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 2s 83ms/step - loss: 0.0955 - acc: 0.7181 - val_loss: 1.6222 - val_acc: 0.5319\n",
      "\n",
      "Epoch 00044: acc improved from 0.71787 to 0.71805, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.0860 - acc: 0.7177 - val_loss: 2.0212 - val_acc: 0.5368\n",
      "\n",
      "Epoch 00045: acc did not improve\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 2s 86ms/step - loss: 0.0730 - acc: 0.7175 - val_loss: 1.5978 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00046: acc did not improve\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 2s 80ms/step - loss: 0.0651 - acc: 0.7182 - val_loss: 1.7706 - val_acc: 0.5228\n",
      "\n",
      "Epoch 00047: acc improved from 0.71805 to 0.71823, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 2s 76ms/step - loss: 0.0569 - acc: 0.7182 - val_loss: 1.6210 - val_acc: 0.5350\n",
      "\n",
      "Epoch 00048: acc did not improve\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 2s 79ms/step - loss: 0.0489 - acc: 0.7185 - val_loss: 2.0460 - val_acc: 0.5399\n",
      "\n",
      "Epoch 00049: acc improved from 0.71823 to 0.71850, saving model to ./best_model_en_ma.hdf5\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 2s 73ms/step - loss: 0.0437 - acc: 0.7185 - val_loss: 1.5773 - val_acc: 0.5189\n",
      "\n",
      "Epoch 00050: acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x110fba438>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size, \n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer Decoder_LSTM was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'Encoder_LSTM/while/Exit_2:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'Encoder_LSTM/while/Exit_3:0' shape=(?, 128) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(root, 'translator_en_ma.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = tar_dict['<START>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = tar_rev_dict[sampled_token_index]\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "            \n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9B4W79kEaJf"
   },
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "w840p8M2EaJi",
    "outputId": "202c4304-073f-47e7-acf5-8c354f8d0c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input English sentence: i see them\n",
      "Actual Marathi Translation:  मी त्यांना बघतो \n",
      "Predicted Marathi Translation:  बघू बघू दिलं दिलं करतो करतो करतो करतो करतो करतो\n",
      "Input English sentence: i know\n",
      "Actual Marathi Translation:  मला माहीत आहे \n",
      "Predicted Marathi Translation:  माझा तुमच्यावर होता होता होता होता होता होता होत\n",
      "Input English sentence: i was naked\n",
      "Actual Marathi Translation:  मी नग्न होते \n",
      "Predicted Marathi Translation:  माझा होते होते होते होते होते होते होते होते होते\n",
      "Input English sentence: it burned\n",
      "Actual Marathi Translation:  जळलं \n",
      "Predicted Marathi Translation:  जळला जळला जळला जळला जळला जळला जळला जळला जळला जळला\n",
      "Input English sentence: he can read\n",
      "Actual Marathi Translation:  त्याला वाचता येतं \n",
      "Predicted Marathi Translation:  बघू काम काम काम काम काम काम काम काम काम काम का\n",
      "Input English sentence: get started\n",
      "Actual Marathi Translation:  सुरू करा \n",
      "Predicted Marathi Translation:  सुरू सुरू सुरू सुरू सुरू सुरू सुरू सुरू सुरू सुरू\n",
      "Input English sentence: is he tall\n",
      "Actual Marathi Translation:  तो उंच आहे का \n",
      "Predicted Marathi Translation:  माझा हवे हवे हवे हवे हवे हवे हवे हवे हवे हवे हव\n",
      "Input English sentence: tomll die\n",
      "Actual Marathi Translation:  टॉम मरेल \n",
      "Predicted Marathi Translation:  असं निघा आहात आहात आहात आहात आहात आहात आहात आहात\n",
      "Input English sentence: tom drowned\n",
      "Actual Marathi Translation:  टॉम बुडला \n",
      "Predicted Marathi Translation:  टॉमने टॉमने टॉमने केली केली केली केली केली केली\n",
      "Input English sentence: back off\n",
      "Actual Marathi Translation:  हट \n",
      "Predicted Marathi Translation:  हट हट हट हट हट हट हट हट हट हट हट हट हट हट हट \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    k+=1\n",
    "    (input_seq, actual_output), _ = next(train_gen)\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "    print('Actual Marathi Translation:', y_train[k:k+1].values[0][7:-5])\n",
    "    print('Predicted Marathi Translation:', decoded_sentence[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VmkOOEZCEaJk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "4_Seq2Seq_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
