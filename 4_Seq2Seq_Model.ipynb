{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_Seq2Seq_Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishitjain97/Example-Based-Neural-Machine-Translation-System/blob/master/4_Seq2Seq_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uLi2DmWTEhAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6de25698-c7ce-451a-a166-682dd44e6b92"
      },
      "cell_type": "code",
      "source": [
        "# Mount Google Drive onto Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rM5YLYnEaIC",
        "colab_type": "code",
        "outputId": "cb704f87-2125-4c60-b905-30f353329502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, Embedding, Dense, CuDNNLSTM\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PNIYiRcsEaIM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/English Dataset/IITB.en-hi_cleaned.en') as f:\n",
        "  sentences = f.readlines()\n",
        "  \n",
        "lines = pd.DataFrame(sentences, columns=['Src'])\n",
        "\n",
        "lines['Tar'] = None\n",
        "\n",
        "with open('/content/drive/My Drive/English Dataset/IITB.en-hi_cleaned.hi') as f:\n",
        "  lines['Tar'] = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JZ93EncFMAI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lines.Src = lines.Src.apply(lambda x: x.strip())\n",
        "lines.Tar = lines.Tar.apply(lambda x: x.strip())\n",
        "lines.Tar = '<START> ' + lines.Tar + ' <END>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-1ZpmG5EaIS",
        "colab_type": "code",
        "outputId": "0b4f8be2-5977-47fb-db93-eb134ece1d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "lines.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "jbggjuAlEaIY",
        "colab_type": "code",
        "outputId": "0aa6adc3-79e0-44ac-f84a-39f94330e594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "lines.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src</th>\n",
              "      <th>Tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7758</th>\n",
              "      <td>generic gcj compiled java</td>\n",
              "      <td>&lt;START&gt; generic gcj compiled java &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2058</th>\n",
              "      <td>move a onto the nine of clubs</td>\n",
              "      <td>&lt;START&gt; a को चिड़ी का नहला पर ले जाएँ &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491</th>\n",
              "      <td>maximum value</td>\n",
              "      <td>&lt;START&gt; अधिकतम मान &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5899</th>\n",
              "      <td>aim to place the suits in the order which fits...</td>\n",
              "      <td>&lt;START&gt; वर्तमान विन्यास अति प्राकृतिक रूप से त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>red joker</td>\n",
              "      <td>&lt;START&gt; लाल जोकर &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8559</th>\n",
              "      <td>conflicted</td>\n",
              "      <td>&lt;START&gt; विरोधी &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3486</th>\n",
              "      <td>the king of diamonds</td>\n",
              "      <td>&lt;START&gt; ईंट का बादशाह &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6371</th>\n",
              "      <td>documents</td>\n",
              "      <td>&lt;START&gt; खाली दस्तावेज &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7137</th>\n",
              "      <td>default project directory</td>\n",
              "      <td>&lt;START&gt; कार्य डायरेक्टरी &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4090</th>\n",
              "      <td>the game file to use</td>\n",
              "      <td>&lt;START&gt; खेल फ़ाइल उपयोग में &lt;END&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Src  \\\n",
              "7758                          generic gcj compiled java   \n",
              "2058                      move a onto the nine of clubs   \n",
              "1491                                      maximum value   \n",
              "5899  aim to place the suits in the order which fits...   \n",
              "3270                                          red joker   \n",
              "8559                                         conflicted   \n",
              "3486                               the king of diamonds   \n",
              "6371                                          documents   \n",
              "7137                          default project directory   \n",
              "4090                               the game file to use   \n",
              "\n",
              "                                                    Tar  \n",
              "7758            <START> generic gcj compiled java <END>  \n",
              "2058        <START> a को चिड़ी का नहला पर ले जाएँ <END>  \n",
              "1491                           <START> अधिकतम मान <END>  \n",
              "5899  <START> वर्तमान विन्यास अति प्राकृतिक रूप से त...  \n",
              "3270                             <START> लाल जोकर <END>  \n",
              "8559                               <START> विरोधी <END>  \n",
              "3486                        <START> ईंट का बादशाह <END>  \n",
              "6371                        <START> खाली दस्तावेज <END>  \n",
              "7137                     <START> कार्य डायरेक्टरी <END>  \n",
              "4090                  <START> खेल फ़ाइल उपयोग में <END>  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "IeXniREjEaIe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/English Dataset/embeddings.en', 'rb') as f:\n",
        "    src_summary = pickle.load(f)\n",
        "    \n",
        "with open('/content/drive/My Drive/English Dataset/embeddings.hi', 'rb') as f:\n",
        "    tar_summary = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foNrsONtFlvO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length_of_dict = len(tar_summary['dictionary'])\n",
        "tar_summary['dictionary']['<START>'] = length_of_dict\n",
        "tar_summary['reverse_dictionary'][length_of_dict] = '<START>'\n",
        "tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))\n",
        "\n",
        "length_of_dict = len(tar_summary['dictionary'])\n",
        "tar_summary['dictionary']['<END>'] = length_of_dict\n",
        "tar_summary['reverse_dictionary'][length_of_dict] = '<END>'\n",
        "tar_summary['embeddings'] = np.vstack((tar_summary['embeddings'], np.zeros((tar_summary['embeddings'].shape[1]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8RpqWyHEaIh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_src_words = src_summary['dictionary'].keys()\n",
        "all_tar_words = tar_summary['dictionary'].keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oUSc8xudEaIj",
        "colab_type": "code",
        "outputId": "86a3364b-1e2d-444a-f1cd-1afa131ab6a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_len_src = max([len(sentence.split(' ')) for sentence in lines.Src])\n",
        "max_len_src"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "oIpfnXPuEaIr",
        "colab_type": "code",
        "outputId": "d83f3f3e-eb4b-497d-dfb7-e424a5ce5087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "max_len_tar = max([len(sentence.split(' ')) for sentence in lines.Tar])\n",
        "max_len_tar"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "6y9wvsBmEaIu",
        "colab_type": "code",
        "outputId": "2e748869-0941-4c00-8ed6-8edc82dce21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "num_encoder_tokens = len(all_src_words)\n",
        "num_decoder_tokens = len(all_tar_words)\n",
        "(num_encoder_tokens, num_decoder_tokens)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 500002)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "mLxuTbVfEaIy",
        "colab_type": "code",
        "outputId": "e5dcd92f-a34b-4dbc-c773-deb5b4a1dc45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "lines = shuffle(lines)\n",
        "lines.head(10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Src</th>\n",
              "      <th>Tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8136</th>\n",
              "      <td>location</td>\n",
              "      <td>&lt;START&gt; स्थान &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2289</th>\n",
              "      <td>move a card or build of cards on to the empty ...</td>\n",
              "      <td>&lt;START&gt; एक पत्ता या पत्तों के समूह खाली खाँचा ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3740</th>\n",
              "      <td>d</td>\n",
              "      <td>&lt;START&gt; d not applicablenot applicable &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>bottom panel</td>\n",
              "      <td>&lt;START&gt; निचला पटल &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7020</th>\n",
              "      <td>add</td>\n",
              "      <td>&lt;START&gt; file roller gnome hi po file roller hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4480</th>\n",
              "      <td>move a onto the ace of diamonds</td>\n",
              "      <td>&lt;START&gt; ईंट का इक्का &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>key</td>\n",
              "      <td>&lt;START&gt; कुंजी &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1775</th>\n",
              "      <td>hopscotch</td>\n",
              "      <td>&lt;START&gt; हॉपस्कॉच &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9758</th>\n",
              "      <td>symboldb menu actions</td>\n",
              "      <td>&lt;START&gt; नमूना क्रिया &lt;END&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6649</th>\n",
              "      <td>new file</td>\n",
              "      <td>&lt;START&gt; नया फिल्टर &lt;END&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Src  \\\n",
              "8136                                           location   \n",
              "2289  move a card or build of cards on to the empty ...   \n",
              "3740                                                  d   \n",
              "736                                        bottom panel   \n",
              "7020                                                add   \n",
              "4480                    move a onto the ace of diamonds   \n",
              "1348                                                key   \n",
              "1775                                          hopscotch   \n",
              "9758                              symboldb menu actions   \n",
              "6649                                           new file   \n",
              "\n",
              "                                                    Tar  \n",
              "8136                                <START> स्थान <END>  \n",
              "2289  <START> एक पत्ता या पत्तों के समूह खाली खाँचा ...  \n",
              "3740       <START> d not applicablenot applicable <END>  \n",
              "736                             <START> निचला पटल <END>  \n",
              "7020  <START> file roller gnome hi po file roller hi...  \n",
              "4480                         <START> ईंट का इक्का <END>  \n",
              "1348                                <START> कुंजी <END>  \n",
              "1775                             <START> हॉपस्कॉच <END>  \n",
              "9758                         <START> नमूना क्रिया <END>  \n",
              "6649                           <START> नया फिल्टर <END>  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "VHAtdcd8EaI1",
        "colab_type": "code",
        "outputId": "dbf21d39-d90d-44ef-85f5-a9d42b2747ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X, y = lines.Src, lines.Tar\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9000,), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "tl8Ycl_APpTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "del lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HQrGCSbUEaI7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_batch(X=X_train, y=y_train, batch_size=128):\n",
        "  while True:\n",
        "    for j in range(0, len(X), batch_size):\n",
        "      encoder_input_data = np.zeros((batch_size, max_len_src), dtype='float32')\n",
        "      decoder_input_data = np.zeros((batch_size, max_len_tar), dtype='float32')\n",
        "      decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens), dtype='float32')\n",
        "      \n",
        "      for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "        for t, word in enumerate(input_text.split()):\n",
        "          if word not in src_summary['dictionary'].keys():\n",
        "            word = 'UNK'\n",
        "          encoder_input_data[i, t] = src_summary['dictionary'][word]\n",
        "        \n",
        "        for t, word in enumerate(target_text.split()):\n",
        "          if word not in tar_summary['dictionary'].keys():\n",
        "            word = 'UNK'\n",
        "          \n",
        "          if t < len(target_text.split())-1:\n",
        "            decoder_input_data\n",
        "            \n",
        "          if t > 0:\n",
        "            decoder_target_data[i, t-1, tar_summary['dictionary'][word]] = 1\n",
        "            \n",
        "        yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xfKb1PFoEaI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "latent_dim = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HTASgTCtLXRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "11cff0f5-0b88-4e05-ee10-78aa92ebb9f7"
      },
      "cell_type": "code",
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "def training():\n",
        "  \"\"\"\n",
        "    Defines a Keras model and runs on training set give by generator function.\n",
        "  \"\"\"\n",
        "  ### Encoder ###\n",
        "  # Input layer\n",
        "  encoder_inputs = Input(shape=(None, ), name='Encoder_Inputs')\n",
        "  \n",
        "  # Word2Vec embedding layer\n",
        "  encoder_embedding_layer = Embedding(num_encoder_tokens, latent_dim, \n",
        "                                      weights=[src_summary['embeddings']], \n",
        "                                      name='English_Embeddings')\n",
        "  encoder_embeddings = encoder_embedding_layer(encoder_inputs)\n",
        "  \n",
        "  # Encoder LSTM layer\n",
        "  encoder_lstm = CuDNNLSTM(64, return_state=True, name='Encoder_LSTM')\n",
        "  encoder_outputs, state_h, state_c = encoder_lstm(encoder_embeddings)\n",
        "  \n",
        "  # Save states for decoder\n",
        "  encoder_states = [state_h, state_c]\n",
        "  \n",
        "  \n",
        "  ### Decoder ###\n",
        "  # Input layer\n",
        "  decoder_inputs = Input(shape=(None, ), name='Decoder_Inputs')\n",
        "  \n",
        "  # Word2Vec embedding layer\n",
        "  decoder_embedding_layer = Embedding(num_decoder_tokens, latent_dim, \n",
        "                                      weights=[tar_summary['embeddings']], \n",
        "                                      name='Hindi_Embeddings')\n",
        "  decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "  \n",
        "  # Decoder LSTM layer\n",
        "  decoder_lstm = CuDNNLSTM(64, return_sequences=True, return_state=True, name='Decoder_LSTM')\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder_embeddings, initial_state=encoder_states)\n",
        "  \n",
        "  # Fully connected Softmax layer for predictions\n",
        "  decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Dense')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  \n",
        "  \n",
        "  ### Model ###\n",
        "  model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "  model.fit_generator(generator=generate_batch(X_train, y_train, batch_size=batch_size), \n",
        "                      steps_per_epoch=train_samples//batch_size, \n",
        "                      epochs=epochs, \n",
        "                      validation_data=generate_batch(X_test, y_test, batch_size=batch_size), \n",
        "                      validation_steps=val_samples//batch_size)\n",
        "training()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DBZ7-lRCEaJa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim, ))\n",
        "decoder_state_input_c = Input(shape=(latent_dim, ))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SyCfJ_OBEaJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = hin_summary['dictionary']['<START>']\n",
        "    \n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        \n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = hin_summary['reverse_dictionary'][sampled_token_index]\n",
        "        decoded_sentence += ' ' + sampled_char\n",
        "        \n",
        "        if (sampled_char == '<END>') or (len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "            \n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "        \n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9B4W79kEaJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w840p8M2EaJi",
        "colab_type": "code",
        "outputId": "dd38487e-85b2-4cf1-8e28-4e15845d92c5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][7:-5])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input English sentence: too many selectable children\n",
            "Actual Hindi Translation:  बहुत अधिक चयनीय शिशु हैं \n",
            "Predicted Hindi Translation:  बहुत अधिक चयनीय शिशु हैं \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VmkOOEZCEaJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aay7cTRgEaJm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "749e452f-bd3e-4c4f-9e4a-bbc5a546a899"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"/var/log/colab-jupyter.log\", \"r\") as fo:\n",
        "  for line in fo:\n",
        "    print(json.loads(line)['msg'])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret\n",
            "google.colab serverextension initialized.\n",
            "Serving notebooks from local directory: /\n",
            "0 active kernels\n",
            "The Jupyter Notebook is running at:\n",
            "http://172.28.0.2:9000/\n",
            "Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
            "Kernel started: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
            "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
            "Adapting to protocol v5.1 for kernel c4dbbf68-7cc1-4958-81c9-84080122875b\n",
            "2019-04-01 14:36:25.486024: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-01 14:36:25.486495: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c2520 executing computations on platform Host. Devices:\n",
            "2019-04-01 14:36:25.486530: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-01 14:36:25.633812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-01 14:36:25.634531: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x19c1fa0 executing computations on platform CUDA. Devices:\n",
            "2019-04-01 14:36:25.634563: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-04-01 14:36:25.635939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-04-01 14:36:25.636333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-01 14:36:27.076814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-01 14:36:27.076971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-01 14:36:27.076992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-01 14:36:27.077415: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-01 14:36:27.077517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "2019-04-01 14:36:34.217251: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\n",
            "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
            "Kernel interrupted: c4dbbf68-7cc1-4958-81c9-84080122875b\n",
            "tcmalloc: large alloc 5376024576 bytes == 0x7f392d9fe000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
            "tcmalloc: large alloc 5376024576 bytes == 0x7f37ed304000 @  0x7f3b1d1ff001 0x7f3b118f2b85 0x7f3b11955b43 0x7f3b11957a86 0x7f3b119ef868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7f3b1cbc16db 0x7f3b1cefa88f\n",
            "KernelRestarter: restarting kernel (1/5), keep random ports\n",
            "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
            "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
            "2019-04-01 14:42:23.533314: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-04-01 14:42:23.534469: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5e520 executing computations on platform Host. Devices:\n",
            "2019-04-01 14:42:23.534510: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-04-01 14:42:23.695447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-04-01 14:42:23.696692: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1f5dfa0 executing computations on platform CUDA. Devices:\n",
            "2019-04-01 14:42:23.696758: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-04-01 14:42:23.697534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.10GiB\n",
            "2019-04-01 14:42:23.697604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-04-01 14:42:24.745623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-04-01 14:42:24.745702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-04-01 14:42:24.745724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-04-01 14:42:24.746543: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-04-01 14:42:24.746716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10754 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "tcmalloc: large alloc 5376024576 bytes == 0x40360000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
            "tcmalloc: large alloc 5376024576 bytes == 0x7fcfff906000 @  0x7fd1e75f4001 0x7fd1dbce7b85 0x7fd1dbd4ab43 0x7fd1dbd4ca86 0x7fd1dbde4868 0x5030d5 0x507641 0x58c63a 0x50e3f0 0x502d6f 0x506859 0x504c28 0x58650d 0x59ebbe 0x507c17 0x504c28 0x58650d 0x59ebbe 0x507c17 0x502209 0x502f3d 0x506859 0x502209 0x502f3d 0x506859 0x501945 0x591461 0x59ebbe 0x5e1662 0x7fd1e6fb66db 0x7fd1e72ef88f\n",
            "KernelRestarter: restarting kernel (1/5), keep random ports\n",
            "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n",
            "WARNING:root:kernel c4dbbf68-7cc1-4958-81c9-84080122875b restarted\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MVzXHer8QdkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}